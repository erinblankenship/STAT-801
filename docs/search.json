[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Stat 801A Notes",
    "section": "",
    "text": "Course Goals for STAT 801A\nSTAT 801A is an introduction to research methods, and how statistical methods may be used to answer research questions. By the end of the course, you will:\n\nunderstand the role statistics plays in the research process, and how a statistical investigation works.\nunderstand statistical evidence, and what conclusions may be drawn based on the evidence and study design.\nbe able to make simple probability calculations, and be able to differentiate a few different probability distributions based on the scenario.\nunderstand that variablility is natural, and commonly used statistics such as the mean, variance, and others have their own probability distributions. Such a probability distribution is called a sampling distribution.\nunderstand the underlying logic behind commonly used statistical inference techniques (hypothesis tests and confidence intervals).\nrealize that the most appropriate statistical inference method changes based on the explanatory variable(s), response variable, and goals of the study.\nbe able to calculate and interpret statistical analyses for studies in which there is one (or fewer) explanatory variables.\nbe able to sketch a skeleton ANOVA table from a description of the study.\nuse statistical software appropriately.\nbe able to clearly write up the results of an analysis.",
    "crumbs": [
      "Course Goals for STAT 801A"
    ]
  },
  {
    "objectID": "Section 1 Introduction.html",
    "href": "Section 1 Introduction.html",
    "title": "1  Introduction to Data and the Scientific Method",
    "section": "",
    "text": "1.1 Step 1: Ask a research question\nSound scientific conclusions require evidence from data. Statistics is the science of collecting, analyzing, and drawing conclusions from data. The goal of STAT 801A is to introduce you to the statistical methods used to answer research questions.\nThe scientific method has been used for hundreds of years for discovering new knowledge, and can be summarized with the following diagram:\nIt’s not coincidental that the steps in the scientific method are closely related to the steps in a statistical investigation. These steps appear in Tintle et al. (2021), but are not at all unique to this textbook.\nHow do you think the steps in a statistical investigation map to the scientific method? Can you map the baby study to either paradigm?\nEach of these steps has a lot of moving parts, so we’ll look at each step in more detail and introduce some concepts and introductory definitions as we do so.\nStep 1 boils down to\nThis may involve\nLet’s consider the baby example.\nWhy is a well-stated research question so important?\nAsking a research question is often the hardest part of the process, and requires technical information and experience in the discipline. A big reason why you are in graduate school is to gain this information and experience! A statistician can help you narrow your research question and state it precisely, but will not be able to formulate it for you.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Data and the Scientific Method</span>"
    ]
  },
  {
    "objectID": "Section 1 Introduction.html#step-2-design-a-study-and-collect-data",
    "href": "Section 1 Introduction.html#step-2-design-a-study-and-collect-data",
    "title": "1  Introduction to Data and the Scientific Method",
    "section": "1.2 Step 2: Design a study and collect data",
    "text": "1.2 Step 2: Design a study and collect data\nStep 2 involves\n\n\n\n\n\nThere is so much going on here that is not evident from the simple statement of “collect data.” Let’s first think about why there are so many things to consider.\nLet’s think about the babies. What questions do you think the researchers had to address in their design and data collection?\n\n\n\nWe’re trying answer a research question, and let’s specifically think about evaluating hypotheses (though the same applies to estimating an unknown quantity). We can almost never absolutely accept or reject a research theory for two reasons:\n\nVariability of experimental material\n\n\n\n\n\n\n\nSampling\n\n\n\n\n\n\nVariability and sampling are probably the two most important ideas in statistics, but they are also some of the hardest to grasp. Let’s lay out some basic concepts.\nA researcher’s major goal is to make general statements about their question as it applies to their population of interest.\n\n\n\n\n\n\n\nPopulations can be finite or infinite. Even if the population is finite, we typically can’t measure all of the units in the population. So, to collect data, we must select a subset of the population, a sample and hope that the subset is representative of the population.\nWe’d really rather not rely on hope, and collect data in a way that ensures the sample represents the population. This is typically accomplished by random sampling\n\n\n\n\n\n\n\n\nThere are other considerations as well, typically driven by both the research question and practicality. These include:\nExperiment or observational study?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIf it’s an experiment, what is the experimental unit?\n\n\n\n\n\n\n\n\n\n\n\n\nWhat variable(s) will be measured?\n\n\n\n\n\n\n\n\n\n\n\n\nHow will the variables be measured? With how much precision?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIf two or more variables are measured, can one be considered the response variable and the other(s) be considered explanatory?\n\n\n\n\n\n\n\n\n\n\n\n\n\nIs it possible to employ random sampling, random assignment, or both?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow many observations should we collect?",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Data and the Scientific Method</span>"
    ]
  },
  {
    "objectID": "Section 1 Introduction.html#step-3-explore-the-data",
    "href": "Section 1 Introduction.html#step-3-explore-the-data",
    "title": "1  Introduction to Data and the Scientific Method",
    "section": "1.3 Step 3: Explore the data",
    "text": "1.3 Step 3: Explore the data\nExploring the data means\n\n\n\n\n\n\nFor example, consider the histogram below. It shows the percent of residents aged 65 years and over in the 50 US states and District of Columbia.\n\n\n\nHistogram of percent of residents aged 65 and over.\n\n\nDo you think these outliers are the result of a recording error?\nHowever, exploring the data goes beyond looking for unexpected outcomes, it also encompasses exploratory data analysis (EDA). EDA includes both numerical exploration and graphical exploration. Our textbook does a great job summarizing both numerical and graphical summaries of data (pages 30-73), including walking through how EDA can be used in several case studies.\nWe won’t spend a lot of time here, since these are mostly very familiar concepts (mean, median, etc.) However, we’ll go through a small example as a preview of coming attractions.\nExample: The Gettysburg Address is comprised of 268 words, with word lengths varying from 1 (“a”) to 11 (“consecrated”) letters. Supposed we’re interested in the average word length.\nThe population of interest is\n\n\n\nWe’re going to take a random sample of \\(n=9\\) words. The sample is\n\nRandom sample of 9 words from the Gettysburg Address\n\n\nWord ID\nWord\nLength\n\n\n\n\n53\nlong\n4\n\n\n31\nNow\n3\n\n\n120\nbrave\n5\n\n\n263\nshall\n5\n\n\n264\nnot\n3\n\n\n249\nof\n2\n\n\n221\nfull\n4\n\n\n144\nnote\n4\n\n\n209\ntake\n4\n\n\n\nUsing our sample, we can easily find the sample mean and sample median.\n\n\n\n\n\nThese values are statistics.\n\n\n\n\nWe typically use statistics to estimate parameters.\nIn this case, we can actually calculate the parameters, because we have access to the entire population.\n\n\n\n\nThis is a very artificial situation. Most of the time, we only have the data in the sample and we want to use the statistics to make some statements about the parameters.\nWe may also be interested in how much variability there is among word lengths. There are a few ways we could quantify variability. Again, let’s consider the sample of 9 words.\n\n\n\n\nAgain, these are statistics because they’re calculated only from our sample of \\(n=9\\) observed words. In this case, we can get the parameters.\n\n\n\n\n\n\nIf we were to take a different sample of size \\(n=9\\), we’d likely get different statistics. Let’s try it.\n\n\n\n\n\n\nSo the sample mean, a statistic, is itself a random variable. There is uncertainty associated the outcome.\nWhat happens if we draw samples that are bigger than \\(n=9\\)?\n\n\n\n\n\n\nSo, the sample mean has its own variance, which depends on the sample size. Specifically,\n\n\n\n\n\n\n\nBut, in real life, we only observe one sample–which means we get one mean and one variance. We need to understand the underlying behavior/variability of the sample statistics to be able to use them to make statements about the population parameters. This is why variability and sampling are such important concepts in statistics. We need to know how our sample statistic behaves in order to …",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Data and the Scientific Method</span>"
    ]
  },
  {
    "objectID": "Section 1 Introduction.html#step-4-draw-inferences-beyond-the-data",
    "href": "Section 1 Introduction.html#step-4-draw-inferences-beyond-the-data",
    "title": "1  Introduction to Data and the Scientific Method",
    "section": "1.4 Step 4: Draw inferences beyond the data",
    "text": "1.4 Step 4: Draw inferences beyond the data\nThe general idea in drawing inferences beyond the data\n\n\n\n\n\nBasically, we’re trying to see what the sample data tells us about the population of interest.\n\n\n\n\n\n\nLet’s go back to the babies. If the babies really can’t tell right from wrong, how likely is a baby to pick the good character?\n\n\n\n\nWe haven’t even seen the data yet, but we can think about how a sample statistic should behave. What was measured? What is the sample statistic of interest? Once we get a handle on how the sample statistic should behave, we can assess how unusual the observed data actually are, if the babies really can’t tell right from wrong.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Data and the Scientific Method</span>"
    ]
  },
  {
    "objectID": "Section 1 Introduction.html#step-5-formulate-conclusions",
    "href": "Section 1 Introduction.html#step-5-formulate-conclusions",
    "title": "1  Introduction to Data and the Scientific Method",
    "section": "1.5 Step 5: Formulate conclusions",
    "text": "1.5 Step 5: Formulate conclusions\nHere, our conclusions must consider the scope of inference made in Step 4.\n\n\n\n\n\n\nIt’s important to keep in mind the population of interest, and whether we employed random assignment, random sampling, both, or neither.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Data and the Scientific Method</span>"
    ]
  },
  {
    "objectID": "Section 1 Introduction.html#step-6-look-back-and-ahead",
    "href": "Section 1 Introduction.html#step-6-look-back-and-ahead",
    "title": "1  Introduction to Data and the Scientific Method",
    "section": "1.6 Step 6: Look back and ahead",
    "text": "1.6 Step 6: Look back and ahead\nThis step involves\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAs we progress through the semester, Step 4 is where we’ll spend most of our time. We’ll consider different types of variables, different research goals, different study designs, and how we can use the data to draw inferences to a larger population.\nAs we saw earlier, in order to draw those inferences we need to understand and be able to quantify how much variability we expect to see in the sample statistic. We also need more precise definitions and rules around the uncertainty associated with data. In the next section, we’ll discuss the basics of probability and probability distributions.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Data and the Scientific Method</span>"
    ]
  },
  {
    "objectID": "Section 2 Probability.html",
    "href": "Section 2 Probability.html",
    "title": "2  Probability Basics and Probability Distributions",
    "section": "",
    "text": "2.1 Probability Basics\nProbability is the language we use to talk about chance and quantify uncertainty. A probability is a number between 0 and 1, where an event is more likely the closer the probability is to 1.\nWe’ve already seen a probability! Back to the babies–when we considered how unusual it was to see 13/16 babies pick the good puppet, we calculated:\nThe value we calculated is a p-value: the (empirical) probability of observing what we did in the data (or something even more extreme), under the assumption that the null hypothesis is true. For better or worse, science runs on p-values.\nIn this section, we’ll see some basic probability theory and calculations, as well as probability distributions.\nWhen we are uncertain about an outcome’s occurrence (e.g., whether a coin will come up heads or tails, the number of dots observed on the roll of a die, whether or not the bus will be late), we typically quantify this uncertainty with a probability. Probability is the foundation upon which all of statistics is built, and it a provides a framework for modeling populations, experiments, and almost anything that could be considered a random phenomenon.\nA sample space, denoted by \\(S\\), is comprised of all possible outcomes of a random phenomenon.\nAn event is a collection of possible outcomes. Each event \\(A\\) is a subset of \\(S\\).\nWe want to formalize the idea of the “chance” that event \\(A\\) occurs. We will do this by defining the probability of each \\(A\\), which we denote \\(P(A)\\).\nProbabilities are calculated by defining functions on sets, and should be defined for all possible events. One thing that must be true: \\[\n0 \\leq P(A) \\leq 1\n\\]\nMore formally, a probability function is defined as follows.\nGiven a sample space \\(S\\), a probability function is a function P(\\(\\cdot\\)) that satisfies\nAny function P(\\(\\cdot\\)) that satisfies these three requirements is called a probability function.\nIf we let \\(S\\) be a sample space with associated probability function P, we can state some basic facts. Let \\(A, B\\) be events in \\(S\\).\nWe’ll use these facts when calculating probabilities. First, however, we need to figure out how to assign probabilities to specific events. There are several ways we can do this.\nHowever we arrive at probabilities for a given scenario, we can use them to construct a probability distribution. There are several flavors of probability distribution. The simplest is a list of all possible outcomes and their associated probabilities, and it must satisfy three rules:\nAny probability distribution that can be written this way corresponds to a discrete variable or one that we have discretized.\nWe’ll see some other (more common, but more complicated) flavors of probability distributions in a bit, after some facts and definitions.\nConsider the following table:\nThe counts in the table are the number of Titanic passengers that fell into each of the categories. From this table, we can calculate some probabilities.\nSometimes we have partial information about a certain event and wish to know how this affects the probablities of other events, if at all. For example, we might be interested in the probability a passenger survived, given they were in First Class. This is called conditional probability.\nDefinition:\nExample: Toss a fair die. Let \\(A=\\{1\\}\\) and let \\(B=\\{1,3,5\\}\\). What is the probability of throwing a 1, given an odd number was thrown?\nThis definition of conditional probability leads to:\nLet \\(A_1, A_2, \\dots\\) be a collection of mutually exclusive and exhaustive events. What does this mean?\nSuppose we want the probability of an event \\(B\\).\nThis leads to the general form of Bayes’ Theorem:\nExample: (Problem 2.18) A genetic test is used to determine if people have a predisposition for thrombosis, which is a formation of a blood clot inside a blood vessel that obstructs the flow of blood through the circulatory system. It is believed that 3% of people actually have this predisposition. The genetic test is 99% accurate if a person actually has the predisposition. The test is 98% accurate if a person does not have the predisposition.\nWhat is the probability a randomly selected person who tests positive for the predisposition by the test actually has the predisposition?\nConsider the following table, which summarizes all flights arriving at an airport in a single day:\nWhat is the probability a randomly selected flight on this day was on time?\nWhat is the probability a randomly selected flight was on time, given it was a domestic flight?\nWhat do you notice?\nDoes this make sense in the context of this scenario? What do you think it means?\nSometimes the occurrence of one event, \\(B\\), will have no effect on the probability of another event, \\(A\\). If \\(A\\) and \\(B\\) are unrelated, then intuitively it should be the case\nAlso, it follows that\nDefinition:\nHow is independence used? Let’s do a pretty famous example. We’ll use a few of the rules we’ve seen so far.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Probability Basics and Probability Distributions</span>"
    ]
  },
  {
    "objectID": "Section 2 Probability.html#probability-basics",
    "href": "Section 2 Probability.html#probability-basics",
    "title": "2  Probability Basics and Probability Distributions",
    "section": "",
    "text": "Equally likely outcomes\n\n\n\nRelative frequencies\n\n\n\nMaking assumptions\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSurvived\nDid Not Survive\n\n\n\n\nFirst Class\n201\n123\n\n\nSecond Class\n118\n166\n\n\nThird Class\n181\n528\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLate\nOn Time\n\n\n\n\nDomestic\n12\n109\n\n\nInternational\n6\n53",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Probability Basics and Probability Distributions</span>"
    ]
  },
  {
    "objectID": "Section 2 Probability.html#random-variables-and-probability-distributions",
    "href": "Section 2 Probability.html#random-variables-and-probability-distributions",
    "title": "2  Probability Basics and Probability Distributions",
    "section": "2.2 Random Variables and Probability Distributions",
    "text": "2.2 Random Variables and Probability Distributions\nTypically we are interested in a numerical measurement of the outcome of a random experiment. For example, we might want to know the number of insects treated with a dose of a new insecticide that are killed. In this case, the outcome is the survival status of each dosed insect and the numerical measurement we’re interested in is the number that died. However, the observed number varies depending on the actual result of the experiment. This type of variable is called a random variable.\nDefinition: A random variable is a function that associates a real number with each element in the sample space. That is, a random variable is a function from a sample space, \\(S\\), into the real numbers.\nExample: Suppose we roll two dice and we’re interested in the number of 1s that are thrown.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRandom variables can also be defined on a continuous range.\nExample: Take a 1 gram soil sample and measure the amount of phosphorus in the sample (in g).\n\n\n\n\nWe’ve already seen one flavor of probability distribution: a list of possible outcomes for the random variable, and the associated probabilities.\n\n\n\n\n\nWe can define probability distribution more generally.\nDefinition: A probability distribution is a function that is used to assign probability to each value the random variable can take on.\nMaybe that function can be written in tabular form, as above, maybe it’s a function in the mathematical function sense (we’ll see some of these later in this section). We can have probability distributions for discrete random variables and continuous random variables.\nDiscrete probability distributions\n\nProbabilities are denoted P\\((X=x)\\) for the realized value \\(x\\) of random variable \\(X\\)\n\\(\\sum_i\\) P\\((X=x_i)\\) = 1.\n\n\n\n\n\nExample: We have two seeds in a Petri dish, and will observe how many germinate. We assume the seeds germinate independently, and the probability a randomly selected seed germinates is 0.80.\n\n\n\n\n\n\nContinuous probability distributions\n\nThis distribution is called a probability density function (pdf) and denoted \\(f(x)\\).\nThe area bounded by \\(f(x)\\), the horizontal axis, and the values \\(a\\) and \\(b\\) is P\\((a \\leq X \\leq b)\\).\nThe total area under the pdf is 1.\n\n\n\n\n\nExample: Let \\(X\\) = phosphorus in a 1 gram soil sample. Suppose we assume the pdf is \\[\nf(x) = \\left \\{ \\begin{array}{ll} 1 & 0 \\leq x \\leq 1 \\\\ 0 & x &lt; 0, x &gt; 1 \\end{array} \\right .\n\\]\n\n\n\n\n\n\n\n\nJoint probability distributions: We’ve already seen some of these! A joint probability distribution can be used to study the relationship between two variables, \\(X\\) and \\(Y\\), simultaneously. We’re going to restrict our attention to discrete joint probability distributions, and summarize them as two-way tables.\nLet’s go back to the Titanic example:\n\n\n\n\nSurvived\nDid Not Survive\n\n\n\n\nFirst Class\n201\n123\n\n\nSecond Class\n118\n166\n\n\nThird Class\n181\n528\n\n\n\n\n\n\n\n\nIf we know the probability distribution for a random variable, we can use it to calculate things like the “true” mean and variance for that variable.\nExpected value: The expected value (or mean) of a discrete random variable is defined as\n\n\n\n\n\n\n\n\n\nThere are some rules that come along with expected values (discrete or continuous):\n\nIf \\(X\\) is a random variable and \\(c\\) is a constant, then\n\n\n\n\n\n\nIf \\(X\\) is a random variable, \\(b\\) and \\(c\\) are constants, and \\(Y=bX + c\\), then\n\n\n\n\n\n\nIf \\(X\\) and \\(Y\\) are random variables, \\(b\\) and \\(c\\) are constants, and \\(W=bX + cY\\), then\n\n\n\n\n\n\n\n\nExample: Let \\(X\\) = number of 1s thrown when rolling two dice.\n\n\n\n\nVariance: The variance of a discrete random variable is defined as\n\n\n\n\n\n\n\n\nThere are also rules that come along with variance (discrete or continuous):\n\nFor any random variable \\(X\\) and any constant \\(c\\),\n\nIf \\(X\\) is a random variable, \\(b\\) and \\(c\\) are constants, and \\(Y=bX + c\\), then\n\n\n\n\n\nIf \\(X\\) and \\(Y\\) are independent random variables, and \\(b\\) and \\(c\\) are constants, then\n\n\n\n\n\n\n\n\n\n\n\n\n\nIf \\(X\\) and \\(Y\\) are any two random variables, and \\(b\\) and \\(c\\) are constants, then\n\n\n\n\n\n\n\n\n\n\n\nExample: In Mendel’s experiments on pea plants, he found the trait of being tall is dominant over being short. His theory indicates that if pure-line tall and pure-line short plants are cross-pollinated and then the hybrids in the next generation are cross-pollinated, in the resulting population approximately 3/4 of the plants will appear tall and 1/4 will appear short. If four plants are chosen at random from such a population, the best model (i.e., probability distribution) for the number of tall plants out of the four is\n\n\n\n\\(y\\)\n0\n1\n2\n3\n4\n\n\n\n\nP\\((Y=y)\\)\n1/256\n12/256\n54/256\n108/256\n81/256\n\n\n\n\nFind the expected number of tall plants\n\n\n\n\n\n\n\n\n\nFind the variance of number of tall plants\n\n\n\n\n\n\n\n\n\n\n\n\n\nFind the standard deviation of number of tall plants\n\n\n\n\n\nWhat is the probability that the value of \\(Y\\) will be more than 2 standard deviations below the expected value?\n\n\n\n\nExample: Three patients receive injections to desensitize them from an allergen. The serum used is said to be 90% effective. Let \\(X\\) denote the number of patients who become desensitized.\n\nFind the probability distribution of \\(X\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\nFind the expected number of patients that will become desensitized.\n\n\n\n\n\n\n\n\n\nFind the variance and standard deviation of the number of patients who become desensitized.\n\n\n\n\n\n\n\n\n\nIf a patient does not become desensitized, the insurance company will spend $50 on additional treatment. How much should the insurance company expect to pay in additional costs for these three patients?\n\n\n\n\n\nExample: A forester is studying a population of trees that are known to have a mean height of 23.4 ft with a variance of 256 ft\\(^2\\). A tree is randomly selected from the population and its height is measured in feet. Let \\(X\\) represent the height of the randomly selected tree.\n\nWhat is the selected tree’s expected height in meters? (there are 0.3048 meters in a foot)\n\n\n\n\n\n\nWhat is the variance of the height of the selected tree in meters?\n\n\n\n\nExample: Contracts for two construction jobs are randomly assigned to one or more of three firms: A, B, and C. Let \\(Y_1\\) denote the number of contracts assigned to firm A and \\(Y_2\\) the number of contracts assigned to firm B. The joint probability distribution for this scenario is\n\n\n\n\n\n\n\n\n\nFind the expected number of contracts awarded to Firm A.\n\n\n\n\n\nFind the expected number of contracts awarded to Firm B.\n\n\n\n\n\nFind the variance of number of contracts awarded to Firm A.\n\n\n\n\n\nFind the variance of number of number of contracts awarded to Firm B.\n\n\n\n\nFind the expected number of contracts awarded to either Firm A or Firm B.\n\n\n\n\nFind the variance of the number of contracts award to either Firm A or Firm B.\n\n\n\n\n\nWhat now? What is this Cov?\nCovariance is a measure of the linear relationship between two random variables. It can be positive or negative. A positive covariance indicates that as the value of one RV increases, so does the other. A negative covariance indicates that as the value of RV increases, the other decreases.\nFor discrete RVs, the covariance is calculated as\n\n\n\n\n\nIf two random variables are independent, the covariance is 0.\n\n\nFor our example, do you think covariance will be positive, negative, or 0?\nLet’s calculate it, and find the variance above.\n\n\n\n\n\n\n\n\n\n\nNote the units of measurement on covariance.\n\n\n\n\n\nThis makes covariance less intuitive as a measure of dependence–its value depends on the scale of measurement. A measure of dependence that is not dependent on scale is the correlation:\n\n\n\n\n\nThe correlation is unitless, and must be \\(-1 \\leq \\rho \\leq 1\\). Just like covariance, if two random variables are independent, their correlation will be 0.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Probability Basics and Probability Distributions</span>"
    ]
  },
  {
    "objectID": "Section 2 Probability.html#special-probability-distributions",
    "href": "Section 2 Probability.html#special-probability-distributions",
    "title": "2  Probability Basics and Probability Distributions",
    "section": "2.3 Special Probability Distributions",
    "text": "2.3 Special Probability Distributions\nEarlier, we mentioned that some probability distributions can be written as mathematical functions. We’re going to discuss some probability distributions that commonly arise in data analysis.\n\n2.3.1 The Binomial Distribution\nIn some studies, the variable of interest only has two potential outcomes: success and failure. These could be died/survived, yes/no, occurred/did not occur, picked the good puppet/picked the bad puppet. Under some very specific conditions, variables like these follow a theoretical probability distribution called the binomial distribution.\nHere are the conditions we need:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIf these conditions are met, the probability distribution of \\(X\\) = number of “successes” observed in \\(n\\) trials is\n\n\n\n\n\n\nIf \\(X\\) follows a binomial distribution with parameter \\(p\\), then\n\n\n\n\nRight now, we’ll use the binomial distribution to calculate some probabilities assuming a specific value for \\(p\\), but inference for scenarios like this typically focuses on testing hypotheses about \\(p\\) (like the babies!) and estimating \\(p\\).\nExample: A new variety of turfgrass has been developed for use on golf courses, with the goal of obtaining a germination rate of 85%. To evaluate the grass, 20 seeds are planted in a greenhouse so that each seed will be exposed to identical conditions. If the 85% germination rate is correct, what is the probability that 18 or more seeds will germinate?\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow many seeds do we expect to germinate? What is the variance of the number of germinated seeds?\n\n\n\n\n\n2.3.2 The Poisson Distribution\nThe Poisson distribution models count data, typically the number of events observed for a particular unit of time or space. For example, the Poisson can be used to model variables like:\n\nthe number of hits to a website per minute\nthe number of PCB particles in a liter of water\nthe number of insects in a square meter\nthe number of cars passing through an intersection in 5 minutes\nthe number of flaws in a yard of fabric\n\nLike the Binomial, the Poisson has some requirements:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe probability distribution for the Poisson is\n\n\n\n\n\n\n\nThe Poisson distribution has a couple of interesting features:\n\n\n\n\n\nExample: Suppose grasshoppers are distributed at random in a large field according to a Poisson distribution with \\(\\lambda=2\\) grasshoppers per square meter.\n\nFind the probability that no grasshoppers will be found in a randomly selected square meter.\n\n\n\n\n\n\n\n\n\nFind the probability that 2 or fewer grasshoppers will be found in 2 square meters.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFind the expected number of grasshoppers in 10 square meters.\n\n\n\n\n\n\nFind the expected number of grasshoppers in 0.5 square meters.\n\n\n\n\n\n\n2.3.3 The Normal Distribution\nThe most commonly used continuous distribution (maybe the most commonly used distribution, period) is the normal distribution. It’s commonly used because\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe normal distribution is bell-shaped, symmetric, and unimodal. In fact, we shouldn’t call it the normal distribution, there are an infinite number of different normal distributions, depending on the parameters of the distribution, \\(\\mu\\) and \\(\\sigma^2\\).\n\n\\(\\mu\\) represents the mean of the distribution\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(\\sigma^2\\) represents the variance of the distribution\n\n\n\n\n\n\n\n\n\n\n\nThe normal distribution does has a mathematical function (a pdf) that governs its shape:\n\n\n\n\n\n\n\nWe denote random variables following the normal as\n\n\n\nand the normal with mean \\(\\mu=0\\) and variance \\(\\sigma^2=1\\) is called the standard normal distribution.\nThe standard normal gives us a convenient way to compare observations, and any normal distribution can be transformed into a standard normal. The Z-score is\n\n\n\n\n\n\nIf the Z-score is positive\n\n\nIf the Z-score is negative\n\n\nZ-scores can be used to\n\ngauge the unusualness of an observation\n\n\n\n\n\nfind probabilities\n\n\n\n\n\nSome helpful R functions:\n\npnorm(x, mean=0, sd=1)\nqnorm(prob, meam=0, sd=1)\n\n\n\n\nnormTail(m=0,s=1, L=x) or normTail(m=0,s=1,U=x) (does require the OpenIntro library)\n\nExample: Full-term birth weights for single babies are normally distributed with a mean of 7.5 pounds and a standard deviation of 1.1 pounds.\n\nA randomly selected newborn weighs 9.1 pounds. What is the weight percentile for this baby?\n\n\n\n\n\n\n\nBabies that weigh less than 5.5 pounds are considered low birth weight. What proportion of babies are low birth weight?\n\n\n\n\n\n\n\n\nWhat weight would make a baby at the 25th percentile?\n\n\n\n\n\n\n\n\nWhat is the probability a randomly selected baby weighs between 7 and 8 pounds?\n\n\n\n\n\n\nThe Empirical Rule (aka the 68-95-99.7 Rule) presents a general rule for the probability of falling within one, two, and three standard deviations of the mean in a normal distribution.\n\n\n\n\n\n\n\n\n\n\n\nThis rule is useful in a wide range of settings when trying to make a quick estimate.\nThe normal distribution is useful because it can be used to approximate other distributions, such as the binomial.\nLet’s see what happens with \\(p=0.15\\) as we change the sample size.\n\n\n\n\n\nRecall the binomial distribution has\n\n\nIf \\(n\\) is sufficiently large, the binomial can be well-approximated with a normal distibution with \\(\\mu=np\\) and \\(\\sigma^2 = np(1-p)\\).\nWhat’s sufficiently large?\n\n\nExample: (problem 3.33) Suppose a university announced that it admitted 2500 students for the incoming first year class. However, the univesity has dorm room spots for only 1786 first year students. If there is a 70% chance an admitted student will enroll at the university, what is the probability the university will not have enough dorm room spots?",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Probability Basics and Probability Distributions</span>"
    ]
  },
  {
    "objectID": "Section 3 Sampling Distributions.html",
    "href": "Section 3 Sampling Distributions.html",
    "title": "3  Sampling Distributions and Foundations of Statistical Inference",
    "section": "",
    "text": "3.1 Sampling Distributions\nAs we’ve seen in the last two chapters, variability is natural and expected. We expect to see variability in observations, which implies there will also be variability in summary statistics. We’ve seen this already:\nIf we want to use a summary statistic (like \\(\\bar X\\) or \\(\\hat p\\)) calculated from our sample to draw inferences about the population, we have to understand how the summary statistic behaves.\nThis means, we need to know the sampling distribution of the statistic.\nAs a refresher, the goal of statistical inference is to use an observed data set to answer questions about the overall population from which the sample data set was drawn. Typically, those questions may be answered using some parameter(s) of the population distribution.\nA parameter is\nFor example,\nParameters are generally fixed, unknown constants. We want to use our sample data to answer a question about the parameter (hypothesis test) or estimate the parameter (confidence interval). We may also be interested in functions of parameters.\nOften, the statistic we’ll use to estimate the underlying parameter is pretty intuitive.\nBut, if we want to use a statistic, we have to understand its behavior.\nThe sampling distribution is\nWe’ve can study sampling distributions empirically, through simulation. We’ve already done this!\nWe can also quantify sampling distributions theoretically. We’ve already done this too!\nThe sampling distributions we’ve seen so far have been (mostly):\nThis isn’t coincidence it’s guaranteed by a very important theorem, the Central Limit Theorem.\nCentral Limit Theorem:\nBut wait, the sample mean? Weren’t we also considering sample proportions?\nLet’s think more about these requirements:\nIf the Central Limit Theorem holds, the underlying parameters of the resulting approximate normal distribution will depend on the population from which the original data were drawn.\nOther statistics will have sampling distributions that do not follow an approximate normal. For example, the sample variance is a natural estimate for the population variance. But, the CLT does not apply to variances. We’ll need a different distribution.\nOnce we can articulate the sampling distribution, we can use it to do statistical inference.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Sampling Distributions and Foundations of Statistical Inference</span>"
    ]
  },
  {
    "objectID": "Section 3 Sampling Distributions.html#sampling-distributions",
    "href": "Section 3 Sampling Distributions.html#sampling-distributions",
    "title": "3  Sampling Distributions and Foundations of Statistical Inference",
    "section": "",
    "text": "Independence\n\n\n\n“Large enough”",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Sampling Distributions and Foundations of Statistical Inference</span>"
    ]
  },
  {
    "objectID": "Section 3 Sampling Distributions.html#foundations-of-statistical-inference",
    "href": "Section 3 Sampling Distributions.html#foundations-of-statistical-inference",
    "title": "3  Sampling Distributions and Foundations of Statistical Inference",
    "section": "3.2 Foundations of Statistical Inference",
    "text": "3.2 Foundations of Statistical Inference\nIn Chapter One, we talked about framing a research question. Many (but not all) research questions can be answered using statistical inference. We’ll now lay out the basic logic of statistical inference, illustraing the different methods for the case in which we have a single response variable (quantitative or categorical) and no explanatory variable. The framework for statistical inference will not change as we move to more complicated scenarios.\nStatistical inference is a collection of techniques which use information from a sample to make precise statements about the entire population. In STAT 801A, the general statements about populations will be expressed in terms of the parameters, or functions of parameters, of probability distributions. Because we know the sampling distribution, we can use probability to precisely quantify the accuracy of our general statements.\nStatistical inference is broken into two broad categories: estimation and testing. These map back to the types of research questions we outlined in Chapter One.\n\n\n\n\n\n\n\n3.2.1 Estimation\nThis category of statistical inference is concerned with using sample information to estimate one or more parameters, or functions of parameters, of the probability distribution for a population. For example, we may be interested in estimating the mean of a population, or the difference in means between two populations. There are two types of estimation, point estimation and interval estimation.\nPoint estimation\n\n\n\n\n\nBut a single value is not very meaningful without some way of telling how close our estimate comes to the true value.\nInterval estimation\n\n\n\n\n\nWe’ll illustrate how interval estimation works with an example.\nExample: An entomologist is studying a new tick species that may be the carrier of the pathogen associated with lyme disease. They design a study to estimate prevalence of the pathogen in the tick. They examine 200 ticks randomly selected in the study region during a period of the year when ticks have been known to be infected with the pathogen in other regions of the country. They find 18 ticks that are infected with the pathogen.\n\nParameter of interest:\n\n\n\n\n\nSample statistic:\n\n\n\n\nAre the requirements for the Central Limit Theorem met?\n\n\n\n\nThe Central Limit Theorem tells us\n\n\n\n\n\n\nNow let’s consider the Empirical Rule.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMost (but not all) confidence intervals have the form:\n\n\n\n\n\n\n\nSo, to calculate a confidence interval of this form we’ll need the margin of error, which is calculated based on the standard error of the statistic and the sampling distribution of the statistic. We’ll also need to specify how much certainly we want in our interval estimate.\n\n\n\n\nBack to the ticks.\n\n\n\n\n\n\n\n\n\n\n\n \n\n\nWhat happens if we change our level of confidence?\n\n\n\n\n\n\n\n\n\nWhat if we want a confidence level that isn’t 68, 95, or 99.7?\n\n\n\n\n\n\n\n\n\n\n\nLet’s think more carefully about what this confidence level means. A confidence interval is a probability statement, but not the probability statement that is intuitive. Suppose we are interested in an interval estimate for a parameter \\(\\theta\\).\n\n\n\n\nIt’s super important to understand that this probability statement is only valid for as long as \\(L\\) and \\(U\\) are unknown. Once we use the data to estimate \\(L\\) and \\(U\\), and get \\(\\hat{L}\\) and \\(\\hat{U}\\), the interval is no longer random. The interval either contains the parameter or it doesn’t. This means statements like\n\n\n\n\n\nare incorrect, as tempting as they are to write. Rather, the statement of probability is about the method used to obtain the confidence interval.\nLet’s look at the applet to explore what that confidence level really means: Applet\n\n\n\n\n\n\n\n\nSo, let’s find a 98% confidence interval for the proportion of ticks that are infected by the pathogen.\n\n\n\n\n\n\n\n\n\n\n\n\nExample: (4.17, sort of) The nutrition label on a bag of potato chips says that a one ounce serving has 130 calories and 10 grams of fat. A random sample of 35 bags yielded a sample mean of \\(\\bar{x}=134\\) calories with a sample standard deviation of \\(s = 17\\) calories. Assume the distribution of bags is relatively symmetric. We want a 95% confidence interval for the true mean calorie count of a bag of potato chips.\nWhat’s different about this example, compared to the tick example?\n\n\n\n\nLet’s state the Central Limit Theorem again.\n\n\n\n\n\n\n\n\nThis presents a few complications:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe natural fix is to use \\(s\\) (the sample standard deviation) in place of \\(\\sigma\\), so the standard error is\n\n\n\n\nBut this leads to yet another complication: the normal distribution isn’t quite right. Instead, we end up with a distribution that has heavier tails than the normal. Instead, we use the \\(t\\) distribution. The \\(t\\) distribution has a single parameter, the degrees of freedom (\\(df\\)). The degrees of freedom determines the shape of the \\(t\\), with the distribution getting closer and closer to the normal as the \\(df\\) increase.\n\n\n\nStandard normal compared to the t distribution with various df\n\n\nIn the scenario of a single mean, \\(df=n-1\\) but this will change as the scenario gets more complicated.\nWe can get \\(t\\) probabilities and quantiles using the R functions\n\npt(x, df=)\nqt(prob, df=)\n\nSo, if we’re interested in calculating an interval estimate for a mean\n\n\n\nBack to the potato chips example. Are the conditions for the Central Limit Theorem met?\n\n\n\n\nWe’ll calculate a 95% confidence interval.\n\nExample: An ichthyologist is interested in estimating the variance of lengths of trout minnows in a very large tank at a fish hatchery. It is reasonable to assume that lengths are normally distributed. 15 minnows are randomly sampled from the tank and measured. The sample variance is \\(s^2 = 0.17\\) inch\\(^2\\).\nWhat’s different now?\n\n\n\n\n\nWhat complications does this present?\n\n\n\n\n\n\n\n\n\n\n\nWe need a new distribution! We need the sampling distribution of \\(S^2\\). It turns out that a function of \\(S^2\\) follows the \\(\\chi^2\\) distribution. The \\(\\chi^2\\) has the following properties:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIf our original observations come from a normal distribution, then\n\n\n\nThis gives us a straightforward way to find a confidence interval for \\(\\sigma^2\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can find these \\(\\chi^2_{\\alpha/2}\\) and \\(\\chi^2_{1-\\alpha/2}\\) using the qchisq(prob,df=) function in R. For example,\n\n\n\n\n\n\n\n\n\n\nThis is one of the cases where the confidence interval does not have the estimate \\(\\pm\\) margin of error form. That’s because the \\(\\chi^2\\) isn’t symmetric. But, we now have all the information we need to calculate the confidence interval for the variance in trout length.\n\n\n\n\n\n\n\n\n\n\n\n\n\nA word of warning. This is not a robust procedure. If the assumption of normality is not met, this interval will give poor results. This is not true of the \\(t\\) interval for the mean.\n\n\n3.2.2 Hypothesis Testing\nThe goal of hypothesis tests is to use an observed data set to answer a yes/no question about a characteristic of a larger population from which the observed data set was drawn.\nFor example, let’s consider the ticks again. The entomologist knows from a literature review that the prevalence of the lyme disease pathogen in the black-legged tick is 0.02. They are interested in whether the presence of the pathogen is more prevalent in the new tick species. The yes/no question we will answer is whether the resulting data provide convincing evidence that the pathogen is more prevalent in the new species. These questions lead to two competing claims, both stated in terms of parameters of a probability distribution\n\nNull hypothesis\n\n\n\n\n\n\n\nAlternative hypothesis\n\n\n\n\n\n\nWe will choose between the competing claims by assessing whether the data conflict so much with H\\(_0\\) that the null hypothesis cannot be considered reasonable. If this happens, we’ll reject the notion of H\\(_0\\) and conclude that H\\(_a\\) must be true. We will NEVER conclude that the null hypothesis is true.\nHypothesis tests work by assuming the null hypothesis is true, and assessing the plausibility of the observed data under that assumption.\n\n\n\n\n\nThe entomologist examined 200 ticks randomly selected from the study region. If we assume the null hypothesis is true, then we expect to see\n\n\n\nIn fact, 18/200 ticks were infected with the pathogen. The question then becomes\n\n\n\n\nTo see how unusual this sample result of 18/200 is, we again need the sampling distribution of the sample statistic. As a reminder, the Central Limit Theorem says\n\n\n\n\n\n\n\n\nSo we can use normal distribution to see how unusual 18/200 is, if the null hypothesis is true.\n\n\n\n\n\n\n\n\n\nExample: Let’s consider the potato chip example again. The bag claims that a serving contains 130 calories. We want to test whether this is true. This leads to the hypotheses\n\n\n\n\n\nWhat’s different here?\n\n\n\n\n\n\nWe can again appeal to the Central Limit Theorem and the \\(t\\) distribution to characterize the sampling distribution of \\(\\bar{X}\\), which leads to the test statistic\n\n\n\n\n\nThe random sample of 35 bags had a sample mean of \\(\\bar{x}=134\\) and standard deviation \\(s=17\\).\n\n\n\n\n\n\n\nBut now what is “more unusual” assuming the null hypothesis is true?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhen in doubt, use a two-sided test! Use a one-sided test only if you truly have interest in only one direction. Why? To fully answer this, we need to address decision errors.\nAnytime we’re using sample data to make decisions about a larger population we can potentially make a mistake. We can make an incorrect decision in a hypothesis test or calculate a confidence interval that does not capture the true population parameter. In a hypothesis test, there are four possible outcomes at the outset of the study:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nType I error:\n\n\n\n\n\n\nType II error:\n\n\n\n\n\nExamples:\n\nDoping in the Olympics\n\n\n\n\n\n\n\n\nCriminal trial\n\n\n\n\n\n\n\n\nDiagnostic test for a serious disease\n\n\n\n\n\n\n\n\n\nErrors require a balancing act. We want to reduce the chance of making a Type I error but this will necessarily increase the chance of making a Type II error. The best we can do is to set the probability of a Type I error. We can do this through setting the significance level.\nSignificance level:\n\n\n\n\n\nSo how does this fit in with one- and two-sided hypotheses?\n\n\n\n\n\n\n\n\n\nHow else can we control Type I error?\n\nSet up tests before seeing the data.\nCollect enough data that the test has sufficient power. Power is the probability of correcting rejecting a false null hypothesis. It’s a function of how big the true difference is (which we don’t know and can’t control), the expected variability in our responses (also can’t control, but might know), and the sample size (which we can control). We’ll talk more about power later on in the semester.\n\nThe two examples we’ve seen have both utilized a test statistic with the form\n\n\n\n\n\n\n\nWith confidence intervals, we mentioned that many confidence intervals have the form estimate \\(\\pm\\) margin of error, but not all do. We saw an example, a confidence interval for a variance, that had a different form. Similarly, many tests have a test statistic of the form\n\\[\n\\frac{\\hbox{estimate - hypothesized value}}{\\hbox{standard error of estimate}}\n\\]\nbut not all do.\nExample: The Poisson distribution is often a good model for scenarios in which we are counting occurrences over some specified time or space unit. However, the Poisson distribution has the characteristic that the population mean = population variance. In some scenarios, this may not be true, invalidating the Poisson as a possible model. We can use hypothesis testing to determine if the Poisson is a reaonable model for a data set. A scientist is interested in modeling the number of parasites found on a host, and believes the Poisson may be a feasible model.\n\n\n\n\n\nThe researcher examines 80 host organisms, and records the number of parasites found on each. The data are:\n\n\n\nNumber of Parasites\n0\n1\n2\n3\n4\n5\n\n\n\n\nNumber of hosts\n20\n28\n19\n9\n3\n1\n\n\n\nThere is not a single mean or proportion (or variance) we can calculate here that will summarize how closely these data follow a Poisson distribution. Instead, we’ll need to come up with a new test statistic.\nThe first thing we’ll need is an estimate of the Poisson parameter, \\(\\lambda\\).\n\n\n\n\nNow, if we consider the Poisson distribution with \\(\\lambda = 1.375\\) we can calculate some probabilities:\n\n\n\nX\nProbability\n\n\n\n\n0\n0.2528\n\n\n1\n0.3477\n\n\n2\n0.2390\n\n\n3\n0.1095\n\n\n4\n0.0377\n\n\n5\n0.0104\n\n\nover 5\n0.0029\n\n\n\nIf the Poisson distribution is a realistic model, we would expect to see our data fall into these categories in about these proportions. So, we expect\n\n\n\n\n\n\n\n\n\n\n\n\n\nNumber of Parasites\n0\n1\n2\n3\n4\n5\n&gt;5\n\n\n\n\nNumber of hosts\n20\n28\n19\n9\n3\n1\n0\n\n\nExpected\n20.224\n27.816\n19.12\n8.76\n3.016\n0.832\n0.232\n\n\n\nand we can compare the observed counts to the expected counts.\n\n\n\n\n\n\n\n\n\n\n\n\n\nNumber of Parasites\n0\n1\n2\n3\n4\n5\n&gt;5\n\n\n\n\nNumber of hosts\n20\n28\n19\n9\n3\n1\n0\n\n\nExpected\n20.224\n27.816\n19.12\n8.76\n3.016\n0.832\n0.232\n\n\nDifference\n-0.224\n0.184\n-0.12\n0.24\n-0.016\n0.168\n-0.232\n\n\n\nBut we’ve got another problem.\n\n\n\n\nAgain, our solution will be squaring! This time we’ll also scale. The resulting test statistic is:\n\n\n\n\n\n\nThis is called the chi-squared goodness-of-fit test. Under the null hypothesis, this test statistic will follow a \\(\\chi^2\\) distribution with \\(k-1\\) degrees of freedom, where \\(k\\) is the number of categories. However, we also need a big enough sample so that all expected counts are at least 5. That’s not true here. What now?\n\n\n\n\n\n\n\n\n\nNumber of Parasites\n0\n1\n2\n\\(\\geq\\) 3\n\n\n\n\nNumber of hosts\n20\n28\n19\n13\n\n\nExpected\n20.224\n27.816\n19.12\n12.84\n\n\nDifference\n-0.224\n0.184\n-0.12\n0.16\n\n\n\nSo now,\n\n\n\n\n\n\n\nWe can also easily do this in R:\n\nhost&lt;-c(20,28,19,9, 3, 1, 0)\nchisq.test(host,p=c(0.2528, 0.3477, 0.2390, 0.1095, 0.0377, 0.0104, 0.0029))\n\nWarning in chisq.test(host, p = c(0.2528, 0.3477, 0.239, 0.1095, 0.0377, :\nChi-squared approximation may be incorrect\n\n\n\n    Chi-squared test for given probabilities\n\ndata:  host\nX-squared = 0.27703, df = 6, p-value = 0.9996\n\n\nSo R is telling us our sample size isn’t big enough for the \\(\\chi^2\\) distribution to work. Like we did by hand, we can collapse some categories.\n\nhost&lt;-c(20,28,19,13)\nchisq.test(host,p=c(0.2528, 0.3477, 0.2390, 0.1605))\n\n\n    Chi-squared test for given probabilities\n\ndata:  host\nX-squared = 0.0064451, df = 3, p-value = 0.9999\n\n\nSo it appears we have no reason to doubt that the Poisson distribution is a good model for these data.\nNow that we’ve seen the logic behind statistical inference, we can move on to more complicated situations. We’ll consider cases in which we have a single explanatory variable and a single response variable. We’ll first cover the case where the explanatory variable is categorical with only two levels, and the response variable is either categorical or numeric (comparing two groups). We’ll then move on to the case where the the explanatory variable is categorical with more than two levels, and the response variable is categorical or numeric. Finally, we’ll consider the case where the explanatory and response variable are both numeric.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Sampling Distributions and Foundations of Statistical Inference</span>"
    ]
  },
  {
    "objectID": "Section 4 One Pred Two Levels.html",
    "href": "Section 4 One Pred Two Levels.html",
    "title": "4  One Predictor/Explanatory Variable, Two Levels",
    "section": "",
    "text": "4.1 Categorical Response, Two Levels\nAs mentioned at the end of Chapter 3, we’ll now move on to cases in which we have a single explanatory variable and a single response variable. In this section, we’ll cover the case where the explanatory variable is categorical with only two levels, and the response variable is either categorical or numeric. This means that in this chapter, we’ll be focusing on comparing two groups.\nData like these may show up in a spreadsheet like\nFirst, we’ll consider situations in which two categorical variables are measured on each unit in the sample, and each variable has two possible values. In cases like these, typically one variable is considered the response and one variable is considered explanatory. The explanatory variable may be randomly assigned (like whether a subject was assigned to a treatment or control) or it may be merely observed (like smoking status).\nThe two possible values of the explanatory variable lead to two groups, and we’re interested in comparing the population proportions that arise from these two groups. We’ll focus on the function of parameters \\(p_1 - p_2\\). The natural estimate of this is \\(\\hat{p_1} - \\hat{p_2}\\): the difference in the sample proportions. We’ll be constructing hypothesis tests to compare \\(p_1\\) to \\(p_2\\) and finding confidence intervals to estimate \\(p_1 - p_2\\). To demonstrate these methods, we’ll use an example.\nExample: Biologists studying crows will capture a crow, tag it, and release it. These crows seem to remember the scientists who caught them and will scold them later. A study to examine this effect had several scientists wear a caveman mask while they trapped and tagged 7 crows. A control group did not tag any crows and wore a different mask. The two masks did not elicit different reactions from the crows before tagging. Volunteers then strolled around town wearing one or the other of the two masks.The crows scolded a person wearing a caveman mask in 158 out of 444 encounters with crows, whereas crows scolded a person in a neutral mask in 109 out of 922 encounters. Suppose we want to find a confidence interval for the difference in proportion of crow scoldings between volunteers wearing the caveman mask and those wearing the neutral mask.\nFor a single proportion, we needed two conditions to be met to ensure the sampling distribution of \\(\\hat{p}\\) is approximately normal:\nIf these conditions are met, then\nWe must meet similar conditions to ensure the sampling distribution of \\(\\hat p_1 - \\hat p_2\\) is approximately normal:\nIf these conditions are met, then\nLike before we don’t know \\(p_1\\) and \\(p_2\\), so we’ll use our best guess. And, like before, our best guess will change depending on whether we’re constructing a confidence interval or carrying out a hypothesis test.\nHow is this going to play out in a confidence interval?\nLet’s go back to the crows.\nHow is this going to play out in a hypothesis test?\nAgain, let’s go back to the crows.\nWe can also do this is R or SAS, but either program will use a different (but also not really) approach. We’ll start with R.\nprop.test(x=c(158,109), n=c(444,922))\n\n\n    2-sample test for equality of proportions with continuity correction\n\ndata:  c(158, 109) out of c(444, 922)\nX-squared = 106.11, df = 1, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n95 percent confidence interval:\n 0.1867976 0.2884716\nsample estimates:\n   prop 1    prop 2 \n0.3558559 0.1182213\nFrom this output, what looks familiar?\nWhat doesn’t look familiar?\nBut is this what we actually tested?\nprop.test(x=c(158,109), n=c(444,922),alternative=\"greater\",correct=FALSE)\n\n\n    2-sample test for equality of proportions without continuity correction\n\ndata:  c(158, 109) out of c(444, 922)\nX-squared = 107.62, df = 1, p-value &lt; 2.2e-16\nalternative hypothesis: greater\n95 percent confidence interval:\n 0.196371 1.000000\nsample estimates:\n   prop 1    prop 2 \n0.3558559 0.1182213\nWhat do you notice?\nIn SAS, we can use proc freq. First, we’ll need to read in the data.\nHere’s the data set\nNow, to get the test\nwhich gives\nWhy do both R and SAS carry out the procedure like this? This is a method that can be used in situations where both the explanatory and response variable have any number (\\(\\geq 2\\)) possible values. We’ll see examples like this in the next chapter.\nBut! The methods are actually doing the same thing. Let’s look at the test we carried out by hand.\nExample: Do metal tags on penguins harm them? Scientists trying to tell penguins apart have several ways to tag the birds. One method involves wrapping metal strips with ID numbers around the penguin’s flipper, while another involves electronic tags. Neither tag seems to physically harm the penguins. However, since tagged penguins are used to study all penguins, scientists wanted to determine whether the tagging method has any effect. Data were collected over a 10-year time span from a sample of 100 penguins that were randomly given either metal or electronic tags. Information collected includes number of chicks, survival over the decade, and length of time on foraging trips. Let’s first consider survival. We’re interested in estimating the difference in survival rate between penguins with metal tags and penguins with electronic tags.\nWhat parameters are of interest here?\nWhat kind of research question are we trying to answer? What does this imply about the analysis method?\nWhat next?\nLet’s do the analysis in R.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>One Predictor/Explanatory Variable, Two Levels</span>"
    ]
  },
  {
    "objectID": "Section 4 One Pred Two Levels.html#categorical-response-two-levels",
    "href": "Section 4 One Pred Two Levels.html#categorical-response-two-levels",
    "title": "4  One Predictor/Explanatory Variable, Two Levels",
    "section": "",
    "text": "data crows;\n  input mask $ NumScold Total;\n  response=\"Scold\"; Count=NumScold;  output;\n  response=\"NoScold\"; Count=Total-NumScold; output;\n  datalines;\nCaveman 158 444\nNeutral 109 922\n;\n\nproc print data=crows; run;\n\n                                         Num\n                      Obs     mask      Scold    Total    response    Count\n\n                       1     Caveman     158      444      Scold       158\n                       2     Caveman     158      444      NoSco       286\n                       3     Neutral     109      922      Scold       109\n                       4     Neutral     109      922      NoSco       813\n\nproc freq data=crows;\n  weight Count;\n  table mask*response/chisq;\nrun;\n\n\n\n\nOutput from proc freq",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>One Predictor/Explanatory Variable, Two Levels</span>"
    ]
  },
  {
    "objectID": "Section 4 One Pred Two Levels.html#quantitative-response",
    "href": "Section 4 One Pred Two Levels.html#quantitative-response",
    "title": "4  One Predictor/Explanatory Variable, Two Levels",
    "section": "4.2 Quantitative Response",
    "text": "4.2 Quantitative Response\nExample: Data were collected over a 10-year time span from a sample of 100 penguins that were randomly given either metal or electronic tags. Information collected includes number of chicks, survival over the decade, and length of time on foraging trips. Now let’s focus on length of foraging trips. Longer foraging trips can jeopardize both breeding success and survival of chicks waiting for food. Suppose we’re interested in estimating the difference in mean trip length between penguins with metal tags and those with electronic tags.\nWhat are the parameters?\n\n\n\n\nWhat kind of research question are we trying to answer? What does this imply about the analysis method?\n\n\n\n\n\n\nWhat’s different from the crows example?\n\n\n\n\n\nThis means we will have to change our analysis approach.\nJust like with the \\(t\\) methods for single means, we need to check conditions to determine whether we can the \\(t\\)-distribution to construct tests and form confidence intervals for the difference in means.\n\nIndependence–both between and within groups\nCheck normality of each group separately (basically checking for extreme outliers)\nIf these are both met, then the standard error of \\(\\bar x_1 - \\bar x_2\\) is \\(SE = \\sqrt{\\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma^2_2}{n_2}}\\) with \\(df=\\) really complicated (you’ll see we get non-integers in R/SAS–it’s doing the complicated calculation). We’ll use \\(\\min(n_1-1, n_2-1)\\) if we’re not using R/SAS. We won’t know \\(\\sigma^2_1\\) and \\(\\sigma_2^2\\), so we’ll approximate the standard error using \\(SE \\approx \\sqrt{\\frac{s_1^2}{n_1} + \\frac{s^2_2}{n_2}}\\)\n\n\n\n\n\n\nAs with tests for a single mean (and one proportion, and two proportions), our test statistic will have the usual form: \\[\n\\hbox{test statistic} = \\frac{\\hbox{observed value - hypothesized value}}{SE}\n\\] In the case of two means, this is \\[\nT = \\frac{(\\bar x_1 - \\bar x_2) - 0}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}}\n\\] When the null hypothesis is true and the conditions are met, \\(T\\) has a \\(t\\)-distribution with \\(df=\\min(n_1-1,n_2-1)\\).\nConfidence intervals will also have the same form: \\[\n\\hbox{observed statistic} \\pm \\hbox{multiplier} \\times SE\n\\] For this specific situation of comparing two independent means, this is \\[\n(\\bar x_1 - \\bar x_2) \\pm t^*_{df} \\times \\sqrt{\\frac{s_1^2}{n_1} + \\frac{s^2_2}{n_2}}\n\\] and we’ll again use \\(df=\\min(n_1-1,n_2-1)\\) (or let R/SAS calculate it for us).\nWith two proportions, our SE changed depending on whether we were doing a hypothesis test or calculating a confidence interval. Here, it doesn’t. Any guesses why?\n\n\n\n\nExample: There were 344 foraging trips made by penguins with a metal tag, and those trips had a sample mean of \\(\\bar x_{M} =12.70\\) days with standard deviation \\(s_{M}=3.71\\) days. For those penguins with electronic tags, the mean was \\(\\bar x_{E} = 11.60\\) days with standard deviation \\(s_{E}=4.53\\) days over 512 trips.\n\n\n\n\n\n\n\n\n\n\nExample: Another variable measured was the date penguins arrive at the breeding site, with later arrivals hurting breeding success. Arrival date is measured as the number of days after 1 November. The researchers are interested in whether metal tagged penguins arrive later than electronic tagged penguins.\nWhat are the parameters?\n\n\n\n\nWhat kind of research question are we trying to answer? What does this imply about the analysis method?\n\n\n\n\n\n\n\n\nMean arrival date for the 167 times metal tagged penguins arrived was 7 December (37 days after 1 November) with standard deviation \\(s_{M}=38.77\\) days, while mean arrival date for the 189 times electronic tagged penguins arrived was 21 November (21 days after 1 November) with standard deviation \\(s_{E}=27.50\\)\n\n\n\n\n\n\n\n\n\n\nWe can easily carry out \\(t\\) tests and confidence intervals in R and SAS. But, we can’t for the penguin data. R and SAS both require the whole data set, as opposed to summary statistics.\nExample: The data set may be found in Canvas: ‘NutritionStudy.csv’. This data set gives nutrition levels in people’s blood as well as information about their eating habits, and comes from a random sample of 315 US adults. Suppose we are interested in estimating the difference in mean beta carotene blood level between smokers and non-smokers. Let’s start by reading the data into R.\n\nNutritionStudy&lt;-read.csv(\"NutritionStudy.csv\",header=TRUE)\n\nhead(NutritionStudy)\n\n  ID Age Smoke Quetelet Vitamin Calories  Fat Fiber Alcohol Cholesterol\n1  1  64    No  21.4838       1   1298.8 57.0   6.3     0.0       170.3\n2  2  76    No  23.8763       1   1032.5 50.1  15.8     0.0        75.8\n3  3  38    No  20.0108       2   2372.3 83.6  19.1    14.1       257.9\n4  4  40    No  25.1406       3   2449.5 97.5  26.5     0.5       332.6\n5  5  72    No  20.9850       1   1952.1 82.6  16.2     0.0       170.8\n6  6  40    No  27.5214       3   1366.9 56.0   9.6     1.3       154.6\n  BetaDiet RetinolDiet BetaPlasma RetinolPlasma    Sex VitaminUse PriorSmoke\n1     1945         890        200           915 Female    Regular          2\n2     2653         451        124           727 Female    Regular          1\n3     6321         660        328           721 Female Occasional          2\n4     1061         864        153           615 Female         No          2\n5     2863        1209         92           799 Female    Regular          1\n6     1729        1439        148           654 Female         No          2\n\n\nIf I wanted to calculate the confidence interval by hand, I could use R to get the summary statistics\n\nNutMeanNS&lt;-mean(NutritionStudy$BetaPlasma[NutritionStudy$Smoke==\"No\"])\nNutMeanNS\n\n[1] 200.7316\n\nNutSDNS&lt;-sd(NutritionStudy$BetaPlasma[NutritionStudy$Smoke==\"No\"])\nNutSDNS\n\n[1] 192.2929\n\nsize_NS&lt;-sum(with(data=NutritionStudy, Smoke==\"No\"))\nsize_NS\n\n[1] 272\n\nNutMeanS&lt;-mean(NutritionStudy$BetaPlasma[NutritionStudy$Smoke==\"Yes\"])\nNutMeanS\n\n[1] 121.3256\n\nNutSDS&lt;-sd(NutritionStudy$BetaPlasma[NutritionStudy$Smoke==\"Yes\"])\nNutSDS\n\n[1] 78.81163\n\nsize_S&lt;-sum(with(data=NutritionStudy, Smoke==\"Yes\"))\nsize_S\n\n[1] 43\n\n\nSo now we have all the components we need to calculate the confidence interval.\n\n\n\n\n\n\n\n\n\n\n\n\nWe can also let R calculate the confidence interval for us, using t.test:\n\nt.test(BetaPlasma~Smoke,data=NutritionStudy)\n\n\n    Welch Two Sample t-test\n\ndata:  BetaPlasma by Smoke\nt = 4.7421, df = 139.15, p-value = 5.175e-06\nalternative hypothesis: true difference in means between group No and group Yes is not equal to 0\n95 percent confidence interval:\n  46.29873 112.51335\nsample estimates:\n mean in group No mean in group Yes \n         200.7316          121.3256 \n\n\nWe can change the confidence level easily\n\nt.test(BetaPlasma~Smoke,data=NutritionStudy, conf.level=0.90)\n\n\n    Welch Two Sample t-test\n\ndata:  BetaPlasma by Smoke\nt = 4.7421, df = 139.15, p-value = 5.175e-06\nalternative hypothesis: true difference in means between group No and group Yes is not equal to 0\n90 percent confidence interval:\n  51.67854 107.13353\nsample estimates:\n mean in group No mean in group Yes \n         200.7316          121.3256 \n\n\nLet’s carry out a test by hand, to see how it compares to the output.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>One Predictor/Explanatory Variable, Two Levels</span>"
    ]
  },
  {
    "objectID": "Section 4 One Pred Two Levels.html#comparing-paired-means",
    "href": "Section 4 One Pred Two Levels.html#comparing-paired-means",
    "title": "4  One Predictor/Explanatory Variable, Two Levels",
    "section": "4.3 Comparing Paired Means",
    "text": "4.3 Comparing Paired Means\nEverything we’ve done so far has assumed independence among observations. If we only had one group, it was just independence among observations. If we had two or more groups, it was independence between and within groups. Now, we’ll turn our attention to a common situation: dependence between groups. Specifically, a particular dependency–pairing. This occurs in before/after studies, other studies in which subjects are matched. For example, considering the price of a item purchased from two different retailers.\nIn these situations, we generally take the difference between the two values, and consider the difference as our observation. So, for example, if we want to compare cost of textbooks between the campus bookstore and Amazon, we’d randomly select a set of book titles, and find their price at both the bookstore and Amazon. We’d find the difference in price, and use those differences as our observations.\nNote that we’re distinguishing between and .\nGood news: we’ve already seen how to construct tests and confidence intervals here! We just use the same techniques we used for a single mean (Chapter 3), but on the differences. The changes come in the form of the hypotheses and interpretation of the confidence interval.\nExample: Long distance runners contend that moderate exposure to ozone increases lung capacity. In investigate this possibility, a researcher exposed 12 rats to ozone at the rate of 2 ppm for a period of 30 days. The lung capacity of the rats was determined at the beginning of the study and again after 30 days of ozone exposure. The lung capacities (in mL) are in the file ‘ozone.csv’.\n\nozone&lt;-read.csv(\"ozone.csv\",header=TRUE)\n\nhead(ozone)\n\n  Rat Before After\n1   1    8.7   9.4\n2   2    7.9   9.8\n3   3    8.3   9.9\n4   4    8.4  10.3\n5   5    9.2   8.9\n6   6    9.1   8.8\n\n\nThe first thing we’ll do is calculate the change in lung capacity.\n\nozone$diff&lt;-ozone$Before - ozone$After\n\nhead(ozone)\n\n  Rat Before After diff\n1   1    8.7   9.4 -0.7\n2   2    7.9   9.8 -1.9\n3   3    8.3   9.9 -1.6\n4   4    8.4  10.3 -1.9\n5   5    9.2   8.9  0.3\n6   6    9.1   8.8  0.3\n\n\nWhat is the parameter?\n\n\n\n\nWhat research question are we trying to answer?\n\n\n\n\nWhat does this imply about the analysis method we should use?\n\n\n\n\n\n\n\nt.test(ozone$diff)\n\n\n    One Sample t-test\n\ndata:  ozone$diff\nt = -3.885, df = 11, p-value = 0.002541\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n -1.8928932 -0.5237735\nsample estimates:\nmean of x \n-1.208333 \n\n\n\n\nt.test(ozone$Before,ozone$After,paired=TRUE)\n\n\n    Paired t-test\n\ndata:  ozone$Before and ozone$After\nt = -3.885, df = 11, p-value = 0.002541\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -1.8928932 -0.5237735\nsample estimates:\nmean difference \n      -1.208333 \n\n\nWhat is incorrect about this analysis in R? How can we fix it?\n\n\n\n\n\n\nt.test(ozone$Before,ozone$After,paired=TRUE,alternative=\"less\")\n\n\n    Paired t-test\n\ndata:  ozone$Before and ozone$After\nt = -3.885, df = 11, p-value = 0.001271\nalternative hypothesis: true mean difference is less than 0\n95 percent confidence interval:\n       -Inf -0.6497695\nsample estimates:\nmean difference \n      -1.208333 \n\n\nLet’s write a couple of conclusions here.\n\nWhat are the consequences of ignoring pairing? Let’s look at a different example.\nExample: Suppose you are playing baseball and hit a hard line drive. You want to turn a single into a double. Does the path you take to round first base make a difference? A masters thesis way back in 1970 considered the difference between a “narrow angle” and a “wide angle” around first base. Suppose we have 22 baseball players who have volunteered to participate. There are a couple ways we could design an experiment to see if there is a difference.\n\nRandomly assign 11 players to run a wide angle and 11 players to run a narrow angle. Problems: some players may be faster than others. Ideally, randomization will equally distribute the speedy runners between the two groups, but there is no guarantee. Speed could be a confounding variable.\nHave each of the 22 runners run both angles, with the angle run first randomized using a coin. This allows each player to serve as their own control.\n\nThe second option is what the thesis writer did–he randomly determined the angle the player would take first. He then used a stopwatch the time the run from going from a spot 35 feet past home to a spot 15 feet before 2nd base. After a rest period, the runner then ran the second angle. This controls for runner-to-runner variability. It’s important to randomize the order of the treatments, where possible! (This isn’t possible in before-and-after type studies.)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[1] 0.075\n\n\nParameter of interest:\nHypotheses of interest:\n\n\n\n\n\nObserved statistic:\nLike before, we’re trying to determine if it’s surprising to see such a large difference as \\(\\bar x_d = 0.075\\) just by chance, if running strategy has no effect on running time.\n\nt.test(bases$diff)\n\n\n    One Sample t-test\n\ndata:  bases$diff\nt = 3.9837, df = 21, p-value = 0.0006754\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n 0.03584814 0.11415186\nsample estimates:\nmean of x \n    0.075 \n\nt.test(time~angle,data=bases2)\n\n\n    Welch Two Sample t-test\n\ndata:  time by angle\nt = 0.93383, df = 41.899, p-value = 0.3557\nalternative hypothesis: true difference in means between group narrow and group wide is not equal to 0\n95 percent confidence interval:\n -0.08709334  0.23709334\nsample estimates:\nmean in group narrow   mean in group wide \n            5.534091             5.459091",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>One Predictor/Explanatory Variable, Two Levels</span>"
    ]
  },
  {
    "objectID": "Section 4 One Pred Two Levels.html#comparing-variances",
    "href": "Section 4 One Pred Two Levels.html#comparing-variances",
    "title": "4  One Predictor/Explanatory Variable, Two Levels",
    "section": "4.4 Comparing Variances",
    "text": "4.4 Comparing Variances\nOften it is useful to test if variances from independent populations are different. For example,\n\na geneticist wants to test equality of the genotypic variances of kernel weight of two different corn populations\nan engineer is interested in comparing the process variance of two different types of production systems used to make a electronic component\nthe two-sample \\(t\\)-test is based on the assumption that the variances of the two populations are equal\n\nAssume the data from both populations follow a normal distribution with different means and possibly different variances. We want to test\n\n\n\n\n\nA natural approach would be to take samples of \\(n_1\\) and \\(n_2\\) observations from the two populations, and compute \\(s_1^2\\) and \\(s_2^2\\). We could then take the ratio \\(s_1^2/s_2^2\\) and reject H\\(_0\\) if the ratio is very different from 1. But, we need to know the sampling distribution of the ratio \\(S^2_1/S^2_2\\). Recall\n\n\n\n\n\n\nSir R. A. Fisher showed that the ratio of two independent \\(\\chi^2\\) distributions has an \\(F\\) distribution with \\((n_1-1)\\) and \\((n_2-1)\\) degrees of freedom. Specifically,\n\n\n\n\n\nUnder H\\(_0: \\sigma^2_1 = \\sigma^2_2\\) then\n\n\n\nThe \\(F\\) distribution\n\nis non-negative, unimodal, and right skewed\n\n\n\n\n\n\n\n\n\n\n\nthe shape of the distribution depends on the numerator and denominator degrees of freedom\n\nSo, to test H\\(_0: \\sigma_1^2 = \\sigma_2^2\\) versus H\\(_a: \\sigma_1^2 \\neq \\sigma_2^2\\), we can\n\nAssume that \\(S_1^2\\) is the larger of the two sample variaces\nUse \\(S_1^2/S_2^2\\) as a test statistic. Under H\\(_0\\), this ratio will follow an \\(F\\) distribution with \\(n_1-1\\) and \\(n_2-1\\) degrees of freedom\nUse the \\(F\\) distribution to see if \\(s_1^2/s_2^2\\) is enough bigger than 1 to convince us the null hypothesis is not true (always a right-tail test!)\n\nExample: The writings of different authors can be partially characterized by the variablity in the lengths of their sentences. Two manuscripts, \\(A\\) and \\(B\\), are found by a historian and they want to know whether they have the same author. Fifteen sentences from each are chosen at random, and word counts per sentence are recorded. The historian finds \\(s_A^2= 0.114\\) and \\(s_B^2= 0.143\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can use var.test() in R, but must have the whole data set.\nExample: Earlier, we used a data set with nutrition levels in people’s blood as well as information about their eating habits that came from a random sample of 315 US adults.\n\nNutritionStudy&lt;-read.csv(\"NutritionStudy.csv\",header=TRUE)\n\nhead(NutritionStudy)\n\n  ID Age Smoke Quetelet Vitamin Calories  Fat Fiber Alcohol Cholesterol\n1  1  64    No  21.4838       1   1298.8 57.0   6.3     0.0       170.3\n2  2  76    No  23.8763       1   1032.5 50.1  15.8     0.0        75.8\n3  3  38    No  20.0108       2   2372.3 83.6  19.1    14.1       257.9\n4  4  40    No  25.1406       3   2449.5 97.5  26.5     0.5       332.6\n5  5  72    No  20.9850       1   1952.1 82.6  16.2     0.0       170.8\n6  6  40    No  27.5214       3   1366.9 56.0   9.6     1.3       154.6\n  BetaDiet RetinolDiet BetaPlasma RetinolPlasma    Sex VitaminUse PriorSmoke\n1     1945         890        200           915 Female    Regular          2\n2     2653         451        124           727 Female    Regular          1\n3     6321         660        328           721 Female Occasional          2\n4     1061         864        153           615 Female         No          2\n5     2863        1209         92           799 Female    Regular          1\n6     1729        1439        148           654 Female         No          2\n\n\nThe Quetelet index is a measure of body mass (BMI). Suppose we are interested in whether smokers and nonsmokers have the same variability of BMI scores.\n\n\n\n\n\n\nvar.test(Quetelet~Smoke,data=NutritionStudy)\n\n\n    F test to compare two variances\n\ndata:  Quetelet by Smoke\nF = 1.563, num df = 271, denom df = 42, p-value = 0.08157\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.9438906 2.3908039\nsample estimates:\nratio of variances \n          1.563047 \n\n\nNow that we’ve covered one predictor variable with two levels, we can move on to one predictor variable with more than 2 levels.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>One Predictor/Explanatory Variable, Two Levels</span>"
    ]
  },
  {
    "objectID": "Section 5 One Pred More Than Two Levels.html",
    "href": "Section 5 One Pred More Than Two Levels.html",
    "title": "5  One Predictor/Explanatory Variable, More Than Two Levels",
    "section": "",
    "text": "5.1 Categorical Response, More Than Two Levels\nAs mentioned at the end of Chapter 4, we’ll now move on to cases in which we have a single explanatory variable and a single response variable. In this section, we’ll cover the case where the explanatory variable is categorical with more than two levels, and the response variable is either categorical or numeric. This means that in this chapter, we’ll be focusing on comparing more than two groups\nData like these may show up in a spreadsheet like\nFirst, we’ll consider situations in which two categorical variables are measured on each unit in the sample, and each variable has potentially more than two possible values. Many categorical variables have more than two possible outcomes, so we can’t easily define the proportion of “successes.” Instead, we’ll summarize categorical data with more than two levels using two-way tables. In this class, we’re still going to restrict ourselves to only two variables (often explanatory and response, but not necessarily), both with two or more levels. However, there are certainly statistical methods for more complicated situations.\nTypically, research questions focus on how the proportions of the possible outcomes in the response variable change (or don’t) across the levels of the explanatory variable. However, we can also consider questions about a single variable with more than two outcomes (are the possible outcomes all equally likely? do the possible outcomes follow a particular pattern? We’ve already seen these!) or just whether the two categorical variables are independent or dependent without assigning an explanatory/response relationship. Due to the structure of the variable(s), there really isn’t a population parameter of interest. We can’t (usually) make a function of proportion of successes that makes sense to estimate, like we can with \\(p_1 - p_2\\). That means we’ll be considering only tests, not confidence intervals.\nExample: When surveys are administered, we hope that the respondents give accurate answers. Does the mode of survey delivery affect this? Schober et al (2015) investigated this question. They had 147 people who agreed to be interviewed on an iPhone, and they were randomly assigned to one of three interview modes: human voice, automated voice, text. One question asked was whether they exercise less than once per week during a typical week (a yes is mostly likely considered socially undesirable). The explanatory variable here is survey mode and the response is whether or not the respondent said yes. Here are the data:\nBased on these data, it looks like the answer to the question does change depending on survey mode, with respondents more likely to say yes via text. However, we don’t know if this result could have happened by chance.\nWe saw expected counts when we did \\(\\chi^2\\) goodness of fit tests. We’ll need to find them again here. We don’t expect the proportion of ‘yes’ to be exactly the same across all survey modes, but we want to know if these vary enough to convince us that survey mode and answer are not independent. To do this, we need to find expected counts for each cell in the table.\nSo, \\[\n\\hbox{Expected Count}_{\\hbox{row } i, \\hbox{col } j} = \\frac{(\\hbox{row } i \\hbox{ total})(\\hbox{col } j \\hbox{ total})}{\\hbox{table total}}\n\\]\nSo just like with the goodness-of-fit test, the key question is whether the observed and expected cell counts are different enough.\nOur \\(\\chi^2\\) test statistic gets just a little more complicated:\nIn our example:\nWe already know this test statistic will follow a \\(\\chi^2\\) distribution, but now\nAgain, we have conditions that need to be met for the \\(\\chi^2\\) distribution to work:\nExample: First, we’ll need to check the conditions:\nTo find the p-value, we can use pchisq(6.1971,df=2,lower.tail=FALSE) =\nWe can also do the test directly in R:\nsurveymodetable&lt;-read.csv(\"surveymodetable.csv\",row.names=1)\nsurveymodetable\n\n    Text Hvoice Avoice\nYes   34     21     20\nNo   124    139    139\n\nchisq.test(surveymodetable)\n\n\n    Pearson's Chi-squared test\n\ndata:  surveymodetable\nX-squared = 6.0069, df = 2, p-value = 0.04962\nExample: Integrated Pest Management (IPM) adopters apply significantly less insecticides and fungicides than nonadopters among grape producers. A 2008 paper published in Agricultural Economics gave data on IPM adoption rates for the six states that accounted for most of the US grape production. The data are in the file ‘ipmtable.csv’.\nipmtable&lt;-read.csv(\"ipmtable.csv\",row.names=1)\nipmtable\n\n         Cal Mich NewYork Oregon Penn Wash\nAdopted   39   55      19     22   24   30\nNotAdopt  92   69     114     88   83   77\nchisq.test(ipmtable)\n\n\n    Pearson's Chi-squared test\n\ndata:  ipmtable\nX-squared = 34.59, df = 5, p-value = 1.816e-06\nExample: A study of drinking habits of college students at a particular college produced the two-way table found in ‘drinkingtable.csv’ and shown below. Students were randomly selected to participate in the survey.\ndrinktable&lt;-read.csv(\"drinkingtable.csv\",row.names=1)\ndrinktable\n\n              OnCampus OffNoParents OffWithParents\nAbstain             46           17             43\nLightModerate      126           72             68\nHeavy              130           52             32\nWhat’s different about this example?\nThis leads to hypotheses\nchisq.test(drinktable)\n\n\n    Pearson's Chi-squared test\n\ndata:  drinktable\nX-squared = 28.949, df = 4, p-value = 8.007e-06",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>One Predictor/Explanatory Variable, More Than Two Levels</span>"
    ]
  },
  {
    "objectID": "Section 5 One Pred More Than Two Levels.html#categorical-response-more-than-two-levels",
    "href": "Section 5 One Pred More Than Two Levels.html#categorical-response-more-than-two-levels",
    "title": "5  One Predictor/Explanatory Variable, More Than Two Levels",
    "section": "",
    "text": "Survey Mode Data\n\n\n\nText\nHuman Voice\nAutomated Voice\nTotal\n\n\n\n\nExercise Yes\n34\n21\n20\n75\n\n\nExercise No\n124\n139\n139\n402\n\n\nTotal\n158\n160\n159\n477\n\n\n\n\n\n\n\n\n\n\nSurvey Model Data with Expected Counts\n\n\n\n\n\n\n\n\n\n\n\nHuman\nAutomated\n\n\n\n\nText\nVoice\nVoice\nTotal\n\n\nExercise Yes\n34 (________)\n21 (________)\n20 (_________)\n75\n\n\nExercise No\n124 (________)\n139 (________)\n139 (________)\n402\n\n\nTotal\n158\n160\n159\n477\n\n\n\n\n\nCell(1,1) obs - exp = 34 -\nCell(1,2) obs - exp = 21 -\nCell(1,3) obs - exp = 20 -\nCell(2,1) obs - exp = 124 -\nCell(2,2) obs - exp = 139 -\nCell(2,3) obs - exp = 139 -\n\n\n\n\n\n\n\nCell(1,1) (obs - exp)\\(^2\\)/exp = \\((34 - 24.84)^2/(24.84) = 9.16^2/24.84 = 3.3778\\)\nCell(1,2) (obs - exp)\\(^2\\)/exp = \\((21 - 25.16)^2/(25.16) = (-4.16)^2/25.16 = 0.6878\\)\nCell(1,3) (obs - exp)\\(^2\\)/exp = \\((20 - 25)^2/(25) = (-5)^2/25 = 1\\)\nCell(2,1) (obs - exp)\\(^2\\)/exp = \\((124 - 133.16)^2/(133.16) = (-9.16)^2/133.16 = 0.6301\\)\nCell(2,2) (obs - exp)\\(^2\\)/exp = \\((139 - 134.84)^2/(134.84) = 4.16^2/134.84 = 0.1283\\)\nCell(2,3) (obs - exp)\\(^2\\)/exp = $(139 - 134)^2/(134) = 5^2/134 =0.3731 $\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDrinking habits of college students\n\n\n\n\n\n\n\n\n\n\nReside on\nReside off campus,\nReside off campus,\n\n\n\n\ncampus\nnot with parents\nwith parents\nTotal\n\n\nAbstain from drinking\n46\n17\n43\n106\n\n\nLight or moderate drinking\n126\n72\n68\n266\n\n\nHeavy drinking\n130\n52\n32\n214\n\n\nTotal\n302\n141\n143\n586",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>One Predictor/Explanatory Variable, More Than Two Levels</span>"
    ]
  },
  {
    "objectID": "Section 5 One Pred More Than Two Levels.html#quantitative-response",
    "href": "Section 5 One Pred More Than Two Levels.html#quantitative-response",
    "title": "5  One Predictor/Explanatory Variable, More Than Two Levels",
    "section": "5.2 Quantitative Response",
    "text": "5.2 Quantitative Response\nWe’re going to start this section by considering an example. The data are in the file ‘mice.csv.’\nExample: These data come from an experiment to determine if exercise confers some resilience to stress. Mice were randomly assigned to either an enriched environment (exercise wheel) or standard environment, and spent three weeks there. After that time, they were exposed for five minutes per day for two weeks to a ``mouse bully’’–a mouse very strong, aggressive, and territorial. After those two weeks, anxiety in the mice was measured, as amount of time hiding in dark compartment. Mice that are more anxious spend more time in darkness. We want to determine if there is a difference in time spent in darkness for the two groups of mice.\n\nmice&lt;-read.csv(\"mice.csv\",header=TRUE)\nhead(mice)\n\n    Envr Time\n1 Enrich  259\n2 Enrich  280\n3 Enrich  138\n4 Enrich  227\n5 Enrich  203\n6 Enrich  184\n\n\nWe already know how to answer this research question!\n\n\n\n\n\n\n\n\n\nLet’s first plot the data\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\n\n\n\n\n\n\nIt definitely looks like there’s a difference between the groups! We can find the group means and standard deviations. We’ll also add the sample means to the plot.\n\naggregate(mice$Time, by=list(mice$Envr), FUN=mean)\n\n  Group.1        x\n1  Enrich 217.4286\n2     Std 438.7143\n\naggregate(mice$Time, by=list(mice$Envr), FUN=sd)\n\n  Group.1        x\n1  Enrich 47.52844\n2     Std 37.68162\n\n\n\n\n\n\n\n\n\n\n\nWe’re testing H\\(_0: \\mu_1 = \\mu_2\\), and assume this is true to construct the test. The overall common sample mean is \\(\\bar x = 328.07\\).\n\nt.test(Time~Envr,data=mice)\n\n\n    Welch Two Sample t-test\n\ndata:  Time by Envr\nt = -9.6526, df = 11.407, p-value = 7.885e-07\nalternative hypothesis: true difference in means between group Enrich and group Std is not equal to 0\n95 percent confidence interval:\n -271.5245 -171.0470\nsample estimates:\nmean in group Enrich    mean in group Std \n            217.4286             438.7143 \n\n\n\n\n\n\n\n\n\n\n\nIt turns out the difference between the two groups will also manifest itself in the variances. There will be variation between the group means and the overall mean, as well as variation between the data points and their group means.\nRemember how sample variance is calculated:\n\n\n\n\n\n\nWe’re exploring how far, on average, observations are from the mean (squared). So, variance has to be positive. If there is a difference between the group means, the first kind of variation (between the group means and the overall mean) will be much greater than the second kind of variance (between the data points and their group mean). We can test whether the first variance is bigger than the second using an F statistic, just like we did in the last section when we were comparing two variances:\n\\[\nF = \\frac{\\hbox{variance between group means and overall mean}}{\\hbox{variance between the data points and their group mean}}\n\\]\nIf the variances are about equal, there’s no evidence of a difference between the group means–they vary as much from the overall mean as data points vary from their group mean. This will result in an F statistic of about 1. If there is a difference between the group means, the first kind of variation (between the group means and the overall mean) will be much greater than the second kind of variance (between the data points and their group mean). This will result in an F statistic greater than 1.\n\nFor the mice data:\n\n\n\n\n\nNotice!\n\n\n\n\n\nWe made some assumptions to carry out the \\(t\\)-test:\n\napproximate normality (no extreme outliers, no strong skew)\nindependence between groups and between observations\nconstant variance (we didn’t make a big deal of this one, but mentioned it)\n\nWe can summarize these assumptions very succinctly, and to do so we’re going to introduce some new notation.\nConsider a random sample of observations from a normal distribution with mean \\(\\mu\\) and variance \\(\\sigma^2\\). If we let \\(Y_1, Y_2,\\dots, Y_n\\) represent our data points we can summarize this as:\n\n\n\n\nOr another way:\n\n\n\n\n\n\n\n\n\nThis is a statistical model with 2 parameters: \\(\\mu\\) and \\(\\sigma^2\\).\n\n\n\n\nIf we have two samples:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIf we have more than two samples:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLet’s start with some summary statistics \\[\\begin{eqnarray*}\n    Y_{i\\cdot} &=& \\sum_{j=1}^{n_i} Y_{ij} = i^{th} \\hbox{ sample total} \\\\\n    \\bar Y_{i\\cdot} &=& \\frac{1}{n_i} \\sum_{j=1}^{n_i} Y_{ij} = i^{th} \\hbox{ sample mean} \\\\\n    Y_{\\cdot \\cdot} &=& \\sum_{i=1}^{t} \\sum_{j=1}^{n_i} Y_{ij} = \\hbox{ grand total} \\\\\n    \\bar Y_{\\cdot \\cdot} &=& \\frac{1}{N} \\sum_{i=1}^{t} \\sum_{j=1}^{n_i} Y_{ij} = \\hbox{ grand mean  } (N=\\sum_{i=1}^{n_i} n_i)\n\\end{eqnarray*}\\]\n\nExample: A student carried out an experiment to investigate handwashing methods: water only, regular soap, antibacterial soap, and alcohol spray. Each treatment was replicated 8 times, and bacteria count was observed. The data are in ‘handwash.csv’.\n\n\n\n\n\n\n\n\n\n  Group.1     x\n1  ABSoap  92.5\n2 Alcohol  37.5\n3    Soap 106.0\n4   Water 117.0\n\n\n  Group.1        x\n1  ABSoap 41.96257\n2 Alcohol 26.55991\n3    Soap 46.95895\n4   Water 31.13106\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRemember how to calculate the sample variance, \\(S^2 = \\frac{\\sum_{i=1}^n (y_i - \\bar y)^2}{n-1}\\). We’re going to look at three difference variances. Let’s assume for simplicity that \\(n_i = n\\) (all groups have equal sample size, this is not really necessary, it’s just to make it easier to look at notation):\n\nTotal Variance. Another name for the numerator is total sum of squares.\n\n\n\n\n\n\n\n\nError (Within-Group) Variance. Another name for the numerator is the error sum of squares.\n\n\n\n\n\n\n\n\n\n\n\n\nModel (Between-Group) Variance. Another name for the numerator is the treatment (model) sum of squares.\n\n\n\n\n\n\nTo see what this is measuring, first consider the ‘inside’ sum:\n\n\n\n\n\nThis is still an estimate of variance, but it’s an estimate of \\(\\sigma^2/n\\), because these are means. In order to be able to compare fairly to the error variance we must multiply by \\(n\\) (only works with equal sample sizes) or, equivalently, take the sum from \\(i=1\\) to \\(n\\):\n\n\n\n\nWe can’t lose sight of what we’re interested in here: testing H\\(_0: \\mu_1 = \\mu_2\\). If H\\(_0\\) is true, \\(\\bar y_1\\) and \\(\\bar y_2\\) should not be different from \\(\\bar y_{\\cdot \\cdot}\\). This means that error variance should be about equal to model variance (both would estimate \\(\\sigma^2\\)). If H\\(_0\\) is not true, model variance will be larger because of the deviations of the group averages from the grand average. If it’s much larger, this gives us evidence against H\\(_0\\).\nWhy do we worry about three variances when we only use two (error and model) to get the F stat? It turn out that: \\[\n\\hbox{Total SS } = \\hbox{Model SS } + \\hbox{ Error SS}\n\\] For the mice data:\n\\[\\begin{eqnarray*}\n        \\hbox{Total SS } &=& (259-328.07)^2 + \\cdots + (231-328.07)^2 + (394-328.07)^2 + \\cdots + (454-328.07)^2 = 193459 \\\\\n        \\hbox{Error SS } &=& (259-217.43)^2 + \\cdots + (231-217.43)^2 + (394-438.71)^2 + \\cdots + (454-438.71)^2 = 22073 \\\\\n        \\hbox{Model SS } &=& 6(217.43-328.07)^2 + 6(438.71-328.07)^2 =  171386 \\\\\n\\end{eqnarray*}\\]\nTo convert these sums of squares into variances (which we call mean squares), they must be divided by denominators noted above. These are degrees of freedom, and have the same relationship as the sums of squares do: \\[\n\\hbox{Total } df = \\hbox{ Model } df + \\hbox{ Error } df\n\\]\nIn our mice example, we have\n\\[\n\\hbox{Total } df = \\hbox{ Model } df + \\hbox{ Error } df\n\\]\n\n\n\n\nWe often summarize our calculations in a table (\\(df\\) assuming equal sample sizes):\n\n\n\nSource\n\\(df\\)\nSS\nMS\n\n\n\n\nModel\n\\(t-1\\)\nSSModel\nMSModel\n\n\nError\n\\(t(n-1)\\)\nSSError\nMSError\n\n\nTotal\n\\(nt-1\\)\nSSTotal\n\n\n\n\nThe MSError (usually called MSE) is our estimate of \\(\\sigma^2\\). In our mice example, we get the table:\n\n\n\nSource\n\\(df\\)\nSS\nMS\n\n\n\n\nModel\n1\n171386\n171386\n\n\nError\n12\n22073\n1839\n\n\nTotal\n13\n193459\n\n\n\n\nTo test H\\(_0: \\mu_1 = \\mu_2\\) we use the F stat: \\[\nF = \\frac{\\hbox{MSModel}}{\\hbox{MSError}} = \\frac{171386}{1839} = 93.2\n\\] and we can add this to the table:\n\n\n\nSource\n\\(df\\)\nSS\nMS\nF\n\n\n\n\nModel\n1\n171386\n171386\n93.2\n\n\nError\n12\n22073\n1839\n\n\n\nTotal\n13\n193459\n\n\n\n\n\nWhat we’ve just done is called an Analysis of Variance (ANOVA), and the resulting table is called an ANOVA table. It’s a single hypothesis test to check whether the means across many groups are equal. Specifically, it’s testing:\n\n\n\n\n\nWe still have assumptions: - Independence between and among groups - Responses/errors are approximately normal - Variability across groups is about equal\nWe already know how to determine if \\(F=93.2\\) is enough greater than 1 to determine there’s a difference–the \\(F\\) distribution we used to test the equality of two variances in the last section. Our numerator and denominator degrees of freedom will be the Model \\(df\\) and Error \\(df\\), respectively:\n\npf(93.2,df1=1,df2=12,lower.tail=FALSE)\n\n[1] 5.232224e-07\n\n\nThe p-value typically gets added to the table as well:\n\n\n\nSource\n\\(df\\)\nSS\nMS\nF\np-value\n\n\n\n\nModel\n1\n171386\n171386\n93.2\n0.0000005\n\n\nError\n12\n22073\n1839\n\n\n\n\nTotal\n13\n193459\n\n\n\n\n\n\n\nThis is the only time we’ll do an ANOVA by hand! Let’s do the same in R.\n\nanova(lm(Time~Envr, data=mice))\n\nAnalysis of Variance Table\n\nResponse: Time\n          Df Sum Sq Mean Sq F value   Pr(&gt;F)    \nEnvr       1 171386  171386  93.173 5.24e-07 ***\nResiduals 12  22073    1839                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nExample: Let’s now carry out the ANOVA on the handwashing data. We’ll start by writing the model and sketching the ANOVA table.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nanova(lm(Bacteria~Method,data=handwash))\n\nAnalysis of Variance Table\n\nResponse: Bacteria\n          Df Sum Sq Mean Sq F value   Pr(&gt;F)   \nMethod     3  29882  9960.7  7.0636 0.001111 **\nResiduals 28  39484  1410.1                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nWe could also use SAS:\nPROC IMPORT OUT= WORK.mice\nDATAFILE= \"C:\\Users\\Erin\\OneDrive - University of Nebraska-Lincoln\\STAT 801\\Book Notes\\mice.csv\"\nDBMS=CSV REPLACE;\nGETNAMES=YES;\nDATAROW=2; \nRUN;\n\nproc glimmix data=mice;\n  class Envr;\n  model Time=Envr;\nrun;\nSAS proc glimmix uses a different numerical method to calculate the ANOVA, and so the SSTrt/SSError don’t exist in the same way.\n\nFor the handwash data:\n\nPROC IMPORT OUT= WORK.handwash\nDATAFILE= \"C:\\Users\\Erin\\OneDrive - University of Nebraska-Lincoln\\STAT 801\\Book Notes\\handwash.csv\"\nDBMS=CSV REPLACE;\nGETNAMES=YES;\nDATAROW=2; \nRUN;\n\nproc glimmix data=handwash;\n  class Method;\n  model Bacteria=Method;\nrun;\n\nThe reason I like SAS for ANOVA is because we can easily add fanciness:\nproc glimmix data=handwash;\n  class Method;\n  model Bacteria=Method;\n  lsmeans Method/pdiff cl;\nrun;\n\nNext, we’ll add some more details and formality to the ANOVA.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>One Predictor/Explanatory Variable, More Than Two Levels</span>"
    ]
  },
  {
    "objectID": "Section 5 One Pred More Than Two Levels.html#the-completely-randomized-design",
    "href": "Section 5 One Pred More Than Two Levels.html#the-completely-randomized-design",
    "title": "5  One Predictor/Explanatory Variable, More Than Two Levels",
    "section": "5.3 The Completely Randomized Design",
    "text": "5.3 The Completely Randomized Design\nWay back in the first section, we talked about the steps in a statistical investigation\n\nStep 1: Ask a research question\nStep 2: Design a study and collect data\nStep 3: Explore the data\nStep 4: Draw inferences beyond the data\nStep 5: Formulate conclusions\nStep 6: Look back and look ahead\n\nAs part of Step 2, we noted that we need to consider questions like ‘what variable(s) wil be measured’. This basically involves identifying the response variable as well as any explanatory variable(s). Now, let’s introduce some new terminology that really only becomes relevant once we are doing ANOVA.\nExample: Handwash, again. The student considered four treatments: water only, regular soap, antibacterial soap, and alcohol spray.\nIn this example, there is one factor.\nDefinition:\n\n\n\n\n\n\nIn order to study the effect of the factor on the response, two or more values of the factor are considered. These values are called levels.\n\n\n\n\nIn some cases, there is more than one factor.\nExample: Two students at Queensland University of Technology, as a project for their statistics class, carried out an experiment to test the effect certain factors such as refrigeration, stem length, and water content have on the life of a cut rose. The students considered\n\nStem length (15 cm or 25 cm)\nWater content (tap water or tap water + citric acid)\nTemperature (refrigerated or room temperature)\n\nThe response measured was the number of days until death, and the goal was to determine the conditions that will extend rose life.\nIn this example, there are 3 factors:\n\n\n\n\nEach factor has 2 levels:\n\n\n\n\n\n\n\nIn multifactor experiments like this, we define a treatment as a combination of factor levels.\n\nFactors:\n\n\n\n\nLevels:\n\n\n\n\n\n\n\n-Treatments:\n\n\n\n\n\n\n\n\n\n\nWe also have to consider the treatment design and the experimental design.\nDefinition: The treatment design\n\n\n\n\n\n\n\nDefinition: The experimental design\n\n\n\n\n\n\n\n\nThe experimental design should address the three basic principles underlying formal experimentation:\n\nReplication: a repetition of the basic experiment\n\n\n\n\n\n\n\nRandomization: both allocation of experimental material and order in which individual runs/trials are performed\n\n\n\n\n\n\n\nControl: control the effect of extraneous variables\n\n\n\n\n\n\nThe first experimental design we’ll consider is the completely randomized design or CRD. The CRD is an experimental design because\n\n\n\n\nThe CRD is characterized by\n\n\n\n\nThe CRD may be combined with several different treatment designs. To explore the CRD in more detail, we’ll start with the simplest treatment design, the one-way design. The one-way design is so named because\n\n\n\n\n\n\nWithin one-way designs there are four basic treatment structures:\n\nUnstructured\n\nControl versus other treatments\n\nQuantitative\n\nOther structure\n\n\nExample: Handwash, again. The student considered four treatments: water only, regular soap, antibacterial soap, and alcohol spray. The student replicated each treatment 8 times.\n\nTreatment Design:\n\nFactor:\nLevels:\n\nExperimental Design:\n\nRun 8 trials in a Completely Randomized Design\n\n\nHere’s one possible sequence of trials:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAL\nRS\nAB\nW\nW\nAL\nAB\nRS\nRS\nRS\nRS\nAL\nRS\nAB\nAB\nAB\nW\nW\nAB\nAB\nAL\nW\nRS\nRS\nAB\nAL\nW\nW\nAL\nW\nAL\nAL\n\n\n\n\n\n\n\n\n\n5.3.1 CRD Model and Basic Analysis\nThe CRD Model can be written in two different ways.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(y_{ij}\\) = bacteria count for the \\(j^{th}\\) trial after handwashing the \\(i^{th}\\) method\n\\(\\mu\\) = overall mean bacteria count\n\\(\\tau_i\\) = treatment effect of method \\(i\\) = additional amount of bacteria observed using handwashing method \\(i\\)\n\\(\\epsilon_{ij}\\) = random error = additional amount of bacteria in the \\(j^{th}\\) trial using handwashing method \\(i\\)\n\nExample: A donut manufacturer wants to see if the type of fat used to fry the donuts has any impact on the amount of fat absorbed by the donuts. The manufacturer has two types of animal fat and two types of vegetable fat that they would like to compare. They also have available 4 fryers, which can each fry 1 batch of 18 donuts at a time. They plan to measure the amount of fat absorbed in each batch.They have the resources to test 24 total batches of donuts.\n\nTreatment Design:\n\nFactor:\nLevels:\n\nExperimental Design:\n\nRun 6 batches of each fat in a Completely Randomized Design\n\n\n\nFor this particular treatment design, there are several hypothesis tests that may be of interest. Write out in the symbols the null and alternative hypotheses for the following specified objectives. Reminder: Fats 1 and 2 are animal fats and Fats 3 and 4 are vegetable fats.\n\nAre there differences among the four fats with respect to the amount of fat absorbed?\n\n\n\n\n\n\n\n\n\n\n\n\nDo the vegetable fats differ from the animal fats in the amount of fat absorbed?\n\n\n\n\n\n\n\n\n\n\n\n\nAre there differences between the two animal fats? Are there differences between the two vegetable fats?\n\n\n\n\n\n\n\n\n\n\n\nWe’ve already seen how to fit the basic ANOVA in R and SAS.\ndata donut; \n  do type=1 to 4; \n    input absorb @@;\n    output;\n  end;\n   datalines; \n   164 178 175 155\n   172 191 193 166\n   168 197 178 149\n   177 182 171 164\n   156 185 163 170\n   195 177 176 168\n   ;\n\nproc glimmix data=donut;\n  class type; \n  model absorb=type; \n  lsmeans type/pdiff cl;\nrun;\n\n\n\n\n5.3.2 Treatment Comparisons and Contrasts\nWe can see in the results above that we may reject the overall hypothesis that the four treatments produce the same mean fat absorption (\\(F=5.41\\), p-value\\(=0.0069\\)). But, this doesn’t address the hypotheses you constructed earlier. Remember, we also considered:\n\nDo the vegetable fats differ from the animal fats in the amount of fat absorbed?\nAre there differences between the two animal fats?\nAre there differences between the two vegetable fats?\n\nThe output above allows us to address some of these questions, but not the one regarding vegetable fats versus animal fats. Let’s look at a more general way to construct treatment comparisons.\nContrasts\nA well-thought-out treatment design’s objectives can usually be stated in terms of a set of contrasts. This is usually an important goal in planning the design, and contrasts are constructed before data are collected.\nA contrast is\n\n\n\n\n\n\nEstimates of the contrast are obtained by substituting in the sample means\n\n\n\n\n\nWe may also obtain standard errors of the contrast estimate\n\n\n\n\n\nStandard errors may then be used to carry out tests and construct confidence intervals.\n\n\n\n\n\n\n\nThe contrasts of interest depend on the basic treatment design structure and the goals of the experiment. Remember, the four basic structures are\n\nUnstructured\nControl versus other treatments\nQuantitative\nOther structure\n\nLet’s first consider Unstructured designs, because these are the simplest.\n\n5.3.2.1 Unstructured Treatment Designs and All Pairwise Comparisons\nExample: Handwashing, again. The student considered four treatments: water only, regular soap, antibacterial soap, and alcohol spray. The student replicated each treatment 8 times.\n\nTreatment Design:\n\nFactor:\nLevels:\n\nExperimental Design:\n\nRun 8 trials in a Completely Randomized Design\n\n\nIn designs like this without structure, we are typically interested in all pairwise comparisons.\n\n\n\n\n\n\n\nThere are multiple methods for making such comparisons. The simplest is the least significant difference (LSD), also called the unprotected LSD. It’s easy, but the Type I error rate can be badly inflated (we’ll talk more about this in a bit).\n\n\n\n\n\n\nA (slightly) more conservative option is Fisher’s protected LSD.\n\n\n\n\nWe’ve already seen these, but let’s add even more fanciness!\nproc glimmix data=handwash;\n  class Method;\n  model Bacteria=Method;\n  lsmeans Method/pdiff cl lines plot=diffplot;\nrun;\n\n\n\n\n\n\n\n\n\n\n\nThis plot is called a diffogram and is a way to visualize differences among the treatments.\nSo these plots are awesome, and the output is easy to interpret! Why do we care about anything other than the LSD? The big issue is Type I error rate, and it can be a concern for pairwise comparisons as well as more complicated contrasts.\nMultiple Comparisons\nIf more than one comparison is made among the treatment means, then we have multiple comparisons which can lead to the problem of multiplicity.\nDefinition: Multiplicity is\n\n\n\n\nFor a single test, the significance level of a Type I error is called a comparison-wise error rate. This means\n\n\n\n\n\nBut, if we have multiple tests, the Type I errors for these tests accumulate. This accumulated rate is the called the experiment-wise error rate. This is\n\n\n\n\n\nBut, the errors don’t just add up. They accumulate in a power-type relationship. Consider a situation with a comparison-wise error rate of \\(\\alpha\\) and \\(c\\) independent comparisons. Then, the experiment-wise error rate is\n\n\n\n\n\nFor example, consider a situation with \\(\\alpha=0.05\\) and 5 independent comparisons (there are as many independent comparisons as there are \\(df\\) for treatment). In that case:\n\n\n\n\n\n\n\nWe can control the experiment-wise error rate by setting it to a pre-specified value \\(\\alpha\\) (maybe 0.05) and then solving for the comparison-wise error rate, assuming \\(c\\) independent comparisons. So, for example, if \\(\\alpha=0.05\\) and \\(c=5\\),\n\n\n\n\n\n\n\nWe’d then use this as the critical value (cut-off) value for our independent treatment comparisons.\nBut here’s another issue. If the comparisons are not independent (which they aren’t in all pairwise-comparisons, and often aren’t in pre-planned contrasts of interest), then the experiment-wise error rate is actually even bigger than we see above. What can we do?\nThere are a multitude of multiple comparison procedures which control the overall experiment-wise error rate, which have different pros and cons. We’re only going to the talk about a few.\nTukey’s HSD: Tukey’s Honestly Significant Difference (HSD) procedure is based on the studentized range statistic. To get this HSD from SAS:\nproc glimmix data=handwash;\n  class Method;\n  model Bacteria=Method;\n  lsmeans Method/pdiff cl adjust=tukey;\nrun;\n\nWe could also request lines and the diffogram; they would be adjusted as well.\n\nThe other multiple comparison procedures we’ll discuss are used with other treatment design structures. The three other one-way treatment design structures are:\n\nControl versus other treatments\nQuantitative (we’ll put a pin in this one for now)\nOther structure\n\n\n\n5.3.2.2 Control versus other treatments\nIn some scenarios, one of the factor levels acts as a control treatment for some or all of the remaining levels. Often, we are interested in comparing all of the treatments against the control but not against each other. This means there are\nDunnett’s procedures is a modification to the two-sample \\(t\\) test that is used when comparing all treatments against a control.\nExample: Sections of tomato plant tissue were grown in culture with differing amounts and types of sugars with five replications of four treatments. The treatments were: control, 3% glucose, 3% fructose, and 3% sucrose.\n\nTreatment Design:\n\nFactor:\nLevels:\n\nExperimental Design:\n\n\n\n\nIn a situation like this, we may be interested in comparing each of the sugar treatments to the control.\n   data tomato;\n     input trt $ growth @@;\n     datalines;\n     control 45 glucose 25 fructose 28 sucrose 31\n     control 39 glucose 28 fructose 31 sucrose 37\n     control 40 glucose 30 fructose 24 sucrose 35\n     control 45 glucose 29 fructose 28 sucrose 33\n     control 42 glucose 33 fructose 27 sucrose 34\n   ;\n    proc glimmix data=tomato;\n      class trt;\n      model growth=trt;\n      lsmeans trt/diff=control('control') cl adjust=dunnett plot=controlplot;\n    run;\nNote that unless otherwise specified, SAS will assume the first treatment level (alphabetically or numerically) is the control.\n\n\n\n\n\n\n\n\n5.3.2.3 Treatment Designs with (other) Structure\nThis is where the donut example fits in. There isn’t a true control, but we also may not care about all pairwise comparisons. Instead, we had some specific, pre-planned comparisons of interest:\n\nDo the vegetable fats differ from the animal fats in the amount of fat absorbed?\nAre there differences between the two animal fats?\nAre there differences between the two vegetable fats?\n\nWhy pre-plan comparisons?\n\n\n\n\n\nEarlier, we wrote out the hypotheses of interest corresponding to these comparisons:\n\n\n\n\n\n\nThere are three options available in SAS to test these hypotheses and/or construct confidence intervals:\n\ncontrast statement\nestimate statement\nlsmestimate statement\n\nAll three statements involve specifying the coefficients of the treatment effects/treatment means. Let’s look at the comparison of vegetable and animal fats.\n\n \n\n\n\n\n\n\n\n\n\nand two different contrast statements we could write:\n\n    proc glimmix data=donut1;\n      class type;\n      model absorb=type;\n      contrast \"animal vs veg\" type 1 1 -1 -1;\n      contrast \"animal vs veg 2\" type 0.5 0.5 -0.5 -0.5;\n    run;\nBoth give the same results!\n                          Contrasts\n    \n    Num      Den\n    Label                DF       DF    F Value    Pr &gt; F\n    \n    animal vs veg         1       20       5.37    0.0313\n    animal vs veg 2       1       20       5.37    0.0313\n    \nLet’s try them with estimate statements, and add a third option:\n    estimate \"animal vs veg\" type 1 1 -1 -1;\n    estimate \"animal vs veg 2\" type 0.5 0.5 -0.5 -0.5;\n    estimate \"animal vs veg 3\" type 1 1 -1 -1/divisor=2;\n\n                                   Estimates\n    \n                                   Standard\n    Label              Estimate       Error       DF    t Value    Pr &gt; |t|\n    \n    animal vs veg       19.0000      8.2016       20       2.32      0.0313\n    animal vs veg 2      9.5000      4.1008       20       2.32      0.0313\n    animal vs veg 3      9.5000      4.1008       20       2.32      0.0313\n    \n                      type Least Squares Means\n    \n                        Standard\n    type    Estimate       Error       DF    t Value    Pr &gt; |t|\n    \n    1         172.00      4.1008       20      41.94      &lt;.0001\n    2         185.00      4.1008       20      45.11      &lt;.0001\n    3         176.00      4.1008       20      42.92      &lt;.0001\n    4         162.00      4.1008       20      39.50      &lt;.0001\n    \n    \nWhat’s going on?\n\n\n\n\n\n\n\n\n\nSuppose for some reason we wanted to test whether fats 1-3 (collectively) were different from fat 4.\n\n\n\n\n\n\n\nThe way we write the estimate statement really matters here:\n    estimate \"first 3 vs last\" type 0.33 0.33 0.33 -1;\n    estimate \"first 3 vs last\" type 1 1 1 -3/divisor=3;\n\n                                   Estimates\n    \n                                   Standard\n    Label              Estimate       Error       DF    t Value    Pr &gt; |t|\n    \n    first 3 vs last     Non-est           .        .        .         .\n    first 3 vs last     15.6667      4.7352       20       3.31      0.0035\nWe do still have a multiplicity issue, because we are interested in three pre-planned contrasts. We can use the Sidak adjustment to control experiment-wise error rate:\n    estimate \"1 vs 2\" type 1 -1 0 0,\n             \"3 vs 4\" type 0 0 1 -1,\n             \"animal vs veg\" type 0.5 0.5 -0.5 -0.5/adjust=sidak;\n\n                                  Estimates\n    \n                                   Standard\n    Label              Estimate       Error       DF    t Value    Pr &gt; |t|\n    \n    animal vs veg 2      9.5000      4.1008       20       2.32      0.0313\n    \n    \n\n                                  Estimates\n                        Adjustment for Multiplicity: Sidak\n    \n                                 Standard\n    Label            Estimate       Error       DF    t Value    Pr &gt; |t|     Adj P\n    \n    1 vs 2           -13.0000      5.7994       20      -2.24      0.0365    0.1055\n    3 vs 4            14.0000      5.7994       20       2.41      0.0255    0.0745\n    animal vs veg      9.5000      4.1008       20       2.32      0.0313    0.0909\n    \nFinally, we can use the lsmestimate statement. lsmestimate basically does the same thing as estimate but it allows for more complicated models than we have yet encountered. For a CRD, the output of the two should be identical, though lsmestimate does have some additional options (and slightly different syntax).\n    lsmestimate type \"1 vs 2\" 1 -1 0 0,\n                     \"3 vs 4\" 0 0 1 -1,\n                     \"animal vs veg\"  0.5 0.5 -0.5 -0.5/joint;\nThe joint option gives a joint test for whether the LSMeans are the same, which is the same as the overall test in the simple designs like the CRD. There are also multiple comparison adjustments available in lsmestimate.\nWhat happens if you don’t pre-plan? Ideally, comparisons are set up ahead of time based on specific research questions. If comparisons are selected after examining the data, most researchers construct tests that correspond to large differences in the means. These differences could be due to a real treatment effect, or they could be due to random error. Picking the largest differences to compare will inflate Type I error. If you do want to look at comparisons suggested by the data (post hoc comparisons), then you should replace the \\(t\\) test with a VERY conservative test called the Scheffé test. Scheffè works for pairwise comparisons or contrasts. We request it by adding the adjust=scheffe option.\nTo see how conservative Scheffè is, let’s look at the comparison of Fats 1 vs 2 (and pretend that Fat 1 is a control, just for illustration.\n\n\n\n\n\nAdjustment Type\np-value\nLower CL\nUpper CL\n\n\n\n\nUnadjusted\n0.0365\n-25.0974\n-0.9026\n\n\nTukey\n0.1462\n-29.2320\n3.2320\n\n\nDunnett\n0.0908\n-27.7326\n1.7326\n\n\nScheffè\n0.2044\n-30.6813\n4.6813\n\n\n\n\nWhat do you notice?\n\n\n\n\nWhich one to use? It depends. Is it more important to control the comparison-wise error rate or experiment-wise error rate? That will depend on the situation. Keep in mind that the more conservative the adjustment, the lower the power. That is, the more likely you are to make a Type II error.\nExample: A study is being planned to study the ability of a liberty ship artificial reef to attract and hold macrobenthic epifauna. One of the variables of interest is the density of oysters, and researchers are interested in comparing different locations on the artificial reef. There are 6 locations\n\nFloors of holds\nSides of holds\nStarboard deck\nStarboard side\nPort side\nPort deck\n\nand 12 observations were randomly sampled at each location.\n\nTreatment Design:\n\nFactor:\nLevels:\n\nExperimental Design:\nModel:\n\n\n\n\n\n\nThe researcher is particularly interested in some specific comparisons. We’ll write the contrasts to address each one.\n\nFloors versus sides of holds\n\n\n\n\n\n\n\n\nPort versus starboard\n\n\n\n\n\n\n\n\nDeck versus sides, except for holds\n\n\n\n\n\n\n\n\nPort sides versus starboard sides\n\n\n\n\n\n\n\n\nPort decks versus starboard decks\n\n\n\n\n\n\n\n\n\nPort side versus port deck\n\n\n\n\n\n\n\n\n\nStarboard side versus starboard deck\n\n\n\n\n\n\n\n\n\n\n\n5.3.3 Model Adequacy\nEverything we’ve done so far is based on the assumptions that the observations are adequately described by the model\n\n\n\n\n\n\n\n\n\n\n\n\n\nIf these assumptions are not valid, then the estimates of the treatment means and tests of significance from the ANOVA will be affected. We typically use residuals as a basis of our diagnostic tools.\nThe residual for observation \\(j\\) in treatment \\(i\\) is defined as:\n\n\n\nExamining residuals should be an automatic part of the analysis of variance, and can be used to check the assumptions of common variance and normality of the error term. The assumptions can be checked using a visual inspection or formally through tests, and SAS makes it very easy to do so.\nThere’s a lot of code here, but we’ll examine it piece-by-piece.\n    proc glimmix data=donut1 plot=residualpanel;\n      class type;\n      model absorb=type; \n      random _residual_/group=type;\n      covtest homogeneity;\n      output out=donutout pred=pred residual=resid;\n    run;\nHere’s what the options are doing:\n\nplot=residualpanel produces a set of residual plots\nrandom _residual_/group=type tells SAS you want to estimate a residual variance for each treatment group (i.e., get separate estimates of \\(\\sigma^2\\) from each treatment group)\ncovtest produces a hypothesis test for comparing variances, and homogeneity says you want to test whether they are all equal\noutput produces a new data set (called donutout) which contains the observed residuals (resid) and predicted values (pred)\n\n\n\n\nResidual panel for the donut data\n\n\nThe upper left hand plot shows\n\n\n\n\n\nThe other three plots all deal with the normality assumption.\n\n\n\n\n\n\n\n\n\n\nWe can also use proc univariate to check normality, using the donoutout data set we created above.\n    proc univariate data=donutout plot normal;\n      var resid;\n    run;\nHere’s part of the output\n                           Tests for Normality\n    \n    Test                  --Statistic---    -----p Value------\n    \n    Shapiro-Wilk          W     0.972165    Pr &lt; W      0.7205\n    \nThe Shapiro-Wilk test is the most commonly used test for normality. A highly significant p-value would indicate there may be a problem with non-normality.\nWhat happens if we do see a large departure from normality?\n\n\n\n\n\n\nThe other assumption we can check with residuals is the constant variance assumption, also called the assumption of homogeneous variances. From the SAS output\n           Covariance Parameter Estimates\n                                           Standard\n    Cov Parm         Group     Estimate       Error\n    Residual (VC)    type 1      178.00      112.58\n    Residual (VC)    type 2     60.4000     38.2003\n    Residual (VC)    type 3     97.6000     61.7277\n    Residual (VC)    type 4     67.6000     42.7540\n    \n          Type III Tests of Fixed Effects\n                  Num      Den\n    Effect         DF       DF    F Value    Pr &gt; F\n    type            3       20       8.39    0.0008\n    \n               Tests of Covariance Parameters\n              Based on the Restricted Likelihood\n    Label            DF    -2 Res Log Like      ChiSq    Pr &gt; ChiSq    Note\n    Homogeneity       3             156.21       1.90        0.5942    DF\n    \n    DF: P-value based on a chi-square with DF degrees of freedom.\nThe covariance parameter estimates are the estimates of the variances for each of the four treatments, along with their standard errors. What do you notice?\n\n\n\n\n\nThe Tests of Covariance Parameters is testing the null hypothesis that the four variances are equal, versus the alternative that at least one is different.\n\n\n\n\n\nIn general, moderate departures from normality are of little concern, especially with the CRD. Nonconstant variance can be a bigger issue, but there are things we can do (like transformations) to stabilize the variance.\n\n\n\n5.3.4 Power for the Completely Randomized Design\nWith multiple comparisons, we talked about Type I error and its probability. We defined Type I error as rejecting the null hypothesis when it is, in fact, true. If P(Type I error) = \\(\\alpha\\), then P(no Type I error) = \\(1-\\alpha\\).\nThere is another kind of error – Type II error. A Type II error occurs when H\\(_0\\) is not rejected, but H\\(_0\\) is actually false. In earlier courses, we summarized these two types of errors in a table:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEarlier in STAT 801, as well as other classes, we’ve said that we can “set” the probability of a Type I error. Anytime we say we’ll reject H\\(_0\\) if the p-value \\(&lt; \\alpha\\), we’re setting P(Type I error) = \\(\\alpha\\). What about Type II error? We generally call the probability of a Type II error \\(\\beta\\), P(Type II error) = \\(\\beta\\). The problem is we can’t “set” both \\(\\beta\\) and \\(\\alpha\\) without some other complications.\nWe are typically interested in the power of a test:\n\n\n\n\n\n\nLet’s explore this via simulation. Consider a two-sample \\(t\\)-test. In Canvas, there is an R file called simulation example.R.\n\nIn the program, we’re generating \\(n_1=20\\) normal random variables with \\(\\mu_1=10\\), \\(\\sigma^2=25\\) and \\(n_2=20\\) normal random variables with \\(\\mu_2=10\\), \\(\\sigma^2=25\\).\nCarry out the t-test (code already included) and observe the p-value. Using \\(\\alpha=0.10\\), what is your decision?\nRun the program 9 more times, so you have a total of 10 p-values. How many times out of 10 did you reject H\\(_0\\)?\nWhat does this estimate?\n\n\n\nEdit the program to generate data with \\(\\mu_1=10\\) and \\(\\mu_2=12\\) (still with \\(n_1=n_2=20\\) and \\(\\sigma^2=25\\)). Run the program 10 times total. How many times did you reject H\\(_0\\), using \\(\\alpha=0.10\\)?\nEdit the program to generate data with \\(\\mu_1=10\\) and \\(\\mu_2=15\\) (still with \\(n_1=n_2=20\\) and \\(\\sigma^2=25\\)). Run the program 10 times total. How many times did you reject H\\(_0\\), using \\(\\alpha=0.10\\)?\nEdit the program to generate data with \\(\\mu_1=10\\) and \\(\\mu_2=20\\) (still with \\(n_1=n_2=20\\) and \\(\\sigma^2=25\\)). Run the program 10 times total. How many times did you reject H\\(_0\\), using \\(\\alpha=0.10\\)?\n\nWhat do you observe as \\(\\mu_1\\) and \\(\\mu_2\\) get further apart?\n\n\n\n\n\nNow let’s try the following:\n\nEdit the program to generate data with \\(\\mu_1=10\\) and \\(\\mu_2=12\\), but with \\(\\sigma^2=1\\) (still with \\(n_1=n_2=20\\)). Run the program 10 times total. How many times did you reject H\\(_0\\), using \\(\\alpha=0.10\\)?\nEdit the program to generate data with \\(\\mu_1=10\\) and \\(\\mu_2=20\\), but with \\(\\sigma^2=625\\) (still with \\(n_1=n_2=20\\)). Run the program 10 times total. How many times did you reject H\\(_0\\), using \\(\\alpha=0.10\\)?\n\nWhat do observe as \\(\\sigma^2\\) gets larger or smaller?\n\n\n\n\n\nPower is the probability of rejecting H\\(_0\\) when it is really false. It is a function of several quantities:\n\n\n\n\n\n\n\n\n\n\nPower analyses usually focus on calculating the sample size required to achieve a particular power. What do you think would happen if instead of using \\(n_1=n_2=20\\) we used \\(n_1=n_2=10\\)?\n\n\n\nWhat do you think would happen if instead of using \\(n_1=n_2=20\\) we used \\(n_1=n_2=40\\)?\n\n\n\n\nWhat do you think would happen if instead of using \\(n_1=n_2=20\\) we used \\(n_1=10\\) and \\(n_2=30\\)?\n\n\n\n\nIn some simple situations, we can SAS procs to do power calculations. There are two: PROC POWER and PROC GLMPOWER. We’ll use PROC POWER. This proc will do power calculations for two sample \\(t\\) tests and ANOVA.\nFor a two-sample \\(t\\) test, the basic code is:\n        proc power;\n          twosamplemeans test=diff\n          alpha=\n          stddev=\n          meandiff=\n          npergroup=\n          power=               ;\n        run;\nWe’ll need to supply values for alpha, stddev, and meandiff. We can either supply a value for npergroup and use power=. or supply a value for power and use npergroup=.\nWe could also add the lines\n\nplot x=power min=0.5 max=0.95; (for ntotal=.)\nx=n min= max= ; (for power=.)\n\nLet’s try this, going back to our example with \\(\\mu_1=10\\), \\(\\mu_2=12\\), and \\(\\sigma^2=25\\).\n\n\n\n\n\nWe can also use PROC POWER for ANOVA and contrasts. This time, the basic code is:\n    proc power;\n      onewayanova\n      alpha=\n      stddev=\n      groupmeans=  |   |\n      ntotal=\n      power=\n      contrast= (     );\n    run;\nLet’s go back to the donut data. In that example, the MSE was 100.90, so we’ll use \\(\\sigma=10\\) as a guess for future experiments. We observed sample means of \\(\\overline y_{1\\cdot}=172\\), \\(\\overline y_{2\\cdot}=185\\), \\(\\overline y_{3\\cdot}=176\\), and \\(\\overline y_{4\\cdot}=162\\). We can certainly use these as guesses for future experiments. We’ll consider the contrast testing animal fats versus vegetable fats. We could also look at the overall test.\n\n\n\n\nWe can also add plot statements here.\n\n\n\n\nBut, we don’t actually have to have guesses for the treatment means. We do have to have an idea of how large a difference we want to be able to detect. With our example data, we had a animal fat mean of 178.5 and a vegetable fat mean of 169. This is a difference of 9.5.\n\n\n\n\nWe could also the consider potential differences we might observe in pairwise differences.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>One Predictor/Explanatory Variable, More Than Two Levels</span>"
    ]
  },
  {
    "objectID": "Section 5 One Pred More Than Two Levels.html#block-designs",
    "href": "Section 5 One Pred More Than Two Levels.html#block-designs",
    "title": "5  One Predictor/Explanatory Variable, More Than Two Levels",
    "section": "5.4 Block Designs",
    "text": "5.4 Block Designs\nUp to now, we’ve concentrated on analyzing data coming from various treatment designs. We’ve considered multiple flavors of one-way designs (unstructured, control vs others, regression, other structure). In all cases though, we’ve been using the same experimental design: the completely randomized design (CRD). Now, we change our focus to other experimental designs. The treatment designs will be those we’ve seen before, and we’ll continue to analyze treatment effects using methods we’ve already discussed.\nWith a shift to experimental designs, we’ll be considering\n\n\n\n\nThis also means\n\n\n\nWe’re going to cover the simplest experimental design (besides the CRD): the randomized complete block design (RCBD) and leave more complicated block designs for STAT 802.\nConsider an experiment in which we are interested in comparing six different lab activities for teaching the central limit theorem. Based on a power analysis, we believe four replications per treatment is sufficient, and so we need a total of 24 lab teams. We’ve got two options:\n\n\n\n\n\nWhich do you pick? Why? What are pros and cons of each?\n\n\n\n\n\n\nSuppose you decide to use teams in different classes (or you don’t have a choice). How will you assign treatments to teams?\n\n\n\n\nSuppose we allocate treatments to teams completely at random (CRD), and by chance four out of six teams in one class are assigned to treatment 1. Would you be okay with this?\n\n\n\n\nOne of the main problems with the CRD is a possible ‘conditional’ bias. That is, treatment assignment is not balanced relative to any systematic variation/gradient. In this experiment, the gradient is\n\n\n\n\nWhen this happens, treatment effect is confounded with gradient. Is any effect we observe really due to treatment, or is it due to the effect of the class? The other problem with the CRD is variance inflation. Suppose there is a gradient among the experimental units, with response increasing as you go up a gradient:\n\n\n\n\n\n\n\n\n\n\n\n\n\nEven if all the same treatment is applied throughout, the variance among the experimental units (the residuals) will be composed of two quantities:\n\n\nThis means it will appear larger than it actually is. The most common solution to these problems of confounding and variance inflation is blocking.\n\nThe idea of blocking is:\n\n\n\n\n\n\nBlocking allows us to reconcile two somewhat opposing aims of experimental design.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn summary, the general idea of blocking is to organize experimental units into groups that are as uniform as possible. We want to\n\n\n\n\nBlocks usually represent naturally occurring differences not related to treatments. If we block ‘correctly’ then the design accounts for block variation, and allows us to pull it out and isolate the usual random error due to experimental units. If we block ‘incorrectly’ then we get a weaker experiment.\nHow Do We Block?\nThere are two basic steps in blocking an experiment:\n\nOrganize the experimental units into subsets (blocks) according to gradient\nRestrict the randomization so that each treatment is assigned to one or fewer (zero) experimental units in each block.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>One Predictor/Explanatory Variable, More Than Two Levels</span>"
    ]
  },
  {
    "objectID": "Section 5 One Pred More Than Two Levels.html#the-randomized-complete-block-design",
    "href": "Section 5 One Pred More Than Two Levels.html#the-randomized-complete-block-design",
    "title": "5  One Predictor/Explanatory Variable, More Than Two Levels",
    "section": "5.5 The Randomized Complete Block Design",
    "text": "5.5 The Randomized Complete Block Design\nThe simplest block design is the randomized complete block design (RCBD). In this design\n\n\n\n\n\nIn the RCBD, we carry out the two steps referenced on the previous page as\n\nDivide the experimental units into blocks of homogeneous units.\nRandomly assign treatments to units within blocks, using a separate randomization for each block. Every treatment will appear in every block.\n\nAgain, we carry out step 1 with the goal\n\n\n\n\nThe model for the RCBD helps point out some considerations for choosing blocks. The model (assuming a one-way treatment design) is:\n\n\n\n\n\n\n\n\n\n\nThe ANOVA table looks like\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample: An experiment was carried out to evaluate the effect of elevated CO\\(_2\\) on rice grain yield. Four blocks of 2 rice paddies each (each block owned by a different farmer, who used different fertilizer regimes and management practices over the years) are available for the experiment. In each paddy there is a 12 m diameter circular plot. In one plot in each block there is a ring of tubing around the plot emitting CO\\(_2\\) at a rate of 300 ppm above ambient level. In the other plot, no CO\\(_2\\) is emitted. The grain yield is measured at 3 locations in each plot at the end of the season, and the response is the average of the 3 locations.\nWhat is the experimental unit here?\nWhat does the assumption of no block \\(\\times\\) treatment interaction mean in this example?\n\n\n\n\n\n\n\n\n\n\nWe can check it with an interaction plot. Here are the means for each plot\n\n\n\n\nBlock\nAmbient CO\\(_2\\)\nElevated CO\\(_2\\)\n\n\n\n\n1\n6.21\n6.41\n\n\n2\n6.25\n6.42\n\n\n3\n6.10\n6.26\n\n\n4\n6.14\n6.30\n\n\n\n\n\n\n\n\nInteraction plot for treatment x block.\n\n\nIf you had been presented with this data earlier in the semester, how would you have analyzed it?\n\n\n\n\n\n\n\nBlock\nAmbient CO\\(_2\\)\nElevated CO\\(_2\\)\n\n\n\n\n\n1\n6.21\n6.41\n\n\n\n2\n6.25\n6.42\n\n\n\n3\n6.10\n6.26\n\n\n\n4\n6.14\n6.30\n\n\n\n\n\n\n\n\n\n\n\n\n5.5.1 Selecting Blocks\nRemember that the RCBD is an experimental design, not a treatment design. It can be used with any treatment design. So, we might see RCBD layouts that look like:\n\n\n\n\nBlock 1\nBlock 2\nBlock 3\n\n\n\n\nControl\nTrt2\nTrt4\n\n\nTrt2\nControl\nTrt3\n\n\nTrt3\nTrt4\nTrt2\n\n\nTrt4\nTrt3\nControl\n\n\n\n\n\n\n\n\nBlock 1\nBlock 2\nBlock 3\n\n\n\n\n20\n60\n80\n\n\n60\n40\n20\n\n\n80\n80\n40\n\n\n40\n20\n60\n\n\n\n\n\n\n\n\nBlock 1\nBlock 2\nBlock 3\n\n\n\n\nA1 & B1\nA1 & B1\nA2 & B2\n\n\nA2 & B1\nA2 & B1\nA1 & B1\n\n\nA2 & B2\nA1 & B2\nA1 & B2\n\n\nA1 & B2\nA2 & B2\nA2 & B2\n\n\n\n\nWhen you write a report, both the treatment design and the experimental design need to be described in the methods section.\nTips for Choosing Blocks:\n\nWe want to maximize differences between blocks and minimize differences within blocks\n\n\n\n\n\n\n\n\n\nBlock size should not be excessively large\n\n\n\n\n\n\n\n\n\n\n\n\nKeep in the mind the no block \\(\\times\\) treatment interaction assumption\n\n\n\n\n\n\n\n\n\n\n\nCommon Criteria for Blocking:\n\ngradients that occur in the field, in greenhouses, in growth chambers\nweight groups in animal experimentation, litters, cage positions in a room\noccasion (day, month, year)\nlocation (barn, different fields, different rooms, different states)\nsubjects (each subject serves as their own control)\n\n\n\n\n5.5.2 RCBD Model and Analysis\nLet \\(y_{ij}\\) be\n\n\n\n\nEarlier we stated the model\n\n\n\n\n\n\n\n\nWe do have another choice to make. We can consider the block effect to either be a fixed effect or a random effect.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOur choice will have implications in the standard errors of the cell means.\n\n\n\n\n\nTo estimate the difference between two treatment means \\((\\mu_{i\\cdot} - \\mu_{i'\\cdot})\\), we use \\(\\overline y_{i\\cdot} - \\overline y_{i'\\cdot}\\). To figure out the variance (or estimate of the variance), let’s look at what \\(\\overline y_{i\\cdot}\\) is actually estimating:\n\n\n\n\n\n\n\n\n\n\nNow let’s explore the variance of this quantity.\n\n\n\n\n\n\n\n\n\nNow let’s consider \\(\\overline y_{i\\cdot} - \\overline y_{i'\\cdot}\\):\n\n\n\n\n\n\nand its variance\n\n\n\n\n\n\nIf we want to construct confidence intervals for treatment means or differences, they’ll have the form\n\n\n\nwhere the standard error is\n\nFor example, we use MSE as our estimate of \\(\\sigma^2\\), so confidence intervals for the difference between two means is\n\n\n\n\n\nRCBDs in SAS\nWe can still use PROC GLIMMIX to fit the model if our experimental design is the RCBD. The basic program for fixed blocks is\n    proc glimmix data=dataset;\n      class block trt;\n      model y = block trt;\n    run;\nNote:\n\n\n\nThe basic program for random blocks is\n    proc glimmix data=dataset;\n      class block trt;\n      model y = trt;\n      random block;\n    run;\nNote:\n\n\n\nExample: This experiment is looking at the emergence rate of soybean seeds treated with four different chemical treatments and a control.\n\n\n\n\nTreatment Number\nTreatment Name\n\n\n\n\n1\nControl\n\n\n2\nArasan\n\n\n3\nSpergon\n\n\n4\nSemesan\n\n\n5\nFermate\n\n\n\n\nExperimental Layout: The field is located on a slope, and blocks are formed based on elevation. There are five plots at each elevation, and five blocks.\n\n\n\n\n\n\n\n\n\n\n\n\n\nTreatment Design:\n\n\n\n\n100 seeds were planted in each plot, and the response is the number of plants that emerge out of the 100.\n\n\n\nModel:\n\n\n\n\n\n\n\nAnalysis with Blocks Fixed:\nIf we assume blocks are fixed, we use the code\nproc glimmix data=seeds;\n  class block chem;\n  model emerge=block chem;\nrun;\nwhich gives\n                 Fit Statistics\n    \n    Pearson Chi-Square / DF         5.41\n    \n         Type III Tests of Fixed Effects\n                  Num      Den\n    Effect         DF       DF    F Value    Pr &gt; F\n    \n    block           4       16       2.30    0.1032\n    chem            4       16       3.87    0.0219\n    \nThe follow-up analyses don’t change from what we’ve done so far. In this case, the treatment design is one-way treatment-versus-control, so comparing all treatments to the control is appropriate and we can use the Dunnett adjustment.\n    lsmeans chem/diff=control('Control') adjust=dunnett;\n\n                        Chem Least Squares Means\n    \n                           Standard\n    Chem       Estimate       Error       DF    t Value    Pr &gt; |t|\n    \n    Arasan      93.8000      1.0402       16      90.18      &lt;.0001\n    Control     89.2000      1.0402       16      85.75      &lt;.0001\n    Fermate     94.2000      1.0402       16      90.56      &lt;.0001\n    Semesan     93.4000      1.0402       16      89.79      &lt;.0001\n    Spergon     91.8000      1.0402       16      88.25      &lt;.0001\n\n                Differences of Chem Least Squares Means\n              Adjustment for Multiple Comparisons: Dunnett\n    \n                                      Standard\n    Chem       _Chem      Estimate       Error       DF    t Value    Pr &gt; |t|     Adj P\n    \n    Arasan     Control      4.6000      1.4711       16       3.13      0.0065    0.0218\n    Fermate    Control      5.0000      1.4711       16       3.40      0.0037    0.0125\n    Semesan    Control      4.2000      1.4711       16       2.86      0.0115    0.0375\n    Spergon    Control      2.6000      1.4711       16       1.77      0.0962    0.2680\n    \nAnalysis with Blocks Random:\nIf we assume blocks are random, we use the code\n    proc glimmix data=seeds;\n      class block chem;\n      model emerge=chem;\n      random block;\n      lsmeans chem/diff=control('Control') adjust=dunnett;\n    run;\nwhich gives\n              Fit Statistics\n    Gener. Chi-Square / DF          5.41\n    \n      Covariance Parameter Estimates\n                            Standard\n    Cov Parm    Estimate       Error\n    block         1.4100      1.8032\n    Residual      5.4100      1.9127\n    \n           Type III Tests of Fixed Effects\n                  Num      Den\n    Effect         DF       DF    F Value    Pr &gt; F\n    Chem            4       16       3.87    0.0219\n    \n                    Chem Least Squares Means\n                           Standard\n    Chem       Estimate       Error       DF    t Value    Pr &gt; |t| \n    Arasan      93.8000      1.1679       16      80.31      &lt;.0001\n    Control     89.2000      1.1679       16      76.38      &lt;.0001\n    Fermate     94.2000      1.1679       16      80.66      &lt;.0001\n    Semesan     93.4000      1.1679       16      79.97      &lt;.0001\n    Spergon     91.8000      1.1679       16      78.60      &lt;.0001\n\n                     Differences of Chem Least Squares Means\n                Adjustment for Multiple Comparisons: Dunnett-Hsu\n                                      Standard\n    Chem       _Chem      Estimate       Error       DF    t Value    Pr &gt; |t|     Adj P    \n    Arasan     Control      4.6000      1.4711       16       3.13      0.0065    0.0218\n    Fermate    Control      5.0000      1.4711       16       3.40      0.0037    0.0125\n    Semesan    Control      4.2000      1.4711       16       2.86      0.0115    0.0375\n    Spergon    Control      2.6000      1.4711       16       1.77      0.0962    0.2680\n    \nThe results are the same whether we used fixed blocks or random blocks. This is because our data are balanced–we had the same number of observations in each block, and all treatments appear in all blocks. If our data had not been balanced, the results would be different.\nDid Blocking Work?",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>One Predictor/Explanatory Variable, More Than Two Levels</span>"
    ]
  },
  {
    "objectID": "Section 5 One Pred More Than Two Levels.html#did-blocking-work",
    "href": "Section 5 One Pred More Than Two Levels.html#did-blocking-work",
    "title": "5  One Predictor/Explanatory Variable, More Than Two Levels",
    "section": "5.6 Did Blocking Work?",
    "text": "5.6 Did Blocking Work?\nWhen we treated blocks as fixed effects, we get a p-value associated with block but it is completely meaningless because there is no valid hypothesis test for evaluating the effect of block. However, we can check the efficiency of the block design relative to a competing design.\nSuppose we have \\(t\\) treatments and \\(rt\\) experimental units available for our experiment. We have two possible experimental designs:\n\n\n\n\n\nThe only difference between these is whether we group the experimental units into blocks before randomly assigning the treatments. Efficiency gives us a way to compare the variance of two competing designs–we want to select the design that gives us the smaller variance of estimated treatment differences.\n\nCRD:\n\n\n\nRCBD\n\n\n\n\nSo the choice between these two designs comes down to a comparison of \\(\\sigma^2_{CRD}\\) and \\(\\sigma^2_{RCBD}\\). We can compare variances using a ratio called the relative efficiency.\n\n\n\nIf RE \\(&gt;\\) 1\n\n\n\n\n\n\n\n\nOnce we’ve conducted an RCBD experiment we can look and see whether we did the right thing when we used blocks.\n\n\n\n\n\nNote there is a difference in the error degrees of freedom between the CRD and RCBD which can have an impact. We can adjust for this difference by calculating the adjusted relative efficiency:\n\n\n\n\n\n\n\nThe correction factor is always less than 1, and usually won’t make much difference. It can make a difference if the number of treatments and reps is small.\nExample: Rice paddies In this example, there were 4 blocks and two treatments. We’ll fit the model both with blocks and without.\n\nRCBD:\n\n\n\n\nCRD:\n\n\n\n\nExample: Seed Emergence In this example, there were five blocks and five treatments. Again, we’ll fit the model both with blocks and without.\n\nRCBD:\n\nCRD:",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>One Predictor/Explanatory Variable, More Than Two Levels</span>"
    ]
  }
]