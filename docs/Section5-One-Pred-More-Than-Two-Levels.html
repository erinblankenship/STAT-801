<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Section 5: One Predictor Variable, More Than Two Levels – Stat 801A Notes</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./Section4-One-Pred-Two-Levels.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-ffd282cb318059e0bcb130885a47f5dc.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./Section5-One-Pred-More-Than-Two-Levels.html"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">One Predictor/Explanatory Variable, More Than Two Levels</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Stat 801A Notes</a> 
        <div class="sidebar-tools-main">
    <a href="./Stat-801A-Notes.pdf" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Course Goals for STAT 801A</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Section 1 Introduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction to Data and the Scientific Method</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Section 2 Probability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Probability Basics and Probability Distributions</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Section 3 Sampling Distributions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Sampling Distributions and Foundations of Statistical Inference</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Section4-One-Pred-Two-Levels.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">One Predictor/Explanatory Variable, Two Levels</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Section5-One-Pred-More-Than-Two-Levels.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">One Predictor/Explanatory Variable, More Than Two Levels</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#categorical-response-more-than-two-levels" id="toc-categorical-response-more-than-two-levels" class="nav-link active" data-scroll-target="#categorical-response-more-than-two-levels"><span class="header-section-number">5.1</span> Categorical Response, More Than Two Levels</a></li>
  <li><a href="#quantitative-response" id="toc-quantitative-response" class="nav-link" data-scroll-target="#quantitative-response"><span class="header-section-number">5.2</span> Quantitative Response</a></li>
  <li><a href="#the-completely-randomized-design" id="toc-the-completely-randomized-design" class="nav-link" data-scroll-target="#the-completely-randomized-design"><span class="header-section-number">5.3</span> The Completely Randomized Design</a>
  <ul class="collapse">
  <li><a href="#crd-model-and-basic-analysis" id="toc-crd-model-and-basic-analysis" class="nav-link" data-scroll-target="#crd-model-and-basic-analysis"><span class="header-section-number">5.3.1</span> CRD Model and Basic Analysis</a></li>
  <li><a href="#treatment-comparisons-and-contrasts" id="toc-treatment-comparisons-and-contrasts" class="nav-link" data-scroll-target="#treatment-comparisons-and-contrasts"><span class="header-section-number">5.3.2</span> Treatment Comparisons and Contrasts</a></li>
  <li><a href="#model-adequacy" id="toc-model-adequacy" class="nav-link" data-scroll-target="#model-adequacy"><span class="header-section-number">5.3.3</span> Model Adequacy</a></li>
  <li><a href="#power-for-the-completely-randomized-design" id="toc-power-for-the-completely-randomized-design" class="nav-link" data-scroll-target="#power-for-the-completely-randomized-design"><span class="header-section-number">5.3.4</span> Power for the Completely Randomized Design</a></li>
  </ul></li>
  <li><a href="#block-designs" id="toc-block-designs" class="nav-link" data-scroll-target="#block-designs"><span class="header-section-number">5.4</span> Block Designs</a>
  <ul class="collapse">
  <li><a href="#the-randomized-complete-block-design" id="toc-the-randomized-complete-block-design" class="nav-link" data-scroll-target="#the-randomized-complete-block-design"><span class="header-section-number">5.4.1</span> The Randomized Complete Block Design</a></li>
  <li><a href="#selecting-blocks" id="toc-selecting-blocks" class="nav-link" data-scroll-target="#selecting-blocks"><span class="header-section-number">5.4.2</span> Selecting Blocks</a></li>
  <li><a href="#rcbd-model-and-analysis" id="toc-rcbd-model-and-analysis" class="nav-link" data-scroll-target="#rcbd-model-and-analysis"><span class="header-section-number">5.4.3</span> RCBD Model and Analysis</a></li>
  <li><a href="#did-blocking-work" id="toc-did-blocking-work" class="nav-link" data-scroll-target="#did-blocking-work"><span class="header-section-number">5.4.4</span> Did Blocking Work?</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">One Predictor/Explanatory Variable, More Than Two Levels</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>As mentioned at the end of Chapter 4, we’ll now move on to cases in which we have a single explanatory variable and a single response variable. In this section, we’ll cover the case where the explanatory variable is categorical with more than two levels, and the response variable is either categorical or numeric. This means that in this chapter, we’ll be focusing on comparing more than two groups</p>
<p>Data like these may show up in a spreadsheet like</p>
<p><br>
<br>
<br>
<br>
</p>
<section id="categorical-response-more-than-two-levels" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="categorical-response-more-than-two-levels"><span class="header-section-number">5.1</span> Categorical Response, More Than Two Levels</h2>
<p>First, we’ll consider situations in which two categorical variables are measured on each unit in the sample, and each variable has potentially more than two possible values. Many categorical variables have more than two possible outcomes, so we can’t easily define the proportion of “successes.” Instead, we’ll summarize categorical data with more than two levels using two-way tables. In this class, we’re still going to restrict ourselves to only two variables (often explanatory and response, but not necessarily), both with two or more levels. However, there are certainly statistical methods for more complicated situations.</p>
<p>Typically, research questions focus on how the proportions of the possible outcomes in the response variable change (or don’t) across the levels of the explanatory variable. However, we can also consider questions about a single variable with more than two outcomes (are the possible outcomes all equally likely? do the possible outcomes follow a particular pattern? We’ve already seen these!) or just whether the two categorical variables are independent or dependent without assigning an explanatory/response relationship. Due to the structure of the variable(s), there really isn’t a population parameter of interest. We can’t (usually) make a function of proportion of successes that makes sense to estimate, like we can with <span class="math inline">\(p_1 - p_2\)</span>. That means we’ll be considering only tests, not confidence intervals.</p>
<p><br>
<br>
<br>
</p>
<div style="page-break-after: always;"></div>
<p><strong>Example:</strong> When surveys are administered, we hope that the respondents give accurate answers. Does the mode of survey delivery affect this? Schober et al (2015) investigated this question. They had 147 people who agreed to be interviewed on an iPhone, and they were randomly assigned to one of three interview modes: human voice, automated voice, text. One question asked was whether they exercise less than once per week during a typical week (a yes is mostly likely considered socially undesirable). The explanatory variable here is survey mode and the response is whether or not the respondent said yes. Here are the data:</p>
<table class="caption-top table">
<caption>Survey Mode Data</caption>
<thead>
<tr class="header">
<th></th>
<th>Text</th>
<th>Human Voice</th>
<th>Automated Voice</th>
<th>Total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Exercise Yes</td>
<td>34</td>
<td>21</td>
<td>20</td>
<td>75</td>
</tr>
<tr class="even">
<td>Exercise No</td>
<td>124</td>
<td>139</td>
<td>139</td>
<td>402</td>
</tr>
<tr class="odd">
<td>Total</td>
<td>158</td>
<td>160</td>
<td>159</td>
<td>477</td>
</tr>
</tbody>
</table>
<p>Based on these data, it looks like the answer to the question does change depending on survey mode, with respondents more likely to say yes via text. However, we don’t know if this result could have happened by chance.</p>
<p><br>
<br>
<br>
<br>
<br>
<br>
</p>
<p>We saw expected counts when we did <span class="math inline">\(\chi^2\)</span> goodness of fit tests. We’ll need to find them again here. We don’t expect the proportion of ‘yes’ to be exactly the same across all survey modes, but we want to know if these vary enough to convince us that survey mode and answer are not independent. To do this, we need to find <strong>expected counts</strong> for each cell in the table.</p>
<p><br>
<br>
<br>
<br>
<br>
</p>
<div style="page-break-after: always;"></div>
<p>So, <span class="math display">\[
\hbox{Expected Count}_{\hbox{row } i, \hbox{col } j} = \frac{(\hbox{row } i \hbox{ total})(\hbox{col } j \hbox{ total})}{\hbox{table total}}
\]</span><br>
<br>
<br>
<br>
<br>
<br>
</p>
<table class="caption-top table">
<caption>Survey Model Data with Expected Counts</caption>
<colgroup>
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
</colgroup>
<tbody>
<tr class="odd">
<td></td>
<td></td>
<td><strong>Human</strong></td>
<td><strong>Automated</strong></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td><strong>Text</strong></td>
<td><strong>Voice</strong></td>
<td><strong>Voice</strong></td>
<td><strong>Total</strong></td>
</tr>
<tr class="odd">
<td>Exercise Yes</td>
<td>34 (________)</td>
<td>21 (________)</td>
<td>20 (_________)</td>
<td>75</td>
</tr>
<tr class="even">
<td>Exercise No</td>
<td>124 (________)</td>
<td>139 (________)</td>
<td>139 (________)</td>
<td>402</td>
</tr>
<tr class="odd">
<td>Total</td>
<td>158</td>
<td>160</td>
<td>159</td>
<td>477</td>
</tr>
</tbody>
</table>
<p>So just like with the goodness-of-fit test, the key question is whether the observed and expected cell counts are different enough.</p>
<ul>
<li>Cell(1,1) obs - exp = 34 -</li>
<li>Cell(1,2) obs - exp = 21 -</li>
<li>Cell(1,3) obs - exp = 20 -</li>
<li>Cell(2,1) obs - exp = 124 -</li>
<li>Cell(2,2) obs - exp = 139 -</li>
<li>Cell(2,3) obs - exp = 139 -</li>
</ul>
<p><br>
<br>
<br>
<br>
<br>
<br>
</p>
<p>Our <span class="math inline">\(\chi^2\)</span> test statistic gets just a little more complicated:</p>
<p><br>
<br>
<br>
<br>
</p>
<div style="page-break-after: always;"></div>
<p>In our example:</p>
<ul>
<li>Cell(1,1) (obs - exp)<span class="math inline">\(^2\)</span>/exp = <span class="math inline">\((34 - 24.84)^2/(24.84) = 9.16^2/24.84 = 3.3778\)</span></li>
<li>Cell(1,2) (obs - exp)<span class="math inline">\(^2\)</span>/exp = <span class="math inline">\((21 - 25.16)^2/(25.16) = (-4.16)^2/25.16 = 0.6878\)</span></li>
<li>Cell(1,3) (obs - exp)<span class="math inline">\(^2\)</span>/exp = <span class="math inline">\((20 - 25)^2/(25) = (-5)^2/25 = 1\)</span></li>
<li>Cell(2,1) (obs - exp)<span class="math inline">\(^2\)</span>/exp = <span class="math inline">\((124 - 133.16)^2/(133.16) = (-9.16)^2/133.16 = 0.6301\)</span></li>
<li>Cell(2,2) (obs - exp)<span class="math inline">\(^2\)</span>/exp = <span class="math inline">\((139 - 134.84)^2/(134.84) = 4.16^2/134.84 = 0.1283\)</span></li>
<li>Cell(2,3) (obs - exp)<span class="math inline">\(^2\)</span>/exp = <span class="math inline">\((139 - 134)\^2/(134) = 5\^2/134 =0.3731\)</span></li>
</ul>
<p><br>
<br>
</p>
<p>We already know this test statistic will follow a <span class="math inline">\(\chi^2\)</span> distribution, but now</p>
<p><br>
<br>
<br>
<br>
<br>
<br>
</p>
<p>Again, we have conditions that need to be met for the <span class="math inline">\(\chi^2\)</span> distribution to work:</p>
<ul>
<li><br>
</li>
<li><br>
<br>
</li>
</ul>
<p><strong>Example:</strong> First, we’ll need to check the conditions:</p>
<ul>
<li><br>
</li>
<li><br>
<br>
</li>
</ul>
<p>To find the p-value, we can use <code>pchisq(6.1971,df=2,lower.tail=FALSE)</code> =</p>
<p>We can also do the test directly in R:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>surveymodetable<span class="ot">&lt;-</span><span class="fu">read.csv</span>(<span class="st">"surveymodetable.csv"</span>,<span class="at">row.names=</span><span class="dv">1</span>)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>surveymodetable</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>    Text Hvoice Avoice
Yes   34     21     20
No   124    139    139</code></pre>
</div>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">chisq.test</span>(surveymodetable)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
    Pearson's Chi-squared test

data:  surveymodetable
X-squared = 6.0069, df = 2, p-value = 0.04962</code></pre>
</div>
</div>
<p><br>
<br>
<br>
<br>
<br>
</p>
<p><strong>Example:</strong> Integrated Pest Management (IPM) adopters apply significantly less insecticides and fungicides than nonadopters among grape producers. A 2008 paper published in <em>Agricultural Economics</em> gave data on IPM adoption rates for the six states that accounted for most of the US grape production. The data are in the file ‘ipmtable.csv’.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>ipmtable<span class="ot">&lt;-</span><span class="fu">read.csv</span>(<span class="st">"ipmtable.csv"</span>,<span class="at">row.names=</span><span class="dv">1</span>)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>ipmtable</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>         Cal Mich NewYork Oregon Penn Wash
Adopted   39   55      19     22   24   30
NotAdopt  92   69     114     88   83   77</code></pre>
</div>
</div>
<p><br>
<br>
<br>
<br>
<br>
</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">chisq.test</span>(ipmtable)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
    Pearson's Chi-squared test

data:  ipmtable
X-squared = 34.59, df = 5, p-value = 1.816e-06</code></pre>
</div>
</div>
<div style="page-break-after: always;"></div>
<p><strong>Example:</strong> A study of drinking habits of college students at a particular college produced the two-way table found in ‘drinkingtable.csv’ and shown below. Students were randomly selected to participate in the survey.</p>
<table class="caption-top table">
<caption>Drinking habits of college students</caption>
<colgroup>
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
</colgroup>
<tbody>
<tr class="odd">
<td></td>
<td><strong>Reside on</strong></td>
<td><strong>Reside off campus,</strong></td>
<td><strong>Reside off campus,</strong></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td><strong>campus</strong></td>
<td><strong>not with parents</strong></td>
<td><strong>with parents</strong></td>
<td><strong>Total</strong></td>
</tr>
<tr class="odd">
<td>Abstain from drinking</td>
<td>46</td>
<td>17</td>
<td>43</td>
<td>106</td>
</tr>
<tr class="even">
<td>Light or moderate drinking</td>
<td>126</td>
<td>72</td>
<td>68</td>
<td>266</td>
</tr>
<tr class="odd">
<td>Heavy drinking</td>
<td>130</td>
<td>52</td>
<td>32</td>
<td>214</td>
</tr>
<tr class="even">
<td>Total</td>
<td>302</td>
<td>141</td>
<td>143</td>
<td>586</td>
</tr>
</tbody>
</table>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>drinktable<span class="ot">&lt;-</span><span class="fu">read.csv</span>(<span class="st">"drinkingtable.csv"</span>,<span class="at">row.names=</span><span class="dv">1</span>)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>drinktable</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>              OnCampus OffNoParents OffWithParents
Abstain             46           17             43
LightModerate      126           72             68
Heavy              130           52             32</code></pre>
</div>
</div>
<p>What’s different about this example?</p>
<p><br>
<br>
<br>
<br>
</p>
<p>This leads to hypotheses</p>
<p><br>
<br>
<br>
<br>
</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">chisq.test</span>(drinktable)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
    Pearson's Chi-squared test

data:  drinktable
X-squared = 28.949, df = 4, p-value = 8.007e-06</code></pre>
</div>
</div>
</section>
<section id="quantitative-response" class="level2" data-number="5.2">
<h2 data-number="5.2" class="anchored" data-anchor-id="quantitative-response"><span class="header-section-number">5.2</span> Quantitative Response</h2>
<p>We’re going to start this section by considering an example. The data are in the file ‘mice.csv.’</p>
<p><strong>Example:</strong> These data come from an experiment to determine if exercise confers some resilience to stress. Mice were randomly assigned to either an enriched environment (exercise wheel) or standard environment, and spent three weeks there. After that time, they were exposed for five minutes per day for two weeks to a “mouse bully”–a mouse very strong, aggressive, and territorial. After those two weeks, anxiety in the mice was measured, as amount of time hiding in a dark compartment. Mice that are more anxious spend more time in darkness. We want to determine if there is a difference in time spent in darkness for the two groups of mice.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>mice<span class="ot">&lt;-</span><span class="fu">read.csv</span>(<span class="st">"mice.csv"</span>,<span class="at">header=</span><span class="cn">TRUE</span>)</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(mice)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>    Envr Time
1 Enrich  259
2 Enrich  280
3 Enrich  138
4 Enrich  227
5 Enrich  203
6 Enrich  184</code></pre>
</div>
</div>
<p>We already know how to answer this research question!</p>
<p><br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
</p>
<p>Let’s first plot the data</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Section5-One-Pred-More-Than-Two-Levels_files/figure-html/mice-data-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>It definitely looks like there’s a difference between the groups! We can find the group means and standard deviations. We’ll also add the sample means to the plot.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="fu">aggregate</span>(mice<span class="sc">$</span>Time, <span class="at">by=</span><span class="fu">list</span>(mice<span class="sc">$</span>Envr), <span class="at">FUN=</span>mean)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  Group.1        x
1  Enrich 217.4286
2     Std 438.7143</code></pre>
</div>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="fu">aggregate</span>(mice<span class="sc">$</span>Time, <span class="at">by=</span><span class="fu">list</span>(mice<span class="sc">$</span>Envr), <span class="at">FUN=</span>sd)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  Group.1        x
1  Enrich 47.52844
2     Std 37.68162</code></pre>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Section5-One-Pred-More-Than-Two-Levels_files/figure-html/mice-data-means-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>We’re testing H<span class="math inline">\(_0: \mu_1 = \mu_2\)</span>, and assume this is true to construct the test. The overall common sample mean is <span class="math inline">\(\bar x = 328.07\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="fu">t.test</span>(Time<span class="sc">~</span>Envr,<span class="at">data=</span>mice)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
    Welch Two Sample t-test

data:  Time by Envr
t = -9.6526, df = 11.407, p-value = 7.885e-07
alternative hypothesis: true difference in means between group Enrich and group Std is not equal to 0
95 percent confidence interval:
 -271.5245 -171.0470
sample estimates:
mean in group Enrich    mean in group Std 
            217.4286             438.7143 </code></pre>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Section5-One-Pred-More-Than-Two-Levels_files/figure-html/mice-data-overall-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>It turns out the difference between the two groups will also manifest itself in the variances. There will be variation between the group means and the overall mean, as well as variation between the data points and their group means.</p>
<p>Remember how sample variance is calculated:</p>
<p><br>
<br>
<br>
<br>
<br>
</p>
<p>We’re exploring how far, on average, observations are from the mean (squared). So, variance has to be positive. If there is a difference between the group means, the first kind of variation (between the group means and the overall mean) will be much greater than the second kind of variance (between the data points and their group mean). We can test whether the first variance is bigger than the second using an <span class="math inline">\(F\)</span> statistic, just like we did in the last section when we were comparing two variances:</p>
<p><span class="math display">\[
F = \frac{\hbox{variance between group means and overall mean}}{\hbox{variance between the data points and their group mean}}
\]</span></p>
<p>If the variances are about equal, there’s no evidence of a difference between the group means–they vary as much from the overall mean as data points vary from their group mean. This will result in an <span class="math inline">\(F\)</span> statistic of about 1. If there is a difference between the group means, the first kind of variation (between the group means and the overall mean) will be much greater than the second kind of variance (between the data points and their group mean). This will result in an <span class="math inline">\(F\)</span> statistic greater than 1.</p>
<div style="page-break-after: always;"></div>
<p>For the mice data:</p>
<p><br>
<br>
<br>
<br>
</p>
<p><strong>Notice!</strong></p>
<p><br>
<br>
<br>
<br>
</p>
<p>We made some assumptions to carry out the <span class="math inline">\(t\)</span>-test:</p>
<ul>
<li>approximate normality (no extreme outliers, no strong skew)</li>
<li>independence between groups and between observations</li>
<li>constant variance (we didn’t make a big deal of this one, but mentioned it)</li>
</ul>
<p>We can summarize these assumptions very succinctly, and to do so we’re going to introduce some new notation.</p>
<p>Consider a random sample of observations from a normal distribution with mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\)</span>. If we let <span class="math inline">\(Y_1, Y_2,\dots, Y_n\)</span> represent our data points we can summarize this as:</p>
<p><br>
<br>
<br>
</p>
<p>Or another way:</p>
<p><br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
</p>
<p>This is a <strong>statistical model</strong> with 2 parameters: <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma^2\)</span>.</p>
<p><br>
<br>
</p>
<div style="page-break-after: always;"></div>
<p>If we have two samples:</p>
<p><br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
</p>
<p>If we have more than two samples:</p>
<p><br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
</p>
<p>Let’s start with some summary statistics <span class="math display">\[\begin{eqnarray*}
    Y_{i\cdot} &amp;=&amp; \sum_{j=1}^{n_i} Y_{ij} = i^{th} \hbox{ sample total} \\
    \bar Y_{i\cdot} &amp;=&amp; \frac{1}{n_i} \sum_{j=1}^{n_i} Y_{ij} = i^{th} \hbox{ sample mean} \\
    Y_{\cdot \cdot} &amp;=&amp; \sum_{i=1}^{t} \sum_{j=1}^{n_i} Y_{ij} = \hbox{ grand total} \\
    \bar Y_{\cdot \cdot} &amp;=&amp; \frac{1}{N} \sum_{i=1}^{t} \sum_{j=1}^{n_i} Y_{ij} = \hbox{ grand mean  } (N=\sum_{i=1}^{n_i} n_i)
\end{eqnarray*}\]</span></p>
<div style="page-break-after: always;"></div>
<p><strong>Example:</strong> A student carried out an experiment to investigate handwashing methods: water only, regular soap, antibacterial soap, and alcohol spray. Each treatment was replicated 8 times, and bacteria count was observed. The data are in ‘handwash.csv’.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Section5-One-Pred-More-Than-Two-Levels_files/figure-html/wash-data-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>  Group.1     x
1  ABSoap  92.5
2 Alcohol  37.5
3    Soap 106.0
4   Water 117.0</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>  Group.1        x
1  ABSoap 41.96257
2 Alcohol 26.55991
3    Soap 46.95895
4   Water 31.13106</code></pre>
</div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Section5-One-Pred-More-Than-Two-Levels_files/figure-html/wash-data-means-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Section5-One-Pred-More-Than-Two-Levels_files/figure-html/wash-data-overall-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<div style="page-break-after: always;"></div>
<p>Remember how to calculate the sample variance, <span class="math inline">\(S^2 = \frac{\sum_{i=1}^n (y_i - \bar y)^2}{n-1}\)</span>. We’re going to look at three difference variances. Let’s assume for simplicity that <span class="math inline">\(n_i = n\)</span> (all groups have equal sample size, this is not really necessary, it’s just to make it easier to look at notation):</p>
<ol type="1">
<li>Total Variance. Another name for the numerator is total sum of squares.</li>
</ol>
<p><br>
<br>
<br>
<br>
<br>
</p>
<ol start="2" type="1">
<li>Error (Within-Group) Variance. Another name for the numerator is the error sum of squares.</li>
</ol>
<p><br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
</p>
<ol start="3" type="1">
<li>Model (Between-Group) Variance. Another name for the numerator is the treatment (model) sum of squares.</li>
</ol>
<p><br>
<br>
<br>
<br>
</p>
<p>To see what this is measuring, first consider the ‘inside’ sum:</p>
<p><br>
<br>
<br>
<br>
</p>
<p>This is still an estimate of variance, but it’s an estimate of <span class="math inline">\(\sigma^2/n\)</span>, because these are means. In order to be able to compare fairly to the error variance we must multiply by <span class="math inline">\(n\)</span> (only works with equal sample sizes) or, equivalently, take the sum from <span class="math inline">\(j=1\)</span> to <span class="math inline">\(n\)</span>:</p>
<p><br>
<br>
</p>
<div style="page-break-after: always;"></div>
<p>We can’t lose sight of what we’re interested in here: testing H<span class="math inline">\(_0: \mu_1 = \mu_2\)</span>. If H<span class="math inline">\(_0\)</span> is true, <span class="math inline">\(\bar y_1\)</span> and <span class="math inline">\(\bar y_2\)</span> should not be different from <span class="math inline">\(\bar y_{\cdot \cdot}\)</span>. This means that error variance should be about equal to model variance (both would estimate <span class="math inline">\(\sigma^2\)</span>). If H<span class="math inline">\(_0\)</span> is not true, model variance will be larger because of the deviations of the group averages from the grand average. If it’s much larger, this gives us evidence against H<span class="math inline">\(_0\)</span>.</p>
<p>Why do we worry about three variances when we only use two (error and model) to get the <span class="math inline">\(F\)</span> stat? It turn out that: <span class="math display">\[
\hbox{Total SS } = \hbox{Model SS } + \hbox{ Error SS}
\]</span> For the mice data:</p>
<p><span class="math display">\[\begin{eqnarray*}
        \hbox{Total SS } &amp;=&amp; (259-328.07)^2 + \cdots + (231-328.07)^2 + (394-328.07)^2 + \cdots + (454-328.07)^2 = 193459 \\
        \hbox{Error SS } &amp;=&amp; (259-217.43)^2 + \cdots + (231-217.43)^2 + (394-438.71)^2 + \cdots + (454-438.71)^2 = 22073 \\
        \hbox{Model SS } &amp;=&amp; 6(217.43-328.07)^2 + 6(438.71-328.07)^2 =  171386 \\
\end{eqnarray*}\]</span></p>
<p>To convert these sums of squares into variances (which we call mean squares), they must be divided by denominators noted above. These are degrees of freedom, and have the same relationship as the sums of squares do: <span class="math display">\[
\hbox{Total } df = \hbox{ Model } df + \hbox{ Error } df
\]</span></p>
<p>In our mice example, we have</p>
<p><span class="math display">\[
\hbox{Total } df = \hbox{ Model } df + \hbox{ Error } df
\]</span><br>
<br>
<br>
<br>
</p>
<p>We often summarize our calculations in a table (<span class="math inline">\(df\)</span> assuming equal sample sizes):</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Source</th>
<th><span class="math inline">\(df\)</span></th>
<th>SS</th>
<th>MS</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Model</td>
<td><span class="math inline">\(t-1\)</span></td>
<td>SSModel</td>
<td>MSModel</td>
</tr>
<tr class="even">
<td>Error</td>
<td><span class="math inline">\(t(n-1)\)</span></td>
<td>SSError</td>
<td>MSError</td>
</tr>
<tr class="odd">
<td>Total</td>
<td><span class="math inline">\(nt-1\)</span></td>
<td>SSTotal</td>
<td></td>
</tr>
</tbody>
</table>
<p>The MSError (usually called MSE) is our estimate of <span class="math inline">\(\sigma^2\)</span>. In our mice example, we get the table:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Source</th>
<th><span class="math inline">\(df\)</span></th>
<th>SS</th>
<th>MS</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Model</td>
<td>1</td>
<td>171386</td>
<td>171386</td>
</tr>
<tr class="even">
<td>Error</td>
<td>12</td>
<td>22073</td>
<td>1839</td>
</tr>
<tr class="odd">
<td>Total</td>
<td>13</td>
<td>193459</td>
<td></td>
</tr>
</tbody>
</table>
<p>To test H<span class="math inline">\(_0: \mu_1 = \mu_2\)</span> we use the F stat: <span class="math display">\[
F = \frac{\hbox{MSModel}}{\hbox{MSError}} = \frac{171386}{1839} = 93.2
\]</span> and we can add this to the table:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Source</th>
<th><span class="math inline">\(df\)</span></th>
<th>SS</th>
<th>MS</th>
<th>F</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Model</td>
<td>1</td>
<td>171386</td>
<td>171386</td>
<td>93.2</td>
</tr>
<tr class="even">
<td>Error</td>
<td>12</td>
<td>22073</td>
<td>1839</td>
<td></td>
</tr>
<tr class="odd">
<td>Total</td>
<td>13</td>
<td>193459</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>What we’ve just done is called an <strong>Analysis of Variance (ANOVA)</strong>, and the resulting table is called an ANOVA table. It’s a single hypothesis test to check whether the means across many groups are equal. Specifically, it’s testing:</p>
<p><br>
<br>
<br>
<br>
</p>
<p>We still have assumptions: - Independence between and among groups - Responses/errors are approximately normal - Variability across groups is about equal</p>
<p>We already know how to determine if <span class="math inline">\(F=93.2\)</span> is enough greater than 1 to determine there’s a difference–the <span class="math inline">\(F\)</span> distribution we used to test the equality of two variances in the last section. Our numerator and denominator degrees of freedom will be the Model <span class="math inline">\(df\)</span> and Error <span class="math inline">\(df\)</span>, respectively:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pf</span>(<span class="fl">93.2</span>,<span class="at">df1=</span><span class="dv">1</span>,<span class="at">df2=</span><span class="dv">12</span>,<span class="at">lower.tail=</span><span class="cn">FALSE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 5.232224e-07</code></pre>
</div>
</div>
<p>The p-value typically gets added to the table as well:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Source</th>
<th><span class="math inline">\(df\)</span></th>
<th>SS</th>
<th>MS</th>
<th>F</th>
<th>p-value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Model</td>
<td>1</td>
<td>171386</td>
<td>171386</td>
<td>93.2</td>
<td>0.0000005</td>
</tr>
<tr class="even">
<td>Error</td>
<td>12</td>
<td>22073</td>
<td>1839</td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>Total</td>
<td>13</td>
<td>193459</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<div style="page-break-after: always;"></div>
<p>This is the only time we’ll do an ANOVA by hand! Let’s do the same in R.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(<span class="fu">lm</span>(Time<span class="sc">~</span>Envr, <span class="at">data=</span>mice))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Analysis of Variance Table

Response: Time
          Df Sum Sq Mean Sq F value   Pr(&gt;F)    
Envr       1 171386  171386  93.173 5.24e-07 ***
Residuals 12  22073    1839                     
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
<p><strong>Example:</strong> Let’s now carry out the ANOVA on the handwashing data. We’ll start by writing the model and sketching the ANOVA table.</p>
<p><br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(<span class="fu">lm</span>(Bacteria<span class="sc">~</span>Method,<span class="at">data=</span>handwash))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Analysis of Variance Table

Response: Bacteria
          Df Sum Sq Mean Sq F value   Pr(&gt;F)   
Method     3  29882  9960.7  7.0636 0.001111 **
Residuals 28  39484  1410.1                    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
<div style="page-break-after: always;"></div>
<p>We could also use SAS:</p>
<pre><code>PROC IMPORT OUT= WORK.mice
DATAFILE= "C:\Users\Erin\OneDrive - University of Nebraska-Lincoln\STAT 801\Book Notes\mice.csv"
DBMS=CSV REPLACE;
GETNAMES=YES;
DATAROW=2; 
RUN;

proc glimmix data=mice;
  class Envr;
  model Time=Envr;
run;</code></pre>
<p>SAS <code>proc glimmix</code> uses a different numerical method to calculate the ANOVA, and so the SSTrt/SSError don’t exist in the same way.</p>
<p><img src="glimmix mice.jpg" class="img-fluid"></p>
<p>For the handwash data:</p>
<pre><code>
PROC IMPORT OUT= WORK.handwash
DATAFILE= "C:\Users\Erin\OneDrive - University of Nebraska-Lincoln\STAT 801\Book Notes\handwash.csv"
DBMS=CSV REPLACE;
GETNAMES=YES;
DATAROW=2; 
RUN;

proc glimmix data=handwash;
  class Method;
  model Bacteria=Method;
run;</code></pre>
<p><img src="handwash glimmix.jpg" class="img-fluid"></p>
<p>The reason I like SAS for ANOVA is because we can easily add fanciness:</p>
<pre><code>proc glimmix data=handwash;
  class Method;
  model Bacteria=Method;
  lsmeans Method/pdiff cl;
run;</code></pre>
<p><img src="handwash lsmeans.jpg" class="img-fluid"></p>
<p>Next, we’ll add some more details and formality to the ANOVA.</p>
</section>
<section id="the-completely-randomized-design" class="level2" data-number="5.3">
<h2 data-number="5.3" class="anchored" data-anchor-id="the-completely-randomized-design"><span class="header-section-number">5.3</span> The Completely Randomized Design</h2>
<p>Way back in the first section, we talked about the steps in a statistical investigation</p>
<ul>
<li><p>Step 1: Ask a research question</p></li>
<li><p>Step 2: Design a study and collect data</p></li>
<li><p>Step 3: Explore the data</p></li>
<li><p>Step 4: Draw inferences beyond the data</p></li>
<li><p>Step 5: Formulate conclusions</p></li>
<li><p>Step 6: Look back and look ahead</p></li>
</ul>
<p>As part of Step 2, we noted that we need to consider questions like ‘what variable(s) wil be measured’. This basically involves identifying the response variable as well as any explanatory variable(s). Now, let’s introduce some new terminology that really only becomes relevant once we are doing ANOVA.</p>
<p><strong>Example:</strong> Handwash, again. The student considered four treatments: water only, regular soap, antibacterial soap, and alcohol spray.</p>
<p>In this example, there is one <strong>factor.</strong></p>
<p><strong>Definition:</strong><br>
<br>
<br>
<br>
<br>
<br>
</p>
<p>In order to study the effect of the factor on the response, two or more values of the factor are considered. These values are called <strong>levels</strong>.</p>
<p><br>
<br>
<br>
</p>
<p>In some cases, there is more than one factor.</p>
<p><strong>Example:</strong> Two students at Queensland University of Technology, as a project for their statistics class, carried out an experiment to test the effect certain factors such as refrigeration, stem length, and water content have on the life of a cut rose. The students considered</p>
<ul>
<li>Stem length (15 cm or 25 cm)</li>
<li>Water content (tap water or tap water + citric acid)</li>
<li>Temperature (refrigerated or room temperature)</li>
</ul>
<p>The response measured was the number of days until death, and the goal was to determine the conditions that will extend rose life.</p>
<p>In this example, there are 3 factors:</p>
<p><br>
<br>
<br>
</p>
<p>Each factor has 2 levels:</p>
<p><br>
<br>
<br>
<br>
<br>
</p>
<div style="page-break-after: always;"></div>
<p>In multifactor experiments like this, we define a <strong>treatment</strong> as a combination of factor levels.</p>
<ul>
<li><p>Factors:<br>
<br>
<br>
<br>
</p></li>
<li><p>Levels:<br>
<br>
<br>
<br>
<br>
<br>
</p></li>
</ul>
<p>-Treatments:<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
</p>
<p>We also have to consider the <strong>treatment design</strong> and the <strong>experimental design.</strong></p>
<p><strong>Definition:</strong> The <strong>treatment design</strong></p>
<p><br>
<br>
<br>
<br>
<br>
<br>
</p>
<p><strong>Definition:</strong> The <strong>experimental design</strong></p>
<p><br>
<br>
<br>
<br>
<br>
<br>
<br>
</p>
<p>The experimental design should address the three basic principles underlying formal experimentation:</p>
<ul>
<li>Replication: a repetition of the basic experiment</li>
</ul>
<p><br>
<br>
<br>
<br>
</p>
<ul>
<li>Randomization: both allocation of experimental material and order in which individual runs/trials are performed</li>
</ul>
<p><br>
<br>
<br>
<br>
</p>
<ul>
<li>Control: control the effect of extraneous variables</li>
</ul>
<p><br>
<br>
<br>
<br>
</p>
<p>The first <strong>experimental design</strong> we’ll consider is the <strong>completely randomized design</strong> or CRD. The CRD is an experimental design because</p>
<p><br>
<br>
<br>
</p>
<p>The CRD is characterized by</p>
<p><br>
<br>
<br>
</p>
<p>The CRD may be combined with several different <strong>treatment designs</strong>. To explore the CRD in more detail, we’ll start with the simplest treatment design, the <strong>one-way design</strong>. The one-way design is so named because</p>
<p><br>
<br>
<br>
<br>
</p>
<div style="page-break-after: always;"></div>
<p>Within one-way designs there are four basic treatment structures:</p>
<ol type="1">
<li><p>Unstructured<br>
</p></li>
<li><p>Control versus other treatments<br>
</p></li>
<li><p>Quantitative<br>
</p></li>
<li><p>Other structure<br>
</p></li>
</ol>
<p><strong>Example:</strong> Handwash, again. The student considered four treatments: water only, regular soap, antibacterial soap, and alcohol spray. The student replicated each treatment 8 times.</p>
<ul>
<li><p><strong>Treatment Design:</strong></p>
<ul>
<li><p>Factor:</p></li>
<li><p>Levels:</p></li>
</ul></li>
<li><p><strong>Experimental Design:</strong></p>
<ul>
<li>Run 8 trials in a Completely Randomized Design</li>
</ul></li>
</ul>
<p>Here’s one possible sequence of trials:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 3%">
<col style="width: 3%">
<col style="width: 3%">
<col style="width: 3%">
<col style="width: 3%">
<col style="width: 3%">
<col style="width: 3%">
<col style="width: 3%">
<col style="width: 3%">
<col style="width: 3%">
<col style="width: 3%">
<col style="width: 3%">
<col style="width: 3%">
<col style="width: 3%">
<col style="width: 3%">
<col style="width: 3%">
<col style="width: 3%">
<col style="width: 3%">
<col style="width: 3%">
<col style="width: 3%">
<col style="width: 3%">
<col style="width: 3%">
<col style="width: 3%">
<col style="width: 3%">
<col style="width: 3%">
<col style="width: 3%">
<col style="width: 3%">
<col style="width: 3%">
<col style="width: 3%">
<col style="width: 3%">
<col style="width: 3%">
<col style="width: 3%">
</colgroup>
<tbody>
<tr class="odd">
<td>AL</td>
<td>RS</td>
<td>AB</td>
<td>W</td>
<td>W</td>
<td>AL</td>
<td>AB</td>
<td>RS</td>
<td>RS</td>
<td>RS</td>
<td>RS</td>
<td>AL</td>
<td>RS</td>
<td>AB</td>
<td>AB</td>
<td>AB</td>
<td>W</td>
<td>W</td>
<td>AB</td>
<td>AB</td>
<td>AL</td>
<td>W</td>
<td>RS</td>
<td>RS</td>
<td>AB</td>
<td>AL</td>
<td>W</td>
<td>W</td>
<td>AL</td>
<td>W</td>
<td>AL</td>
<td>AL</td>
</tr>
</tbody>
</table>
<p><br>
<br>
<br>
</p>
<div style="page-break-after: always;"></div>
<section id="crd-model-and-basic-analysis" class="level3" data-number="5.3.1">
<h3 data-number="5.3.1" class="anchored" data-anchor-id="crd-model-and-basic-analysis"><span class="header-section-number">5.3.1</span> CRD Model and Basic Analysis</h3>
<p>The <strong>CRD Model</strong> can be written in two different ways.</p>
<p><br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
</p>
<ul>
<li><p><span class="math inline">\(y_{ij}\)</span> = bacteria count for the <span class="math inline">\(j^{th}\)</span> trial after handwashing the <span class="math inline">\(i^{th}\)</span> method</p></li>
<li><p><span class="math inline">\(\mu\)</span> = overall mean bacteria count</p></li>
<li><p><span class="math inline">\(\tau_i\)</span> = treatment effect of method <span class="math inline">\(i\)</span> = additional amount of bacteria observed using handwashing method <span class="math inline">\(i\)</span></p></li>
<li><p><span class="math inline">\(\epsilon_{ij}\)</span> = random error = additional amount of bacteria in the <span class="math inline">\(j^{th}\)</span> trial using handwashing method <span class="math inline">\(i\)</span></p></li>
</ul>
<p><strong>Example:</strong> A donut manufacturer wants to see if the type of fat used to fry the donuts has any impact on the amount of fat absorbed by the donuts. The manufacturer has two types of animal fat and two types of vegetable fat that they would like to compare. They also have available 4 fryers, which can each fry 1 batch of 18 donuts at a time. They plan to measure the amount of fat absorbed in each batch.They have the resources to test 24 total batches of donuts.</p>
<ul>
<li><p><strong>Treatment Design:</strong></p>
<ul>
<li><p>Factor:</p></li>
<li><p>Levels:</p></li>
</ul></li>
<li><p><strong>Experimental Design:</strong></p>
<ul>
<li>Run 6 batches of each fat in a Completely Randomized Design</li>
</ul></li>
</ul>
<div style="page-break-after: always;"></div>
<p>For this particular treatment design, there are several hypothesis tests that may be of interest. Write out in the symbols the null and alternative hypotheses for the following specified objectives. Reminder: Fats 1 and 2 are animal fats and Fats 3 and 4 are vegetable fats.</p>
<ol type="1">
<li>Are there differences among the four fats with respect to the amount of fat absorbed?</li>
</ol>
<p><br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
</p>
<ol start="2" type="1">
<li>Do the vegetable fats differ from the animal fats in the amount of fat absorbed?</li>
</ol>
<p><br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
</p>
<ol start="3" type="1">
<li>Are there differences between the two animal fats? Are there differences between the two vegetable fats?</li>
</ol>
<p><br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
</p>
<div style="page-break-after: always;"></div>
<p>We’ve already seen how to fit the basic ANOVA in R and SAS.</p>
<pre><code>data donut; 
  do type=1 to 4; 
    input absorb @@;
    output;
  end;
   datalines; 
   164 178 175 155
   172 191 193 166
   168 197 178 149
   177 182 171 164
   156 185 163 170
   195 177 176 168
   ;

proc glimmix data=donut;
  class type; 
  model absorb=type; 
  lsmeans type/pdiff cl;
run;</code></pre>
<p><img src="donut glimmix.jpg" class="img-fluid"></p>
<div style="page-break-after: always;"></div>
</section>
<section id="treatment-comparisons-and-contrasts" class="level3" data-number="5.3.2">
<h3 data-number="5.3.2" class="anchored" data-anchor-id="treatment-comparisons-and-contrasts"><span class="header-section-number">5.3.2</span> Treatment Comparisons and Contrasts</h3>
<p>We can see in the results above that we may reject the overall hypothesis that the four treatments produce the same mean fat absorption (<span class="math inline">\(F=5.41\)</span>, p-value<span class="math inline">\(=0.0069\)</span>). But, this doesn’t address the hypotheses you constructed earlier. Remember, we also considered:</p>
<ul>
<li><p>Do the vegetable fats differ from the animal fats in the amount of fat absorbed?</p></li>
<li><p>Are there differences between the two animal fats?</p></li>
<li><p>Are there differences between the two vegetable fats?</p></li>
</ul>
<p>The output above allows us to address some of these questions, but not the one regarding vegetable fats versus animal fats. Let’s look at a more general way to construct treatment comparisons.</p>
<p><strong>Contrasts</strong></p>
<p>A well-thought-out treatment design’s objectives can usually be stated in terms of a set of <strong>contrasts</strong>. This is usually an important goal in planning the design, and contrasts are constructed before data are collected.</p>
<p>A <strong>contrast</strong> is</p>
<p><br>
<br>
<br>
<br>
<br>
</p>
<p>Estimates of the contrast are obtained by substituting in the sample means</p>
<p><br>
<br>
<br>
<br>
</p>
<p>We may also obtain standard errors of the contrast estimate</p>
<p><br>
<br>
<br>
<br>
</p>
<p>Standard errors may then be used to carry out tests and construct confidence intervals.</p>
<p><br>
<br>
<br>
<br>
<br>
<br>
</p>
<p>The contrasts of interest depend on the basic treatment design structure and the goals of the experiment. Remember, the four basic structures are</p>
<ol type="1">
<li><p>Unstructured</p></li>
<li><p>Control versus other treatments</p></li>
<li><p>Quantitative</p></li>
<li><p>Other structure</p></li>
</ol>
<p>Let’s first consider Unstructured designs, because these are the simplest.</p>
<section id="unstructured-treatment-designs-and-all-pairwise-comparisons" class="level4" data-number="5.3.2.1">
<h4 data-number="5.3.2.1" class="anchored" data-anchor-id="unstructured-treatment-designs-and-all-pairwise-comparisons"><span class="header-section-number">5.3.2.1</span> Unstructured Treatment Designs and All Pairwise Comparisons</h4>
<p><strong>Example:</strong> Handwashing, again. The student considered four treatments: water only, regular soap, antibacterial soap, and alcohol spray. The student replicated each treatment 8 times.</p>
<ul>
<li><p><strong>Treatment Design:</strong></p>
<ul>
<li><p>Factor:</p></li>
<li><p>Levels:</p></li>
</ul></li>
<li><p><strong>Experimental Design:</strong></p>
<ul>
<li>Run 8 trials in a Completely Randomized Design</li>
</ul></li>
</ul>
<p>In designs like this without structure, we are typically interested in <strong>all pairwise comparisons</strong>.</p>
<p><br>
<br>
<br>
<br>
<br>
<br>
</p>
<p>There are multiple methods for making such comparisons. The simplest is the <strong>least significant difference</strong> (LSD), also called the unprotected LSD. It’s easy, but the Type I error rate can be badly inflated (we’ll talk more about this in a bit).</p>
<p><br>
<br>
<br>
<br>
<br>
</p>
<p>A (slightly) more conservative option is <strong>Fisher’s protected LSD</strong>.</p>
<p><br>
<br>
<br>
</p>
<p>We’ve already seen these, but let’s add even more fanciness!</p>
<pre><code>proc glimmix data=handwash;
  class Method;
  model Bacteria=Method;
  lsmeans Method/pdiff cl lines plot=diffplot;
run;</code></pre>
<p><img src="handwash lsd.jpg" class="img-fluid"></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="handwash lines.jpg" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="handwash diffogram.jpg" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>This plot is called a <strong>diffogram</strong> and is a way to visualize differences among the treatments.</p>
<p>So these plots are awesome, and the output is easy to interpret! Why do we care about anything other than the LSD? The big issue is Type I error rate, and it can be a concern for pairwise comparisons as well as more complicated contrasts.</p>
<p><strong>Multiple Comparisons</strong></p>
<p>If more than one comparison is made among the treatment means, then we have multiple comparisons which can lead to the problem of <strong>multiplicity</strong>.</p>
<p><strong>Definition:</strong> <strong>Multiplicity</strong> is</p>
<p><br>
<br>
<br>
</p>
<p>For a single test, the significance level of a Type I error is called a <strong>comparison-wise</strong> error rate. This means</p>
<p><br>
<br>
<br>
<br>
</p>
<p>But, if we have multiple tests, the Type I errors for these tests accumulate. This accumulated rate is the called the <strong>experiment-wise</strong> error rate. This is</p>
<p><br>
<br>
<br>
<br>
</p>
<p>But, the errors don’t just add up. They accumulate in a power-type relationship. Consider a situation with a comparison-wise error rate of <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(c\)</span> independent comparisons. Then, the experiment-wise error rate is</p>
<p><br>
<br>
<br>
<br>
</p>
<p>For example, consider a situation with <span class="math inline">\(\alpha=0.05\)</span> and 5 independent comparisons (there are as many independent comparisons as there are <span class="math inline">\(df\)</span> for treatment). In that case:</p>
<p><br>
<br>
<br>
<br>
<br>
<br>
</p>
<p>We can control the experiment-wise error rate by setting it to a pre-specified value <span class="math inline">\(\alpha\)</span> (maybe 0.05) and then solving for the comparison-wise error rate, assuming <span class="math inline">\(c\)</span> independent comparisons. So, for example, if <span class="math inline">\(\alpha=0.05\)</span> and <span class="math inline">\(c=5\)</span>,</p>
<p><br>
<br>
<br>
<br>
<br>
<br>
</p>
<p>We’d then use this as the critical value (cut-off) value for our independent treatment comparisons.</p>
<p>But here’s another issue. If the comparisons are not independent (which they aren’t in all pairwise-comparisons, and often aren’t in pre-planned contrasts of interest), then the experiment-wise error rate is actually even bigger than we see above. What can we do?</p>
<p>There are a multitude of multiple comparison procedures which control the overall experiment-wise error rate, which have different pros and cons. We’re only going to the talk about a few.</p>
<p><strong>Tukey’s HSD</strong>: Tukey’s Honestly Significant Difference (HSD) procedure is based on the studentized range statistic. To get this HSD from SAS:</p>
<pre><code>proc glimmix data=handwash;
  class Method;
  model Bacteria=Method;
  lsmeans Method/pdiff cl adjust=tukey;
run;</code></pre>
<p><img src="handwash tukey.jpg" class="img-fluid"></p>
<p>We could also request lines and the diffogram; they would be adjusted as well.</p>
<div style="page-break-after: always;"></div>
<p>The other multiple comparison procedures we’ll discuss are used with other treatment design structures. The three other one-way treatment design structures are:</p>
<ol type="1">
<li><p>Control versus other treatments</p></li>
<li><p>Quantitative (we’ll put a pin in this one for now)</p></li>
<li><p>Other structure</p></li>
</ol>
</section>
<section id="control-versus-other-treatments" class="level4" data-number="5.3.2.2">
<h4 data-number="5.3.2.2" class="anchored" data-anchor-id="control-versus-other-treatments"><span class="header-section-number">5.3.2.2</span> Control versus other treatments</h4>
<p>In some scenarios, one of the factor levels acts as a control treatment for some or all of the remaining levels. Often, we are interested in comparing all of the treatments against the control but not against each other. This means there are</p>
<p><strong>Dunnett’s</strong> procedures is a modification to the two-sample <span class="math inline">\(t\)</span> test that is used when comparing all treatments against a control.</p>
<p><strong>Example:</strong> Sections of tomato plant tissue were grown in culture with differing amounts and types of sugars with five replications of four treatments. The treatments were: control, 3% glucose, 3% fructose, and 3% sucrose.</p>
<ul>
<li><p><strong>Treatment Design:</strong></p>
<ul>
<li><p>Factor:</p></li>
<li><p>Levels:</p></li>
</ul></li>
<li><p><strong>Experimental Design:</strong></p>
<ul>
<li></li>
</ul></li>
</ul>
<p>In a situation like this, we may be interested in comparing each of the sugar treatments to the control.</p>
<pre><code>   data tomato;
     input trt $ growth @@;
     datalines;
     control 45 glucose 25 fructose 28 sucrose 31
     control 39 glucose 28 fructose 31 sucrose 37
     control 40 glucose 30 fructose 24 sucrose 35
     control 45 glucose 29 fructose 28 sucrose 33
     control 42 glucose 33 fructose 27 sucrose 34
   ;
    proc glimmix data=tomato;
      class trt;
      model growth=trt;
      lsmeans trt/diff=control('control') cl adjust=dunnett plot=controlplot;
    run;</code></pre>
<p>Note that unless otherwise specified, SAS will assume the first treatment level (alphabetically or numerically) is the control.</p>
<p><img src="tomato lsmeans.jpg" class="img-fluid"></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="tomato control plot.jpg" class="img-fluid quarto-figure quarto-figure-center figure-img" width="423"></p>
</figure>
</div>
</section>
<section id="treatment-designs-with-other-structure" class="level4" data-number="5.3.2.3">
<h4 data-number="5.3.2.3" class="anchored" data-anchor-id="treatment-designs-with-other-structure"><span class="header-section-number">5.3.2.3</span> Treatment Designs with (other) Structure</h4>
<p>This is where the donut example fits in. There isn’t a true control, but we also may not care about all pairwise comparisons. Instead, we had some specific, pre-planned comparisons of interest:</p>
<ul>
<li><p>Do the vegetable fats differ from the animal fats in the amount of fat absorbed?</p></li>
<li><p>Are there differences between the two animal fats?</p></li>
<li><p>Are there differences between the two vegetable fats?</p></li>
</ul>
<p>Why pre-plan comparisons?</p>
<p><br>
<br>
<br>
<br>
</p>
<p>Earlier, we wrote out the hypotheses of interest corresponding to these comparisons:</p>
<p><br>
<br>
<br>
<br>
<br>
</p>
<p>There are three options available in SAS to test these hypotheses and/or construct confidence intervals:</p>
<ul>
<li><p><code>contrast</code> statement</p></li>
<li><p><code>estimate</code> statement</p></li>
<li><p><code>lsmestimate</code> statement</p></li>
</ul>
<p>All three statements involve specifying the coefficients of the treatment effects/treatment means. Let’s look at the comparison of vegetable and animal fats.</p>
<p><br>
&nbsp;<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
</p>
<p>and two different contrast statements we could write:</p>
<div style="page-break-after: always;"></div>
<pre><code>    proc glimmix data=donut;
      class type;
      model absorb=type;
      contrast "animal vs veg" type 1 1 -1 -1;
      contrast "animal vs veg 2" type 0.5 0.5 -0.5 -0.5;
    run;</code></pre>
<p>Both give the same results!</p>
<pre><code>                          Contrasts
    
    Num      Den
    Label                DF       DF    F Value    Pr &gt; F
    
    animal vs veg         1       20       5.37    0.0313
    animal vs veg 2       1       20       5.37    0.0313
    </code></pre>
<p>Let’s try them with <code>estimate</code> statements, and add a third option:</p>
<pre><code>    estimate "animal vs veg" type 1 1 -1 -1;
    estimate "animal vs veg 2" type 0.5 0.5 -0.5 -0.5;
    estimate "animal vs veg 3" type 1 1 -1 -1/divisor=2;

                                   Estimates
    
                                   Standard
    Label              Estimate       Error       DF    t Value    Pr &gt; |t|
    
    animal vs veg       19.0000      8.2016       20       2.32      0.0313
    animal vs veg 2      9.5000      4.1008       20       2.32      0.0313
    animal vs veg 3      9.5000      4.1008       20       2.32      0.0313
    
                      type Least Squares Means
    
                        Standard
    type    Estimate       Error       DF    t Value    Pr &gt; |t|
    
    1         172.00      4.1008       20      41.94      &lt;.0001
    2         185.00      4.1008       20      45.11      &lt;.0001
    3         176.00      4.1008       20      42.92      &lt;.0001
    4         162.00      4.1008       20      39.50      &lt;.0001
    
    </code></pre>
<p>What’s going on?</p>
<p><br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
</p>
<p>Suppose for some reason we wanted to test whether fats 1-3 (collectively) were different from fat 4.</p>
<p><br>
<br>
<br>
<br>
<br>
<br>
</p>
<p>The way we write the <code>estimate</code> statement really matters here:</p>
<pre><code>    estimate "first 3 vs last" type 0.33 0.33 0.33 -1;
    estimate "first 3 vs last" type 1 1 1 -3/divisor=3;

                                   Estimates
    
                                   Standard
    Label              Estimate       Error       DF    t Value    Pr &gt; |t|
    
    first 3 vs last     Non-est           .        .        .         .
    first 3 vs last     15.6667      4.7352       20       3.31      0.0035</code></pre>
<p>We do still have a multiplicity issue, because we are interested in three pre-planned contrasts. We can use the <strong>Sidak</strong> adjustment to control experiment-wise error rate:</p>
<pre><code>    estimate "1 vs 2" type 1 -1 0 0,
             "3 vs 4" type 0 0 1 -1,
             "animal vs veg" type 0.5 0.5 -0.5 -0.5/adjust=sidak;</code></pre>
<div style="page-break-after: always;"></div>
<pre><code>                                  Estimates
    
                                   Standard
    Label              Estimate       Error       DF    t Value    Pr &gt; |t|
    
    animal vs veg 2      9.5000      4.1008       20       2.32      0.0313
    
    

                                  Estimates
                        Adjustment for Multiplicity: Sidak
    
                                 Standard
    Label            Estimate       Error       DF    t Value    Pr &gt; |t|     Adj P
    
    1 vs 2           -13.0000      5.7994       20      -2.24      0.0365    0.1055
    3 vs 4            14.0000      5.7994       20       2.41      0.0255    0.0745
    animal vs veg      9.5000      4.1008       20       2.32      0.0313    0.0909
    </code></pre>
<p>Finally, we can use the <code>lsmestimate</code> statement. <code>lsmestimate</code> basically does the same thing as <strong>estimate</strong> but it allows for more complicated models than we have yet encountered. For a CRD, the output of the two should be identical, though <code>lsmestimate</code> does have some additional options (and slightly different syntax).</p>
<pre><code>    lsmestimate type "1 vs 2" 1 -1 0 0,
                     "3 vs 4" 0 0 1 -1,
                     "animal vs veg"  0.5 0.5 -0.5 -0.5/joint;</code></pre>
<p>The <code>joint</code> option gives a joint test for whether the LSMeans are the same, which is the same as the overall test in the simple designs like the CRD. There are also multiple comparison adjustments available in <code>lsmestimate</code>.</p>
<p><strong>What happens if you don’t pre-plan?</strong> Ideally, comparisons are set up ahead of time based on specific research questions. If comparisons are selected after examining the data, most researchers construct tests that correspond to large differences in the means. These differences could be due to a real treatment effect, or they could be due to random error. Picking the largest differences to compare will inflate Type I error. If you do want to look at comparisons suggested by the data (post hoc comparisons), then you should replace the <span class="math inline">\(t\)</span> test with a VERY conservative test called the <strong>Scheffé</strong> test. Scheffè works for pairwise comparisons or contrasts. We request it by adding the <code>adjust=scheffe</code> option.</p>
<p>To see how conservative Scheffè is, let’s look at the comparison of Fats 1 vs 2 (and pretend that Fat 1 is a control, just for illustration.</p>
<div style="page-break-after: always;"></div>
<div class="center">
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: center;">Adjustment Type</th>
<th style="text-align: center;">p-value</th>
<th style="text-align: center;">Lower CL</th>
<th style="text-align: center;">Upper CL</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Unadjusted</td>
<td style="text-align: center;">0.0365</td>
<td style="text-align: center;">-25.0974</td>
<td style="text-align: center;">-0.9026</td>
</tr>
<tr class="even">
<td style="text-align: center;">Tukey</td>
<td style="text-align: center;">0.1462</td>
<td style="text-align: center;">-29.2320</td>
<td style="text-align: center;">3.2320</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Dunnett</td>
<td style="text-align: center;">0.0908</td>
<td style="text-align: center;">-27.7326</td>
<td style="text-align: center;">1.7326</td>
</tr>
<tr class="even">
<td style="text-align: center;">Scheffè</td>
<td style="text-align: center;">0.2044</td>
<td style="text-align: center;">-30.6813</td>
<td style="text-align: center;">4.6813</td>
</tr>
</tbody>
</table>
</div>
<p>What do you notice?</p>
<p><br>
<br>
<br>
</p>
<p>Which one to use? It depends. Is it more important to control the comparison-wise error rate or experiment-wise error rate? That will depend on the situation. Keep in mind that the more conservative the adjustment, the lower the power. That is, the more likely you are to make a Type II error.</p>
<p><strong>Example:</strong> A study is being planned to study the ability of a liberty ship artificial reef to attract and hold macrobenthic epifauna. One of the variables of interest is the density of oysters, and researchers are interested in comparing different locations on the artificial reef. There are 6 locations</p>
<ul>
<li>Floors of holds</li>
<li>Sides of holds</li>
<li>Starboard deck</li>
<li>Starboard side</li>
<li>Port side</li>
<li>Port deck</li>
</ul>
<p>and 12 observations were randomly sampled at each location.</p>
<ul>
<li><p><strong>Treatment Design:</strong></p>
<ul>
<li><p>Factor:</p></li>
<li><p>Levels:</p></li>
</ul></li>
<li><p><strong>Experimental Design:</strong></p></li>
<li><p><strong>Model:</strong></p></li>
</ul>
<p><br>
<br>
<br>
<br>
</p>
<p>The researcher is particularly interested in some specific comparisons. We’ll write the contrasts to address each one.</p>
<ol type="1">
<li>Floors versus sides of holds</li>
</ol>
<p><br>
<br>
<br>
<br>
<br>
</p>
<ol start="2" type="1">
<li>Port versus starboard</li>
</ol>
<p><br>
<br>
<br>
<br>
<br>
</p>
<ol start="3" type="1">
<li>Deck versus sides, except for holds</li>
</ol>
<p><br>
<br>
<br>
<br>
<br>
</p>
<ol start="4" type="1">
<li>Port sides versus starboard sides</li>
</ol>
<p><br>
<br>
<br>
<br>
<br>
</p>
<ol start="5" type="1">
<li>Port decks versus starboard decks</li>
</ol>
<p><br>
<br>
<br>
<br>
<br>
</p>
<div style="page-break-after: always;"></div>
<ol start="6" type="1">
<li>Port side versus port deck</li>
</ol>
<p><br>
<br>
<br>
<br>
<br>
<br>
</p>
<ol start="7" type="1">
<li>Starboard side versus starboard deck</li>
</ol>
<p><br>
<br>
<br>
<br>
<br>
<br>
</p>
</section>
</section>
<section id="model-adequacy" class="level3" data-number="5.3.3">
<h3 data-number="5.3.3" class="anchored" data-anchor-id="model-adequacy"><span class="header-section-number">5.3.3</span> Model Adequacy</h3>
<p>Everything we’ve done so far is based on the assumptions that the observations are adequately described by the model</p>
<p><br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
</p>
<p>If these assumptions are not valid, then the estimates of the treatment means and tests of significance from the ANOVA will be affected. We typically use <strong>residuals</strong> as a basis of our diagnostic tools.</p>
<p>The <strong>residual</strong> for observation <span class="math inline">\(j\)</span> in treatment <span class="math inline">\(i\)</span> is defined as:<br>
<br>
<br>
</p>
<p>Examining residuals should be an automatic part of the analysis of variance, and can be used to check the assumptions of common variance and normality of the error term. The assumptions can be checked using a visual inspection or formally through tests, and SAS makes it very easy to do so.</p>
<p>There’s a lot of code here, but we’ll examine it piece-by-piece.</p>
<pre><code>    proc glimmix data=donut plot=residualpanel;
      class type;
      model absorb=type; 
      random _residual_/group=type;
      covtest homogeneity;
      output out=donutout pred=pred residual=resid;
    run;</code></pre>
<p>Here’s what the options are doing:</p>
<ul>
<li><p><code>plot=residualpanel</code> produces a set of residual plots</p></li>
<li><p><code>random _residual_/group=type</code> tells SAS you want to estimate a residual variance for each treatment group (i.e., get separate estimates of <span class="math inline">\(\sigma^2\)</span> from each treatment group)</p></li>
<li><p><code>covtest</code> produces a hypothesis test for comparing variances, and <code>homogeneity</code> says you want to test whether they are all equal</p></li>
<li><p><code>output</code> produces a new data set (called <code>donutout</code>) which contains the observed residuals (<code>resid</code>) and predicted values (<code>pred</code>)</p></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Donut-residual-panel.jpg" class="img-fluid figure-img" style="width:70.0%" alt="The graphic contains four plots used to assess the fit of the ANOVA model: a scatterplot of the residuals versus the predictor, a histogram of the residuals with the normal distribution overlayed, a quantile-quantile plot of the residuals, and a box plot of the residuals."></p>
<figcaption>Residual panel for the donut data</figcaption>
</figure>
</div>
<p>The upper left hand plot shows</p>
<p><br>
<br>
<br>
<br>
</p>
<p>The other three plots all deal with the normality assumption.</p>
<p><br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
</p>
<p>We can also use <code>proc univariate</code> to check normality, using the <code>donoutout</code> data set we created above.</p>
<pre><code>    proc univariate data=donutout plot normal;
      var resid;
    run;</code></pre>
<p>Here’s part of the output</p>
<pre><code>                           Tests for Normality
    
    Test                  --Statistic---    -----p Value------
    
    Shapiro-Wilk          W     0.972165    Pr &lt; W      0.7205
    </code></pre>
<p>The Shapiro-Wilk test is the most commonly used test for normality. A highly significant p-value would indicate there may be a problem with non-normality.</p>
<p>What happens if we do see a large departure from normality?</p>
<p><br>
<br>
<br>
<br>
</p>
<div style="page-break-after: always;"></div>
<p>The other assumption we can check with residuals is the constant variance assumption, also called the assumption of homogeneous variances. From the SAS output</p>
<pre><code>           Covariance Parameter Estimates
                                           Standard
    Cov Parm         Group     Estimate       Error
    Residual (VC)    type 1      178.00      112.58
    Residual (VC)    type 2     60.4000     38.2003
    Residual (VC)    type 3     97.6000     61.7277
    Residual (VC)    type 4     67.6000     42.7540
    
          Type III Tests of Fixed Effects
                  Num      Den
    Effect         DF       DF    F Value    Pr &gt; F
    type            3       20       8.39    0.0008
    
               Tests of Covariance Parameters
              Based on the Restricted Likelihood
    Label            DF    -2 Res Log Like      ChiSq    Pr &gt; ChiSq    Note
    Homogeneity       3             156.21       1.90        0.5942    DF
    
    DF: P-value based on a chi-square with DF degrees of freedom.</code></pre>
<p>The covariance parameter estimates are the estimates of the variances for each of the four treatments, along with their standard errors. What do you notice?</p>
<p><br>
<br>
<br>
<br>
</p>
<p>The Tests of Covariance Parameters is testing the null hypothesis that the four variances are equal, versus the alternative that at least one is different.</p>
<p><br>
<br>
<br>
<br>
</p>
<p>In general, moderate departures from normality are of little concern, especially with the CRD. Nonconstant variance can be a bigger issue, but there are things we can do (like transformations) to stabilize the variance.</p>
<div style="page-break-after: always;"></div>
</section>
<section id="power-for-the-completely-randomized-design" class="level3" data-number="5.3.4">
<h3 data-number="5.3.4" class="anchored" data-anchor-id="power-for-the-completely-randomized-design"><span class="header-section-number">5.3.4</span> Power for the Completely Randomized Design</h3>
<p>With multiple comparisons, we talked about Type I error and its probability. We defined Type I error as rejecting the null hypothesis when it is, in fact, true. If P(Type I error) = <span class="math inline">\(\alpha\)</span>, then P(no Type I error) = <span class="math inline">\(1-\alpha\)</span>.</p>
<p>There is another kind of error – Type II error. A Type II error occurs when H<span class="math inline">\(_0\)</span> is not rejected, but H<span class="math inline">\(_0\)</span> is actually false. Earlier this semester, we summarized these two types of errors in a table:</p>
<p><br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
</p>
<p>Earlier in STAT 801 we’ve said that we can “set” the probability of a Type I error. Anytime we say we’ll reject H<span class="math inline">\(_0\)</span> if the p-value <span class="math inline">\(&lt; \alpha\)</span>, we’re setting P(Type I error) = <span class="math inline">\(\alpha\)</span>. What about Type II error? We generally call the probability of a Type II error <span class="math inline">\(\beta\)</span>, P(Type II error) = <span class="math inline">\(\beta\)</span>. The problem is we can’t “set” both <span class="math inline">\(\beta\)</span> and <span class="math inline">\(\alpha\)</span> without some other complications.</p>
<p>We are typically interested in the <strong>power</strong> of a test:</p>
<p><br>
<br>
<br>
<br>
<br>
</p>
<p>Let’s explore this via simulation. Consider a two-sample <span class="math inline">\(t\)</span>-test. In Canvas, there is an R file called <code>simulation example.R</code>.</p>
<ul>
<li><p>In the program, we’re generating <span class="math inline">\(n_1=20\)</span> normal random variables with <span class="math inline">\(\mu_1=10\)</span>, <span class="math inline">\(\sigma^2=25\)</span> and <span class="math inline">\(n_2=20\)</span> normal random variables with <span class="math inline">\(\mu_2=10\)</span>, <span class="math inline">\(\sigma^2=25\)</span>.</p></li>
<li><p>Carry out the t-test (code already included) and observe the p-value. Using <span class="math inline">\(\alpha=0.10\)</span>, what is your decision?</p></li>
<li><p>Run the program 9 more times, so you have a total of 10 p-values. How many times out of 10 did you reject H<span class="math inline">\(_0\)</span>?</p>
<p>What does this estimate?</p></li>
</ul>
<div style="page-break-after: always;"></div>
<ul>
<li><p>Edit the program to generate data with <span class="math inline">\(\mu_1=10\)</span> and <span class="math inline">\(\mu_2=12\)</span> (still with <span class="math inline">\(n_1=n_2=20\)</span> and <span class="math inline">\(\sigma^2=25\)</span>). Run the program 10 times total. How many times did you reject H<span class="math inline">\(_0\)</span>, using <span class="math inline">\(\alpha=0.10\)</span>?</p></li>
<li><p>Edit the program to generate data with <span class="math inline">\(\mu_1=10\)</span> and <span class="math inline">\(\mu_2=15\)</span> (still with <span class="math inline">\(n_1=n_2=20\)</span> and <span class="math inline">\(\sigma^2=25\)</span>). Run the program 10 times total. How many times did you reject H<span class="math inline">\(_0\)</span>, using <span class="math inline">\(\alpha=0.10\)</span>?</p></li>
<li><p>Edit the program to generate data with <span class="math inline">\(\mu_1=10\)</span> and <span class="math inline">\(\mu_2=20\)</span> (still with <span class="math inline">\(n_1=n_2=20\)</span> and <span class="math inline">\(\sigma^2=25\)</span>). Run the program 10 times total. How many times did you reject H<span class="math inline">\(_0\)</span>, using <span class="math inline">\(\alpha=0.10\)</span>?</p></li>
</ul>
<p>What do you observe as <span class="math inline">\(\mu_1\)</span> and <span class="math inline">\(\mu_2\)</span> get further apart?</p>
<p><br>
<br>
<br>
<br>
</p>
<p>Now let’s try the following:</p>
<ul>
<li><p>Edit the program to generate data with <span class="math inline">\(\mu_1=10\)</span> and <span class="math inline">\(\mu_2=12\)</span>, but with <span class="math inline">\(\sigma^2=1\)</span> (still with <span class="math inline">\(n_1=n_2=20\)</span>). Run the program 10 times total. How many times did you reject H<span class="math inline">\(_0\)</span>, using <span class="math inline">\(\alpha=0.10\)</span>?</p></li>
<li><p>Edit the program to generate data with <span class="math inline">\(\mu_1=10\)</span> and <span class="math inline">\(\mu_2=20\)</span>, but with <span class="math inline">\(\sigma^2=625\)</span> (still with <span class="math inline">\(n_1=n_2=20\)</span>). Run the program 10 times total. How many times did you reject H<span class="math inline">\(_0\)</span>, using <span class="math inline">\(\alpha=0.10\)</span>?</p></li>
</ul>
<p>What do observe as <span class="math inline">\(\sigma^2\)</span> gets larger or smaller?</p>
<p><br>
<br>
<br>
<br>
</p>
<p><strong>Power</strong> is the probability of rejecting H<span class="math inline">\(_0\)</span> when it is really false. It is a function of several quantities:</p>
<ul>
<li><br>
</li>
<li><br>
</li>
<li><br>
</li>
<li><br>
</li>
</ul>
<p>Power analyses usually focus on calculating the sample size required to achieve a particular power. What do you think would happen if instead of using <span class="math inline">\(n_1=n_2=20\)</span> we used <span class="math inline">\(n_1=n_2=10\)</span>?</p>
<p><br>
</p>
<div style="page-break-after: always;"></div>
<p>What do you think would happen if instead of using <span class="math inline">\(n_1=n_2=20\)</span> we used <span class="math inline">\(n_1=n_2=40\)</span>?</p>
<p><br>
<br>
<br>
</p>
<p>What do you think would happen if instead of using <span class="math inline">\(n_1=n_2=20\)</span> we used <span class="math inline">\(n_1=10\)</span> and <span class="math inline">\(n_2=30\)</span>?</p>
<p><br>
<br>
<br>
</p>
<p>In some simple situations, we can SAS procs to do power calculations. There are two: <code>PROC POWER</code> and <code>PROC GLMPOWER</code>. We’ll use <code>PROC POWER</code>. This proc will do power calculations for two sample <span class="math inline">\(t\)</span> tests and ANOVA.</p>
<p>For a two-sample <span class="math inline">\(t\)</span> test, the basic code is:</p>
<pre><code>        proc power;
          twosamplemeans test=diff
          alpha=
          stddev=
          meandiff=
          npergroup=
          power=               ;
        run;</code></pre>
<p>We’ll need to supply values for alpha, stddev, and meandiff. We can either supply a value for npergroup and use <code>power=.</code> or supply a value for power and use <code>npergroup=.</code></p>
<p>We could also add the lines</p>
<ul>
<li><p><code>plot x=power min=0.5 max=0.95;</code> (for <code>ntotal=.</code>)</p></li>
<li><p><code>x=n min= max= ;</code> (for <code>power=.</code>)</p></li>
</ul>
<p>Let’s try this, going back to our example with <span class="math inline">\(\mu_1=10\)</span>, <span class="math inline">\(\mu_2=12\)</span>, and <span class="math inline">\(\sigma^2=25\)</span>.</p>
<p><br>
<br>
<br>
</p>
<div style="page-break-after: always;"></div>
<p>We can also use <code>PROC POWER</code> for ANOVA and contrasts. This time, the basic code is:</p>
<pre><code>    proc power;
      onewayanova
      alpha=
      stddev=
      groupmeans=  |   |
      ntotal=
      power=
      contrast= (     );
    run;</code></pre>
<p>Let’s go back to the donut data. In that example, the MSE was 100.90, so we’ll use <span class="math inline">\(\sigma=10\)</span> as a guess for future experiments. We observed sample means of <span class="math inline">\(\overline y_{1\cdot}=172\)</span>, <span class="math inline">\(\overline y_{2\cdot}=185\)</span>, <span class="math inline">\(\overline y_{3\cdot}=176\)</span>, and <span class="math inline">\(\overline y_{4\cdot}=162\)</span>. We can certainly use these as guesses for future experiments. We’ll consider the contrast testing animal fats versus vegetable fats. We could also look at the overall test.</p>
<p><br>
<br>
<br>
</p>
<p>We can also add plot statements here.</p>
<p><br>
<br>
<br>
</p>
<p>But, we don’t actually have to have guesses for the treatment means. We do have to have an idea of how large a difference we want to be able to detect. With our example data, we had a animal fat mean of 178.5 and a vegetable fat mean of 169. This is a difference of 9.5.</p>
<p><br>
<br>
<br>
</p>
<p>We could also the consider potential differences we might observe in pairwise differences.</p>
<p><br>
<br>
<br>
</p>
</section>
</section>
<section id="block-designs" class="level2" data-number="5.4">
<h2 data-number="5.4" class="anchored" data-anchor-id="block-designs"><span class="header-section-number">5.4</span> Block Designs</h2>
<p>Up to now, we’ve concentrated on analyzing data coming from various <strong>treatment</strong> designs. We’ve considered multiple flavors of one-way designs (unstructured, control vs others, regression, other structure). In all cases though, we’ve been using the same <strong>experimental</strong> design: the completely randomized design (CRD). Now, we change our focus to other experimental designs. The treatment designs will be those we’ve seen before, and we’ll continue to analyze treatment effects using methods we’ve already discussed.</p>
<p>With a shift to experimental designs, we’ll be considering</p>
<p><br>
<br>
<br>
</p>
<p>This also means</p>
<p><br>
<br>
</p>
<p>We’re going to cover the simplest experimental design (besides the CRD): the <strong>randomized complete block design</strong> (RCBD) and leave more complicated block designs for STAT 802.</p>
<p>Consider an experiment in which we are interested in comparing six different lab activities for teaching the central limit theorem. Based on a power analysis, we believe four replications per treatment is sufficient, and so we need a total of 24 lab teams. We’ve got two options:</p>
<ul>
<li><br>
</li>
<li></li>
</ul>
<p>Which do you pick? Why? What are pros and cons of each?</p>
<p><br>
<br>
<br>
<br>
</p>
<div style="page-break-after: always;"></div>
<p>Suppose you decide to use teams in different classes (or you don’t have a choice). How will you assign treatments to teams?</p>
<p><br>
<br>
<br>
</p>
<p>Suppose we allocate treatments to teams completely at random (CRD), and by chance four out of six teams in one class are assigned to treatment 1. Would you be okay with this?</p>
<p><br>
<br>
<br>
</p>
<p>One of the main problems with the CRD is a possible ‘conditional’ bias. That is, treatment assignment is not balanced relative to any systematic variation/gradient. In this experiment, the gradient is</p>
<p><br>
<br>
<br>
</p>
<p>When this happens, treatment effect is confounded with gradient. Is any effect we observe really due to treatment, or is it due to the effect of the class? The other problem with the CRD is variance inflation. Suppose there is a gradient among the experimental units, with response increasing as you go up a gradient:</p>
<p><br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
</p>
<p>Even if all the same treatment is applied throughout, the variance among the experimental units (the residuals) will be composed of two quantities:</p>
<p><br>
</p>
<p>This means it will appear larger than it actually is. The most common solution to these problems of confounding and variance inflation is <strong>blocking</strong>.</p>
<div style="page-break-after: always;"></div>
<p>The idea of blocking is:</p>
<p><br>
<br>
<br>
<br>
<br>
</p>
<p>Blocking allows us to reconcile two somewhat opposing aims of experimental design.</p>
<ul>
<li><br>
</li>
<li><br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
</li>
</ul>
<p>In summary, the general idea of blocking is to organize experimental units into groups that are as uniform as possible. We want to</p>
<p><br>
<br>
<br>
</p>
<p>Blocks usually represent naturally occurring differences not related to treatments. If we block ‘correctly’ then the design accounts for block variation, and allows us to pull it out and isolate the usual random error due to experimental units. If we block ‘incorrectly’ then we get a weaker experiment.</p>
<p><strong>How Do We Block?</strong></p>
<p>There are two basic steps in blocking an experiment:</p>
<ol type="1">
<li><p>Organize the experimental units into subsets (blocks) according to gradient</p></li>
<li><p>Restrict the randomization so that each treatment is assigned to one or fewer (zero) experimental units in each block.</p></li>
</ol>
<section id="the-randomized-complete-block-design" class="level3" data-number="5.4.1">
<h3 data-number="5.4.1" class="anchored" data-anchor-id="the-randomized-complete-block-design"><span class="header-section-number">5.4.1</span> The Randomized Complete Block Design</h3>
<p>The simplest block design is the <strong>randomized complete block design</strong> (RCBD). In this design</p>
<p><br>
<br>
<br>
<br>
</p>
<p>In the RCBD, we carry out the two steps referenced on the previous page as</p>
<ol type="1">
<li><p>Divide the experimental units into blocks of homogeneous units.</p></li>
<li><p>Randomly assign treatments to units within blocks, using a separate randomization for each block. Every treatment will appear in every block.</p></li>
</ol>
<p>Again, we carry out step 1 with the goal</p>
<p><br>
<br>
<br>
</p>
<p>The model for the RCBD helps point out some considerations for choosing blocks. The model (assuming a one-way treatment design) is:</p>
<p><br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
</p>
<div style="page-break-after: always;"></div>
<p>The ANOVA table looks like</p>
<p><br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
</p>
<p><strong>Example:</strong> An experiment was carried out to evaluate the effect of elevated CO<span class="math inline">\(_2\)</span> on rice grain yield. Four blocks of 2 rice paddies each (each block owned by a different farmer, who used different fertilizer regimes and management practices over the years) are available for the experiment. In each paddy there is a 12 m diameter circular plot. In one plot in each block there is a ring of tubing around the plot emitting CO<span class="math inline">\(_2\)</span> at a rate of 300 ppm above ambient level. In the other plot, no CO<span class="math inline">\(_2\)</span> is emitted. The grain yield is measured at 3 locations in each plot at the end of the season, and the response is the average of the 3 locations.</p>
<p>What is the experimental unit here?</p>
<p>What does the assumption of no block <span class="math inline">\(\times\)</span> treatment interaction mean in this example?</p>
<p><br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
</p>
<p>We can check it with an interaction plot. Here are the means for each plot</p>
<div class="center">
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: center;">Block</th>
<th style="text-align: center;">Ambient CO<span class="math inline">\(_2\)</span></th>
<th style="text-align: center;">Elevated CO<span class="math inline">\(_2\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">1</td>
<td style="text-align: center;">6.21</td>
<td style="text-align: center;">6.41</td>
</tr>
<tr class="even">
<td style="text-align: center;">2</td>
<td style="text-align: center;">6.25</td>
<td style="text-align: center;">6.42</td>
</tr>
<tr class="odd">
<td style="text-align: center;">3</td>
<td style="text-align: center;">6.10</td>
<td style="text-align: center;">6.26</td>
</tr>
<tr class="even">
<td style="text-align: center;">4</td>
<td style="text-align: center;">6.14</td>
<td style="text-align: center;">6.30</td>
</tr>
</tbody>
</table>
</div>
<div style="page-break-after: always;"></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="block.jpeg" class="img-fluid figure-img" style="width:70.0%" alt="The graph shows the interaction plot for treatment x block with the rice data. The lines are roughly parallel, indicating that there is no interaction"></p>
<figcaption>Interaction plot for treatment x block.</figcaption>
</figure>
</div>
<p>If you had been presented with this data earlier in the semester, how would you have analyzed it?</p>
<p><br>
<br>
</p>
<div class="center">
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: center;">Block</th>
<th style="text-align: center;">Ambient CO<span class="math inline">\(_2\)</span></th>
<th style="text-align: center;">Elevated CO<span class="math inline">\(_2\)</span></th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">1</td>
<td style="text-align: center;">6.21</td>
<td style="text-align: center;">6.41</td>
<td></td>
</tr>
<tr class="even">
<td style="text-align: center;">2</td>
<td style="text-align: center;">6.25</td>
<td style="text-align: center;">6.42</td>
<td></td>
</tr>
<tr class="odd">
<td style="text-align: center;">3</td>
<td style="text-align: center;">6.10</td>
<td style="text-align: center;">6.26</td>
<td></td>
</tr>
<tr class="even">
<td style="text-align: center;">4</td>
<td style="text-align: center;">6.14</td>
<td style="text-align: center;">6.30</td>
<td></td>
</tr>
</tbody>
</table>
</div>
<p><br>
<br>
<br>
<br>
</p>
<div style="page-break-after: always;"></div>
</section>
<section id="selecting-blocks" class="level3" data-number="5.4.2">
<h3 data-number="5.4.2" class="anchored" data-anchor-id="selecting-blocks"><span class="header-section-number">5.4.2</span> Selecting Blocks</h3>
<p>Remember that the RCBD is an <strong>experimental</strong> design, not a treatment design. It can be used with any treatment design. So, we might see RCBD layouts that look like:</p>
<div class="center">
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: center;">Block 1</th>
<th style="text-align: center;">Block 2</th>
<th style="text-align: center;">Block 3</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Control</td>
<td style="text-align: center;">Trt2</td>
<td style="text-align: center;">Trt4</td>
</tr>
<tr class="even">
<td style="text-align: center;">Trt2</td>
<td style="text-align: center;">Control</td>
<td style="text-align: center;">Trt3</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Trt3</td>
<td style="text-align: center;">Trt4</td>
<td style="text-align: center;">Trt2</td>
</tr>
<tr class="even">
<td style="text-align: center;">Trt4</td>
<td style="text-align: center;">Trt3</td>
<td style="text-align: center;">Control</td>
</tr>
</tbody>
</table>
</div>
<div class="center">
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: center;">Block 1</th>
<th style="text-align: center;">Block 2</th>
<th style="text-align: center;">Block 3</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">20</td>
<td style="text-align: center;">60</td>
<td style="text-align: center;">80</td>
</tr>
<tr class="even">
<td style="text-align: center;">60</td>
<td style="text-align: center;">40</td>
<td style="text-align: center;">20</td>
</tr>
<tr class="odd">
<td style="text-align: center;">80</td>
<td style="text-align: center;">80</td>
<td style="text-align: center;">40</td>
</tr>
<tr class="even">
<td style="text-align: center;">40</td>
<td style="text-align: center;">20</td>
<td style="text-align: center;">60</td>
</tr>
</tbody>
</table>
</div>
<div class="center">
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: center;">Block 1</th>
<th style="text-align: center;">Block 2</th>
<th style="text-align: center;">Block 3</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">A1 &amp; B1</td>
<td style="text-align: center;">A1 &amp; B1</td>
<td style="text-align: center;">A2 &amp; B2</td>
</tr>
<tr class="even">
<td style="text-align: center;">A2 &amp; B1</td>
<td style="text-align: center;">A2 &amp; B1</td>
<td style="text-align: center;">A1 &amp; B1</td>
</tr>
<tr class="odd">
<td style="text-align: center;">A2 &amp; B2</td>
<td style="text-align: center;">A1 &amp; B2</td>
<td style="text-align: center;">A1 &amp; B2</td>
</tr>
<tr class="even">
<td style="text-align: center;">A1 &amp; B2</td>
<td style="text-align: center;">A2 &amp; B2</td>
<td style="text-align: center;">A2 &amp; B2</td>
</tr>
</tbody>
</table>
</div>
<p>When you write a report, both the treatment design and the experimental design need to be described in the methods section.</p>
<p><strong>Tips for Choosing Blocks:</strong></p>
<ul>
<li>We want to maximize differences between blocks and minimize differences within blocks</li>
</ul>
<p><br>
<br>
<br>
<br>
<br>
</p>
<div style="page-break-after: always;"></div>
<ul>
<li>Block size should not be excessively large</li>
</ul>
<p><br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
</p>
<ul>
<li>Keep in the mind the no block <span class="math inline">\(\times\)</span> treatment interaction assumption</li>
</ul>
<p><br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
</p>
<p><strong>Common Criteria for Blocking:</strong></p>
<ul>
<li><p>gradients that occur in the field, in greenhouses, in growth chambers</p></li>
<li><p>weight groups in animal experimentation, litters, cage positions in a room</p></li>
<li><p>occasion (day, month, year)</p></li>
<li><p>location (barn, different fields, different rooms, different states)</p></li>
<li><p>subjects (each subject serves as their own control)</p></li>
</ul>
<div style="page-break-after: always;"></div>
</section>
<section id="rcbd-model-and-analysis" class="level3" data-number="5.4.3">
<h3 data-number="5.4.3" class="anchored" data-anchor-id="rcbd-model-and-analysis"><span class="header-section-number">5.4.3</span> RCBD Model and Analysis</h3>
<p>Let <span class="math inline">\(y_{ij}\)</span> be</p>
<p><br>
<br>
<br>
</p>
<p>Earlier we stated the model</p>
<p><br>
<br>
<br>
<br>
<br>
<br>
<br>
</p>
<p>We do have another choice to make. We can consider the block effect to either be a <strong>fixed effect</strong> or a <strong>random effect</strong>.</p>
<p><br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
</p>
<p>Our choice will have implications in the standard errors of the cell means.</p>
<p><br>
<br>
<br>
</p>
<div style="page-break-after: always;"></div>
<p>To estimate the difference between two treatment means <span class="math inline">\((\mu_{i\cdot} - \mu_{i'\cdot})\)</span>, we use <span class="math inline">\(\overline y_{i\cdot} - \overline y_{i'\cdot}\)</span>. To figure out the variance (or estimate of the variance), let’s look at what <span class="math inline">\(\overline y_{i\cdot}\)</span> is actually estimating:</p>
<p><br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
</p>
<p>Now let’s explore the variance of this quantity.</p>
<p><br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
</p>
<p>Now let’s consider <span class="math inline">\(\overline y_{i\cdot} - \overline y_{i'\cdot}\)</span>:</p>
<p><br>
<br>
<br>
<br>
<br>
</p>
<p>and its variance</p>
<p><br>
<br>
<br>
<br>
<br>
</p>
<p>If we want to construct confidence intervals for treatment means or differences, they’ll have the form</p>
<p><br>
<br>
</p>
<p>where the standard error is</p>
<div style="page-break-after: always;"></div>
<p>For example, we use MSE as our estimate of <span class="math inline">\(\sigma^2\)</span>, so confidence intervals for the difference between two means is</p>
<p><br>
<br>
<br>
<br>
</p>
<p><strong>RCBDs in SAS</strong></p>
<p>We can still use <code>PROC GLIMMIX</code> to fit the model if our experimental design is the RCBD. The basic program for <strong>fixed blocks</strong> is</p>
<pre><code>    proc glimmix data=dataset;
      class block trt;
      model y = block trt;
    run;</code></pre>
<p>Note:</p>
<p><br>
<br>
</p>
<p>The basic program for <strong>random blocks</strong> is</p>
<pre><code>    proc glimmix data=dataset;
      class block trt;
      model y = trt;
      random block;
    run;</code></pre>
<p>Note:</p>
<p><br>
<br>
</p>
<p><strong>Example:</strong> This experiment is looking at the emergence rate of soybean seeds treated with four different chemical treatments and a control.</p>
<div class="center">
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: center;">Treatment Number</th>
<th style="text-align: left;">Treatment Name</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">1</td>
<td style="text-align: left;">Control</td>
</tr>
<tr class="even">
<td style="text-align: center;">2</td>
<td style="text-align: left;">Arasan</td>
</tr>
<tr class="odd">
<td style="text-align: center;">3</td>
<td style="text-align: left;">Spergon</td>
</tr>
<tr class="even">
<td style="text-align: center;">4</td>
<td style="text-align: left;">Semesan</td>
</tr>
<tr class="odd">
<td style="text-align: center;">5</td>
<td style="text-align: left;">Fermate</td>
</tr>
</tbody>
</table>
</div>
<p><strong>Experimental Layout:</strong> The field is located on a slope, and blocks are formed based on elevation. There are five plots at each elevation, and five blocks.</p>
<p><br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
</p>
<p><strong>Treatment Design:</strong></p>
<p><br>
<br>
<br>
</p>
<p>100 seeds were planted in each plot, and the response is the number of plants that emerge out of the 100.</p>
<p><br>
<br>
</p>
<p><strong>Model:</strong></p>
<p><br>
<br>
<br>
<br>
<br>
</p>
<div style="page-break-after: always;"></div>
<p><strong>Analysis with Blocks Fixed:</strong></p>
<p>If we assume blocks are fixed, we use the code</p>
<pre><code>proc glimmix data=seeds;
  class block chem;
  model emerge=block chem;
run;</code></pre>
<p>which gives</p>
<pre><code>                 Fit Statistics
    
    Pearson Chi-Square / DF         5.41
    
         Type III Tests of Fixed Effects
                  Num      Den
    Effect         DF       DF    F Value    Pr &gt; F
    
    block           4       16       2.30    0.1032
    chem            4       16       3.87    0.0219
    </code></pre>
<p>The follow-up analyses don’t change from what we’ve done so far. In this case, the treatment design is one-way treatment-versus-control, so comparing all treatments to the control is appropriate and we can use the Dunnett adjustment.</p>
<pre><code>    lsmeans chem/diff=control('Control') adjust=dunnett;

                        Chem Least Squares Means
    
                           Standard
    Chem       Estimate       Error       DF    t Value    Pr &gt; |t|
    
    Arasan      93.8000      1.0402       16      90.18      &lt;.0001
    Control     89.2000      1.0402       16      85.75      &lt;.0001
    Fermate     94.2000      1.0402       16      90.56      &lt;.0001
    Semesan     93.4000      1.0402       16      89.79      &lt;.0001
    Spergon     91.8000      1.0402       16      88.25      &lt;.0001</code></pre>
<div style="page-break-after: always;"></div>
<pre><code>                Differences of Chem Least Squares Means
              Adjustment for Multiple Comparisons: Dunnett
    
                                      Standard
    Chem       _Chem      Estimate       Error       DF    t Value    Pr &gt; |t|     Adj P
    
    Arasan     Control      4.6000      1.4711       16       3.13      0.0065    0.0218
    Fermate    Control      5.0000      1.4711       16       3.40      0.0037    0.0125
    Semesan    Control      4.2000      1.4711       16       2.86      0.0115    0.0375
    Spergon    Control      2.6000      1.4711       16       1.77      0.0962    0.2680
    </code></pre>
<p><strong>Analysis with Blocks Random:</strong></p>
<p>If we assume blocks are random, we use the code</p>
<pre><code>    proc glimmix data=seeds;
      class block chem;
      model emerge=chem;
      random block;
      lsmeans chem/diff=control('Control') adjust=dunnett;
    run;</code></pre>
<p>which gives</p>
<pre><code>              Fit Statistics
    Gener. Chi-Square / DF          5.41
    
      Covariance Parameter Estimates
                            Standard
    Cov Parm    Estimate       Error
    block         1.4100      1.8032
    Residual      5.4100      1.9127
    
           Type III Tests of Fixed Effects
                  Num      Den
    Effect         DF       DF    F Value    Pr &gt; F
    Chem            4       16       3.87    0.0219
    
                    Chem Least Squares Means
                           Standard
    Chem       Estimate       Error       DF    t Value    Pr &gt; |t| 
    Arasan      93.8000      1.1679       16      80.31      &lt;.0001
    Control     89.2000      1.1679       16      76.38      &lt;.0001
    Fermate     94.2000      1.1679       16      80.66      &lt;.0001
    Semesan     93.4000      1.1679       16      79.97      &lt;.0001
    Spergon     91.8000      1.1679       16      78.60      &lt;.0001</code></pre>
<div style="page-break-after: always;"></div>
<pre><code>                     Differences of Chem Least Squares Means
                Adjustment for Multiple Comparisons: Dunnett-Hsu
                                      Standard
    Chem       _Chem      Estimate       Error       DF    t Value    Pr &gt; |t|     Adj P    
    Arasan     Control      4.6000      1.4711       16       3.13      0.0065    0.0218
    Fermate    Control      5.0000      1.4711       16       3.40      0.0037    0.0125
    Semesan    Control      4.2000      1.4711       16       2.86      0.0115    0.0375
    Spergon    Control      2.6000      1.4711       16       1.77      0.0962    0.2680
    </code></pre>
<p>The results are the same whether we used fixed blocks or random blocks. This is because our data are <strong>balanced</strong>–we had the same number of observations in each block, and all treatments appear in all blocks. If our data had not been balanced, the results would be different.</p>
</section>
<section id="did-blocking-work" class="level3" data-number="5.4.4">
<h3 data-number="5.4.4" class="anchored" data-anchor-id="did-blocking-work"><span class="header-section-number">5.4.4</span> Did Blocking Work?</h3>
<p>When we treated blocks as fixed effects, we get a p-value associated with block but it is completely meaningless because there is no valid hypothesis test for evaluating the effect of block. However, we can check the <strong>efficiency</strong> of the block design relative to a competing design.</p>
<p>Suppose we have <span class="math inline">\(t\)</span> treatments and <span class="math inline">\(rt\)</span> experimental units available for our experiment. We have two possible experimental designs:</p>
<ul>
<li><br>
</li>
<li></li>
</ul>
<p>The only difference between these is whether we group the experimental units into blocks before randomly assigning the treatments. Efficiency gives us a way to compare the variance of two competing designs–we want to select the design that gives us the smaller variance of estimated treatment differences.</p>
<ul>
<li><p>CRD:<br>
<br>
<br>
</p></li>
<li><p>RCBD<br>
<br>
<br>
</p></li>
</ul>
<p>So the choice between these two designs comes down to a comparison of <span class="math inline">\(\sigma^2_{CRD}\)</span> and <span class="math inline">\(\sigma^2_{RCBD}\)</span>. We can compare variances using a ratio called the <strong>relative efficiency</strong>.</p>
<p><br>
</p>
<div style="page-break-after: always;"></div>
<p>If RE <span class="math inline">\(&gt;\)</span> 1</p>
<p><br>
<br>
<br>
<br>
<br>
<br>
<br>
</p>
<p>Once we’ve conducted an RCBD experiment we can look and see whether we did the right thing when we used blocks.</p>
<p><br>
<br>
<br>
<br>
</p>
<p>Note there is a difference in the error degrees of freedom between the CRD and RCBD which can have an impact. We can adjust for this difference by calculating the <strong>adjusted relative efficiency</strong>:</p>
<p><br>
<br>
<br>
<br>
<br>
<br>
</p>
<p>The correction factor is always less than 1, and usually won’t make much difference. It can make a difference if the number of treatments and reps is small.</p>
<p><strong>Example: Rice paddies</strong> In this example, there were 4 blocks and two treatments. We’ll fit the model both with blocks and without.</p>
<ul>
<li>RCBD:</li>
</ul>
<p><br>
</p>
<ul>
<li>CRD:</li>
</ul>
<p><br>
</p>
<div style="page-break-after: always;"></div>
<p><strong>Example: Seed Emergence</strong> In this example, there were five blocks and five treatments. Again, we’ll fit the model both with blocks and without.</p>
<ul>
<li><p>RCBD:<br>
</p></li>
<li><p>CRD:<br>
<br>
<br>
<br>
<br>
<br>
<br>
</p></li>
</ul>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./Section4-One-Pred-Two-Levels.html" class="pagination-link" aria-label="One Predictor/Explanatory Variable, Two Levels">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">One Predictor/Explanatory Variable, Two Levels</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
  </div>
</nav>
</div> <!-- /content -->




</body></html>